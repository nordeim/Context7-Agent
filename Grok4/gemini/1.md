An analysis of the traceback reveals two distinct errors originating from `src/agent.py`, which I will address systematically.

1.  **`TypeError: OpenAIModel.__init__() got an unexpected keyword argument 'model'`**: This error occurs because the `pydantic_ai.models.openai.OpenAIModel` class is being instantiated with a `model` argument, which it does not accept. This is likely due to an API change in the `pydantic-ai` library. The modern approach is to configure the `OpenAIProvider` directly with the model name and an existing OpenAI client instance, rather than creating a separate `OpenAIModel` object for this purpose.

2.  **`AttributeError: 'Context7Agent' object has no attribute 'mcp_server'`**: This secondary error is a direct consequence of the first. The `TypeError` causes the `Context7Agent.__init__` method to fail and exit prematurely, before the `self.mcp_server` attribute can be assigned. When the object is garbage-collected, the `__del__` method is invoked and fails because the attribute was never created.

Resolving the primary `TypeError` will allow the `__init__` method to complete successfully, which will, in turn, resolve the `AttributeError`.

My plan is to modify `src/agent.py` to correctly initialize the `pydantic-ai` provider. This involves:
*   Removing the incorrect instantiation of `OpenAIModel`.
*   Updating the `OpenAIProvider` instantiation to use the already-configured `openai.OpenAI` client instance and the model name from the configuration.
*   Removing the now-unused import of `OpenAIModel`.

This targeted change will align the code with the expected library usage, ensuring robust initialization and resolving both reported errors without altering any other functionality.

I will now provide the complete, updated file for `src/agent.py`.

```python
# File: src/agent.py
"""
Agent module for the Context7 Agent.

This module implements a Pydantic AI agent with Context7 MCP server integration.
The agent uses an OpenAI model with configuration from environment variables.
"""

import os
import sys
from typing import Dict, Any, Optional, List, Union

from pydantic_ai import Agent
from pydantic_ai.mcp import MCPServerStdio
from pydantic_ai.providers.openai import OpenAIProvider
from pydantic_ai.messages import ModelMessagesTypeAdapter
from pydantic_core import to_jsonable_python
import openai  # Underlying lib for actual calls

# Add project root to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import config
from history import History

class Context7Agent:
    """
    Context7 Agent implementation using Pydantic AI.

    This agent integrates with the Context7 MCP server for enhanced context management
    and uses an OpenAI model with OpenAIProvider as the underlying LLM provider.
    Supports intent detection, MCP searches, and conversational responses.
    """

    def __init__(self):
        """
        Initialize the Context7 Agent with configuration from environment variables.

        Sets up the OpenAI model with OpenAIProvider and Context7 MCP server integration.
        """
        error = config.validate()
        if error:
            raise ValueError(error)

        # Set up OpenAI client
        self.openai_client = openai.OpenAI(
            api_key=config.openai_api_key,
            base_url=config.openai_base_url
        )

        # Set up Pydantic AI provider
        self.provider = OpenAIProvider(
            client=self.openai_client,
            model=config.openai_model
        )

        # Set up MCP server integration using the specific syntax
        self.mcp_server = MCPServerStdio(config.mcp_config["mcpServers"]["context7"])

        # Pydantic AI Agent
        self.agent = Agent(provider=self.provider)

        # History integration
        self.history = History()

        # Start MCP server
        self.mcp_server.start()

    def detect_intent(self, message: str) -> str:
        """Detect if the message intends a search or command."""
        if "/search" in message or any(keyword in message.lower() for keyword in ["tell me about", "find docs on", "search for"]):
            return "search"
        elif message.startswith("/"):
            return "command"
        return "chat"

    def query_mcp(self, query: str, filters: Optional[Dict] = None) -> List[Dict]:
        """Query the Context7 MCP server for documents. (Mocked for demo; integrate real MCP calls.)"""
        # In reality, use self.mcp_server to send query and get contextual results
        # For demo, return mock results with fuzzy matching simulation
        mock_results = [
            {"id": 1, "title": f"Doc on {query}", "content": "Sample content...", "tags": ["ai"], "date": "2025-07-13"},
            {"id": 2, "title": f"Related to {query}", "content": "More info...", "tags": ["ethics"], "date": "2025-07-12"}
        ]
        self.history.add_search(query, mock_results)
        return mock_results

    def generate_response(self, message: str, conversation: List[Dict]) -> str:
        """Generate response using OpenAI via Pydantic AI."""
        intent = self.detect_intent(message)
        if intent == "search":
            search_query = message.split("about")[-1].strip() if "about" in message else message
            results = self.query_mcp(search_query)
            summary = f"Found {len(results)} docs: " + ", ".join([r['title'] for r in results])
            # Use OpenAI to enhance response
            prompt = f"Summarize these search results for the user: {summary}"
            response = self.openai_client.chat.completions.create(
                model=config.openai_model,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content + "\nUse /preview <id> to view."
        elif intent == "command":
            return self.handle_command(message)
        else:
            # Standard chat
            messages = ModelMessagesTypeAdapter.validate_python(conversation + [{"role": "user", "content": message}])
            ai_response = self.agent.complete(messages)
            return ai_response.content

    def handle_command(self, command: str) -> str:
        """Handle hotkey commands."""
        if command == "/help":
            return "Commands: /search <query>, /preview <id>, /bookmark <id>, /theme <name>, /analytics, /exit"
        # Add more handlers...
        return "Unknown command."

    def preview_document(self, doc_id: int) -> str:
        """Syntax-highlighted preview (simple text for now)."""
        docs = self.history.get_searches()[-1]["results"] if self.history.get_searches() else []
        for doc in docs:
            if doc["id"] == doc_id:
                return f"Preview: {doc['title']}\nContent: {doc['content']}"  # Add highlighting with Rich in CLI
        return "Doc not found."

    def __del__(self):
        self.mcp_server.stop()
```

---
https://drive.google.com/file/d/1E3aE0HAzd78kBhbvsi6kXAZVH6c-xrCL/view?usp=sharing, https://drive.google.com/file/d/1PzF1Ha_uY5dnIuVJbR3LOwtgGgaeZSdd/view?usp=sharing, https://drive.google.com/file/d/1Qg-vxxIH4c0LButLJYJUgWzWEcfrpPed/view?usp=sharing, https://drive.google.com/file/d/1XY-0HMxi45gRUg0ionP5mfb2gA0GOzv9/view?usp=sharing, https://drive.google.com/file/d/1c6NnLhE1HmMc9VyLinoB4X9I_Vd1ajkC/view?usp=sharing, https://drive.google.com/file/d/1jbBQnzE6_ubpDfT35i1J8OBgKJKdfQb2/view?usp=sharing, https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%221rMmtddressFzIwdCnFzxtUaYL6r5lkXh%22%5D,%22action%22:%22open%22,%22userId%22:%22108686197475781557359%22,%22resourceKeys%22:%7B%7D%7D&usp=sharing, https://drive.google.com/file/d/1tb8XiTo6PfK_1y_nShEJFjRjgMZuwJgk/view?usp=sharing, https://drive.google.com/file/d/1vDAp7A3Y2vapTvHTXw91hdIGnFHTNSX5/view?usp=sharing, https://drive.google.com/file/d/1wyPf_fppqZrEoXu188CK65SACi2fhLEp/view?usp=sharing, https://drive.google.com/file/d/1xIs1MgSpnYfFqhBdo6KfTEMoGSQCqhn7/view?usp=sharing

