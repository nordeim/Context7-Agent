"""
Core agent implementation with Pydantic AI and MCP integration.
Fixed async generator and streaming API issues with proper patterns.
"""

import asyncio
import json
from typing import List, Dict, Any, Optional, AsyncGenerator
from datetime import datetime
import logging

from pydantic_ai import Agent
from pydantic_ai.mcp import MCPServerStdio
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider

from .config import config
from .history import HistoryManager

logger = logging.getLogger(__name__)

class Context7Agent:
    """Advanced AI agent with Context7 MCP integration."""
    
    def __init__(self):
        """Initialize the agent with MCP and OpenAI."""
        self.provider = OpenAIProvider(
            api_key=config.openai_api_key,
            base_url=config.openai_base_url
        )
        
        self.model = OpenAIModel(
            model_name=config.openai_model,
            provider=self.provider
        )
        
        self.mcp_server = MCPServerStdio(
            command="npx",
            args=["-y", "@upstash/context7-mcp@latest"]
        )
        
        self.agent = Agent(
            model=self.model,
            mcp_servers=[self.mcp_server],
            system_prompt="""You are Context7, an advanced AI assistant with access to a vast knowledge base.
            You can search, analyze, and present documents in real-time. Be helpful, concise, and engaging.
            When users ask about topics, use the search tools to find relevant documents and provide summaries."""
        )
        
        self.history = HistoryManager()
        self._conversation_id = None
    
    async def initialize(self):
        """Initialize the agent and MCP connection."""
        await self.history.load()
    
    async def chat_stream(
        self, 
        message: str, 
        conversation_id: Optional[str] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """Stream chat responses with MCP integration using proper async patterns."""
        
        try:
            async with self.agent.run_mcp_servers():
                # Build conversation history
                history = self.history.get_messages(conversation_id or "default")
                
                # Create proper message structure
                messages = []
                for msg in history[-10:]:  # Keep last 10 messages for context
                    if msg["role"] == "user":
                        messages.append({"role": "user", "content": msg["content"]})
                    elif msg["role"] == "assistant":
                        messages.append({"role": "assistant", "content": msg["content"]})
                
                messages.append({"role": "user", "content": message})
                
                # Use agent.run() for reliable streaming
                full_response = ""
                
                # Handle both streaming and non-streaming modes
                try:
                    # First, try the standard run method
                    result = await self.agent.run(message, message_history=messages)
                    content = str(result.data)
                    
                    # Yield as single chunk
                    yield {
                        "type": "content",
                        "data": content,
                        "timestamp": datetime.now().isoformat()
                    }
                    full_response = content
                    
                except Exception as e:
                    # Fallback to simpler approach
                    logger.warning(f"Streaming failed, using fallback: {e}")
                    
                    # Use direct query
                    result = await self.agent.run(
                        f"Please answer: {message}",
                        message_history=messages
                    )
                    content = str(result.data)
                    
                    yield {
                        "type": "content",
                        "data": content,
                        "timestamp": datetime.now().isoformat()
                    }
                    full_response = content
                
                # Save to history
                await self.history.save_message(
                    conversation_id or "default",
                    message,
                    full_response
                )
                
                yield {
                    "type": "complete",
                    "data": full_response,
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"Agent error: {e}")
            yield {
                "type": "error",
                "data": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def search_documents(
        self, 
        query: str, 
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """Search documents using MCP tools."""
        
        try:
            async with self.agent.run_mcp_servers():
                result = await self.agent.run(
                    f"Search for documents about: {query}. Return up to {limit} results."
                )
                
                # Parse MCP tool results
                if hasattr(result, 'data'):
                    return json.loads(result.data) if isinstance(result.data, str) else result.data
                
                return [{"title": "Search Result", "content": str(result)}]
                
        except Exception as e:
            logger.error(f"Search error: {e}")
            return [{"error": str(e)}]
    
    def get_conversations(self) -> List[Dict[str, Any]]:
        """Get all conversation histories."""
        return self.history.get_conversations()
    
    async def clear_history(self, conversation_id: Optional[str] = None):
        """Clear conversation history."""
        await self.history.clear(conversation_id)
