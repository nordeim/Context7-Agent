<think>
The user wants me to create a sophisticated AI agent using Pydantic AI that integrates with the Context7 MCP server. Looking at the requirements:

1. Visual Interface with 4 themes, animations, rich terminal UI, and ASCII art
2. Powerful search capabilities with AI-powered search, real-time results, filters, and analytics
3. Document management with previews, bookmarks, history, and recommendations
4. Context7 MCP server integration
5. Complete project structure with tests and documentation

I'll create a comprehensive implementation that includes all requested features. Let me start by creating the core modules.
</think>

I'll help you create an awesome Context7 AI Agent with Pydantic AI. Let me build a comprehensive implementation with all the requested features.

## Project Structure

First, let's create the complete project structure:

### 1. Configuration Module (`config.py`)

```python
# src/config.py
"""
Configuration module for Context7 Agent.

Handles environment variables and application settings.
"""

import os
from pathlib import Path
from typing import Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class Config:
    """Application configuration."""
    
    def __init__(self):
        # OpenAI Configuration
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        self.openai_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        
        # Context7 Configuration
        self.context7_command = os.getenv("CONTEXT7_COMMAND", "npx")
        self.context7_args = os.getenv("CONTEXT7_ARGS", "-y,@upstash/context7-mcp@latest").split(",")
        
        # Application Configuration
        self.app_name = "Context7 Agent"
        self.app_version = "1.0.0"
        self.history_file = Path.home() / ".context7_agent" / "history.db"
        self.bookmarks_file = Path.home() / ".context7_agent" / "bookmarks.json"
        self.session_file = Path.home() / ".context7_agent" / "session.json"
        self.theme = os.getenv("CONTEXT7_THEME", "cyberpunk")
        
        # Create directories if they don't exist
        self.history_file.parent.mkdir(parents=True, exist_ok=True)
    
    def validate(self) -> Optional[str]:
        """Validate configuration."""
        if not self.openai_api_key:
            return "OPENAI_API_KEY environment variable is not set"
        return None

config = Config()
```

### 2. Agent Module (`agent.py`)

```python
# src/agent.py
"""
Agent module for the Context7 Agent.

This module implements a Pydantic AI agent with Context7 MCP server integration.
"""

import os
import sys
from typing import Dict, Any, Optional, List, Union
import json
import asyncio
from datetime import datetime

from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.tools import Tool

# Add Context7 MCP integration
import subprocess
import asyncio
from pathlib import Path

# Add the project root to the Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.config import config

class SearchRequest(BaseModel):
    """Model for search requests."""
    query: str = Field(..., description="Search query")
    filters: Optional[Dict[str, Any]] = Field(default=None, description="Search filters")
    limit: int = Field(default=10, description="Maximum results")

class Document(BaseModel):
    """Model for documents."""
    id: str
    title: str
    content: str
    path: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)
    similarity_score: Optional[float] = None

class SearchResult(BaseModel):
    """Model for search results."""
    documents: List[Document]
    total: int
    query: str
    timestamp: datetime

class Context7MCPClient:
    """Client for interacting with Context7 MCP server."""
    
    def __init__(self):
        self.process = None
        self.connected = False
        
    async def connect(self):
        """Connect to Context7 MCP server."""
        try:
            # Start the Context7 MCP server
            self.process = await asyncio.create_subprocess_exec(
                config.context7_command,
                *config.context7_args,
                stdin=asyncio.subprocess.PIPE,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            self.connected = True
            return True
        except Exception as e:
            print(f"Failed to connect to Context7 MCP: {e}")
            return False
    
    async def search(self, query: str, filters: Optional[Dict] = None) -> List[Dict]:
        """Search documents using Context7."""
        if not self.connected:
            await self.connect()
        
        # Send search request to MCP server
        request = {
            "jsonrpc": "2.0",
            "method": "search",
            "params": {
                "query": query,
                "filters": filters or {}
            },
            "id": 1
        }
        
        try:
            # Send request
            self.process.stdin.write(json.dumps(request).encode() + b'\n')
            await self.process.stdin.drain()
            
            # Read response
            response_line = await self.process.stdout.readline()
            response = json.loads(response_line.decode())
            
            if "result" in response:
                return response["result"].get("documents", [])
            return []
        except Exception as e:
            print(f"Search error: {e}")
            return []
    
    async def disconnect(self):
        """Disconnect from Context7 MCP server."""
        if self.process:
            self.process.terminate()
            await self.process.wait()
            self.connected = False

class Context7Agent:
    """
    Context7 Agent implementation using Pydantic AI.
    
    This agent integrates with the Context7 MCP server for enhanced context management
    and uses an OpenAI model as the underlying LLM provider.
    """
    
    def __init__(self):
        """Initialize the Context7 Agent."""
        # Validate configuration
        error = config.validate()
        if error:
            raise ValueError(error)
        
        # Initialize Context7 MCP client
        self.mcp_client = Context7MCPClient()
        
        # Initialize OpenAI model
        self.model = OpenAIModel(
            api_key=config.openai_api_key,
            base_url=config.openai_base_url,
            model_name=config.openai_model
        )
        
        # Define system prompt
        system_prompt = """You are Context7, an advanced AI assistant with document search and management capabilities.
        You can search through documents, provide intelligent recommendations, and help users manage their knowledge base.
        
        Your capabilities include:
        - Semantic search across documents
        - Document analysis and summarization
        - Finding similar documents
        - Managing bookmarks and search history
        - Providing contextual recommendations
        
        Be helpful, accurate, and provide clear explanations for your search results and recommendations."""
        
        # Initialize Pydantic AI agent
        self.agent = Agent(
            model=self.model,
            system_prompt=system_prompt,
            tools=[
                self.search_documents,
                self.analyze_document,
                self.find_similar,
                self.get_recommendations
            ]
        )
    
    async def search_documents(
        self,
        ctx: RunContext,
        query: str,
        file_type: Optional[str] = None,
        date_from: Optional[str] = None,
        date_to: Optional[str] = None,
        max_results: int = 10
    ) -> SearchResult:
        """
        Search for documents using Context7.
        
        Args:
            query: Search query
            file_type: Filter by file type (e.g., 'pdf', 'txt', 'md')
            date_from: Filter by start date (ISO format)
            date_to: Filter by end date (ISO format)
            max_results: Maximum number of results
        
        Returns:
            SearchResult with matching documents
        """
        filters = {}
        if file_type:
            filters["file_type"] = file_type
        if date_from:
            filters["date_from"] = date_from
        if date_to:
            filters["date_to"] = date_to
        
        # Search using Context7 MCP
        results = await self.mcp_client.search(query, filters)
        
        # Convert to Document models
        documents = []
        for result in results[:max_results]:
            doc = Document(
                id=result.get("id", ""),
                title=result.get("title", "Untitled"),
                content=result.get("content", ""),
                path=result.get("path"),
                metadata=result.get("metadata", {}),
                similarity_score=result.get("score")
            )
            documents.append(doc)
        
        return SearchResult(
            documents=documents,
            total=len(results),
            query=query,
            timestamp=datetime.now()
        )
    
    async def analyze_document(
        self,
        ctx: RunContext,
        document_id: str
    ) -> Dict[str, Any]:
        """
        Analyze a document and provide insights.
        
        Args:
            document_id: ID of the document to analyze
        
        Returns:
            Analysis results including summary, key topics, and entities
        """
        # Get document from Context7
        results = await self.mcp_client.search(f"id:{document_id}", {"limit": 1})
        
        if not results:
            return {"error": "Document not found"}
        
        doc = results[0]
        
        # Analyze using the LLM
        analysis_prompt = f"""Analyze this document and provide:
        1. A brief summary
        2. Key topics and themes
        3. Important entities (people, organizations, locations)
        4. Suggested tags
        
        Document: {doc.get('content', '')[:2000]}..."""
        
        response = await self.agent.run(analysis_prompt)
        
        return {
            "document_id": document_id,
            "title": doc.get("title"),
            "analysis": response.data
        }
    
    async def find_similar(
        self,
        ctx: RunContext,
        document_id: str,
        limit: int = 5
    ) -> List[Document]:
        """
        Find documents similar to a given document.
        
        Args:
            document_id: ID of the reference document
            limit: Maximum number of similar documents
        
        Returns:
            List of similar documents
        """
        # Get the reference document
        results = await self.mcp_client.search(f"id:{document_id}", {"limit": 1})
        
        if not results:
            return []
        
        ref_doc = results[0]
        
        # Search for similar content
        similar_results = await self.mcp_client.search(
            ref_doc.get("content", "")[:500],
            {"exclude_id": document_id, "limit": limit}
        )
        
        documents = []
        for result in similar_results:
            doc = Document(
                id=result.get("id", ""),
                title=result.get("title", "Untitled"),
                content=result.get("content", ""),
                path=result.get("path"),
                metadata=result.get("metadata", {}),
                similarity_score=result.get("score")
            )
            documents.append(doc)
        
        return documents
    
    async def get_recommendations(
        self,
        ctx: RunContext,
        user_history: List[str]
    ) -> List[Document]:
        """
        Get personalized document recommendations based on user history.
        
        Args:
            user_history: List of previously viewed document IDs
        
        Returns:
            List of recommended documents
        """
        if not user_history:
            # Return popular or recent documents
            results = await self.mcp_client.search("*", {"sort": "date", "limit": 5})
        else:
            # Get content from recent documents
            recent_content = []
            for doc_id in user_history[-3:]:
                results = await self.mcp_client.search(f"id:{doc_id}", {"limit": 1})
                if results:
                    recent_content.append(results[0].get("content", "")[:200])
            
            # Search for related content
            combined_query = " ".join(recent_content)
            results = await self.mcp_client.search(combined_query, {"limit": 10})
            
            # Filter out already viewed documents
            results = [r for r in results if r.get("id") not in user_history]
        
        documents = []
        for result in results[:5]:
            doc = Document(
                id=result.get("id", ""),
                title=result.get("title", "Untitled"),
                content=result.get("content", ""),
                path=result.get("path"),
                metadata=result.get("metadata", {}),
                similarity_score=result.get("score")
            )
            documents.append(doc)
        
        return documents
    
    async def chat(self, message: str, conversation_history: Optional[List[Dict]] = None) -> str:
        """
        Chat with the agent.
        
        Args:
            message: User message
            conversation_history: Previous conversation messages
        
        Returns:
            Agent response
        """
        # Prepare conversation context
        messages = []
        if conversation_history:
            for msg in conversation_history[-10:]:  # Keep last 10 messages for context
                messages.append(msg)
        
        # Run the agent
        result = await self.agent.run(message, message_history=messages)
        
        return result.data
    
    async def __aenter__(self):
        """Async context manager entry."""
        await self.mcp_client.connect()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit."""
        await self.mcp_client.disconnect()
```

### 3. Themes Module (`themes.py`)

```python
# src/themes.py
"""
Beautiful themes for the Context7 Agent CLI.

Includes Cyberpunk, Ocean, Forest, and Sunset themes with
gradients, ASCII art, and color schemes.
"""

from typing import Dict, List, Tuple
from rich.console import Console
from rich.text import Text
from rich.panel import Panel
from rich.style import Style
import random

class Theme:
    """Base theme class."""
    
    def __init__(self, name: str, colors: Dict[str, str], ascii_art: str):
        self.name = name
        self.colors = colors
        self.ascii_art = ascii_art
        
    def get_gradient(self, text: str, start_color: str, end_color: str) -> Text:
        """Create gradient text."""
        styled_text = Text()
        length = len(text)
        
        for i, char in enumerate(text):
            # Interpolate between colors
            ratio = i / max(1, length - 1)
            r1, g1, b1 = self._hex_to_rgb(start_color)
            r2, g2, b2 = self._hex_to_rgb(end_color)
            
            r = int(r1 + (r2 - r1) * ratio)
            g = int(g1 + (g2 - g1) * ratio)
            b = int(b1 + (b2 - b1) * ratio)
            
            color = f"#{r:02x}{g:02x}{b:02x}"
            styled_text.append(char, style=color)
        
        return styled_text
    
    def _hex_to_rgb(self, hex_color: str) -> Tuple[int, int, int]:
        """Convert hex to RGB."""
        hex_color = hex_color.lstrip('#')
        return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
    
    def get_welcome_panel(self) -> Panel:
        """Get themed welcome panel."""
        content = Text()
        content.append(self.ascii_art, style=self.colors['primary'])
        content.append("\n\n")
        content.append("Welcome to ", style=self.colors['text'])
        content.append("Context7 Agent", style=self.colors['accent'])
        content.append("\n", style=self.colors['text'])
        content.append("Your AI-powered document assistant", style=self.colors['dim'])
        
        return Panel(
            content,
            border_style=self.colors['border'],
            title=f"[{self.colors['accent']}]{self.name} Theme[/{self.colors['accent']}]",
            padding=(1, 2)
        )

# Cyberpunk Theme
CYBERPUNK_THEME = Theme(
    name="Cyberpunk",
    colors={
        'primary': '#ff00ff',
        'secondary': '#00ffff',
        'accent': '#ffff00',
        'background': '#1a0033',
        'text': '#e0e0e0',
        'dim': '#808080',
        'error': '#ff0040',
        'success': '#00ff40',
        'border': '#ff00ff',
        'highlight': '#ff00ff'
    },
    ascii_art="""
    ╔═══════════════════════════════════════╗
    ║  ▄████▄   ▒█████   ███▄    █ ▄▄▄█████▓║
    ║ ▒██▀ ▀█  ▒██▒  ██▒ ██ ▀█   █ ▓  ██▒ ▓▒║
    ║ ▒▓█    ▄ ▒██░  ██▒▓██  ▀█ ██▒▒ ▓██░ ▒░║
    ║ ▒▓▓▄ ▄██▒▒██   ██░▓██▒  ▐▌██▒░ ▓██▓ ░ ║
    ║ ▒ ▓███▀ ░░ ████▓▒░▒██░   ▓██░  ▒██▒ ░ ║
    ║ ░ ░▒ ▒  ░░ ▒░▒░▒░ ░ ▒░   ▒ ▒   ▒ ░░   ║
    ║   ░  ▒     ░ ▒ ▒░ ░ ░░   ░ ▒░    ░    ║
    ╚═══════════════════════════════════════╝
    """
)

# Ocean Theme
OCEAN_THEME = Theme(
    name="Ocean",
    colors={
        'primary': '#006994',
        'secondary': '#00a8cc',
        'accent': '#00d4ff',
        'background': '#001f3f',
        'text': '#e0f7ff',
        'dim': '#6b8cae',
        'error': '#ff6b6b',
        'success': '#4ecdc4',
        'border': '#00a8cc',
        'highlight': '#00d4ff'
    },
    ascii_art="""
    ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈
    ≈  ╔═╗╔═╗╔═╗╔═╗╔╗╔  ╔═╗╔═╗╔═╗╔╗╔╔╦╗  ≈
    ≈  ║ ║║  ║╣ ╠═╣║║║  ╠═╣║ ╦║╣ ║║║ ║   ≈
    ≈  ╚═╝╚═╝╚═╝╩ ╩╝╚╝  ╩ ╩╚═╝╚═╝╝╚╝ ╩   ≈
    ≈       ～～～ Waves of Knowledge ～～～    ≈
    ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈
    """
)

# Forest Theme
FOREST_THEME = Theme(
    name="Forest",
    colors={
        'primary': '#228b22',
        'secondary': '#32cd32',
        'accent': '#90ee90',
        'background': '#0f2f0f',
        'text': '#e0ffe0',
        'dim': '#6b8e6b',
        'error': '#dc143c',
        'success': '#00ff00',
        'border': '#32cd32',
        'highlight': '#90ee90'
    },
    ascii_art="""
    🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲
    🌲  ╔═╗╔═╗╦═╗╔═╗╔═╗╔╦╗  ╔═╗╔═╗╔═╗╔╗╔╔╦╗  🌲
    🌲  ╠╣ ║ ║╠╦╝║╣ ╚═╗ ║   ╠═╣║ ╦║╣ ║║║ ║   🌲
    🌲  ╚  ╚═╝╩╚═╚═╝╚═╝ ╩   ╩ ╩╚═╝╚═╝╝╚╝ ╩   🌲
    🌲     Growing Knowledge Naturally        🌲
    🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲🌲
    """
)

# Sunset Theme
SUNSET_THEME = Theme(
    name="Sunset",
    colors={
        'primary': '#ff6b35',
        'secondary': '#f7931e',
        'accent': '#ffd700',
        'background': '#2d1810',
        'text': '#ffe4e1',
        'dim': '#cd853f',
        'error': '#ff1744',
        'success': '#ffd700',
        'border': '#ff6b35',
        'highlight': '#ffd700'
    },
    ascii_art="""
    ☀️════════════════════════════════════☀️
    ║  ╔═╗╦ ╦╔╗╔╔═╗╔═╗╔╦╗  ╔═╗╔═╗╔═╗╔╗╔╔╦╗ ║
    ║  ╚═╗║ ║║║║╚═╗║╣  ║   ╠═╣║ ╦║╣ ║║║ ║  ║
    ║  ╚═╝╚═╝╝╚╝╚═╝╚═╝ ╩   ╩ ╩╚═╝╚═╝╝╚╝ ╩  ║
    ║        Golden Hour Intelligence        ║
    ☀️════════════════════════════════════☀️
    """
)

# Theme registry
THEMES = {
    'cyberpunk': CYBERPUNK_THEME,
    'ocean': OCEAN_THEME,
    'forest': FOREST_THEME,
    'sunset': SUNSET_THEME
}

def get_theme(name: str) -> Theme:
    """Get theme by name."""
    return THEMES.get(name.lower(), CYBERPUNK_THEME)

def list_themes() -> List[str]:
    """List available theme names."""
    return list(THEMES.keys())
```

### 4. History Module (`history.py`)

```python
# src/history.py
"""
Conversation history management for Context7 Agent.

Provides SQLite-based storage for conversations, search history,
bookmarks, and sessions.
"""

import sqlite3
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, asdict

@dataclass
class Message:
    """Represents a conversation message."""
    id: Optional[int] = None
    session_id: str = ""
    role: str = ""  # 'user' or 'assistant'
    content: str = ""
    timestamp: datetime = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()
        if self.metadata is None:
            self.metadata = {}

@dataclass
class SearchEntry:
    """Represents a search history entry."""
    id: Optional[int] = None
    query: str = ""
    results_count: int = 0
    filters: Dict[str, Any] = None
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()
        if self.filters is None:
            self.filters = {}

@dataclass
class Bookmark:
    """Represents a document bookmark."""
    id: Optional[int] = None
    document_id: str = ""
    title: str = ""
    path: Optional[str] = None
    tags: List[str] = None
    notes: str = ""
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()
        if self.tags is None:
            self.tags = []

class HistoryManager:
    """Manages conversation history, search history, and bookmarks."""
    
    def __init__(self, db_path: Path):
        """Initialize the history manager."""
        self.db_path = db_path
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_database()
    
    def _init_database(self):
        """Initialize the database schema."""
        with sqlite3.connect(self.db_path) as conn:
            # Conversation messages
            conn.execute("""
                CREATE TABLE IF NOT EXISTS messages (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    role TEXT NOT NULL,
                    content TEXT NOT NULL,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    metadata TEXT
                )
            """)
            
            # Search history
            conn.execute("""
                CREATE TABLE IF NOT EXISTS search_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    query TEXT NOT NULL,
                    results_count INTEGER DEFAULT 0,
                    filters TEXT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Bookmarks
            conn.execute("""
                CREATE TABLE IF NOT EXISTS bookmarks (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    document_id TEXT NOT NULL UNIQUE,
                    title TEXT NOT NULL,
                    path TEXT,
                    tags TEXT,
                    notes TEXT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Sessions
            conn.execute("""
                CREATE TABLE IF NOT EXISTS sessions (
                    id TEXT PRIMARY KEY,
                    name TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    metadata TEXT
                )
            """)
            
            # Create indexes
            conn.execute("CREATE INDEX IF NOT EXISTS idx_messages_session ON messages(session_id)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_search_timestamp ON search_history(timestamp)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_bookmarks_tags ON bookmarks(tags)")
            
            conn.commit()
    
    # Message Management
    def add_message(self, message: Message) -> int:
        """Add a message to the conversation history."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                """INSERT INTO messages (session_id, role, content, timestamp, metadata)
                   VALUES (?, ?, ?, ?, ?)""",
                (message.session_id, message.role, message.content,
                 message.timestamp, json.dumps(message.metadata))
            )
            return cursor.lastrowid
    
    def get_session_messages(self, session_id: str, limit: int = 100) -> List[Message]:
        """Get messages for a session."""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute(
                """SELECT * FROM messages 
                   WHERE session_id = ? 
                   ORDER BY timestamp DESC 
                   LIMIT ?""",
                (session_id, limit)
            )
            
            messages = []
            for row in cursor:
                msg = Message(
                    id=row['id'],
                    session_id=row['session_id'],
                    role=row['role'],
                    content=row['content'],
                    timestamp=datetime.fromisoformat(row['timestamp']),
                    metadata=json.loads(row['metadata'] or '{}')
                )
                messages.append(msg)
            
            return list(reversed(messages))
    
    # Search History Management
    def add_search(self, search: SearchEntry) -> int:
        """Add a search to history."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                """INSERT INTO search_history (query, results_count, filters, timestamp)
                   VALUES (?, ?, ?, ?)""",
                (search.query, search.results_count,
                 json.dumps(search.filters), search.timestamp)
            )
            return cursor.lastrowid
    
    def get_search_history(self, limit: int = 50) -> List[SearchEntry]:
        """Get recent search history."""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute(
                """SELECT * FROM search_history 
                   ORDER BY timestamp DESC 
                   LIMIT ?""",
                (limit,)
            )
            
            searches = []
            for row in cursor:
                search = SearchEntry(
                    id=row['id'],
                    query=row['query'],
                    results_count=row['results_count'],
                    filters=json.loads(row['filters'] or '{}'),
                    timestamp=datetime.fromisoformat(row['timestamp'])
                )
                searches.append(search)
            
            return searches
    
    def get_popular_searches(self, days: int = 7, limit: int = 10) -> List[Dict[str, Any]]:
        """Get popular searches from the last N days."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                """SELECT query, COUNT(*) as count 
                   FROM search_history 
                   WHERE timestamp > datetime('now', '-{} days')
                   GROUP BY query 
                   ORDER BY count DESC 
                   LIMIT ?""".format(days),
                (limit,)
            )
            
            return [{'query': row[0], 'count': row[1]} for row in cursor]
    
    # Bookmark Management
    def add_bookmark(self, bookmark: Bookmark) -> int:
        """Add a bookmark."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                """INSERT OR REPLACE INTO bookmarks 
                   (document_id, title, path, tags, notes, timestamp)
                   VALUES (?, ?, ?, ?, ?, ?)""",
                (bookmark.document_id, bookmark.title, bookmark.path,
                 json.dumps(bookmark.tags), bookmark.notes, bookmark.timestamp)
            )
            return cursor.lastrowid
    
    def get_bookmarks(self, tag: Optional[str] = None) -> List[Bookmark]:
        """Get bookmarks, optionally filtered by tag."""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            
            if tag:
                cursor = conn.execute(
                    """SELECT * FROM bookmarks 
                       WHERE tags LIKE ? 
                       ORDER BY timestamp DESC""",
                    (f'%"{tag}"%',)
                )
            else:
                cursor = conn.execute(
                    "SELECT * FROM bookmarks ORDER BY timestamp DESC"
                )
            
            bookmarks = []
            for row in cursor:
                bookmark = Bookmark(
                    id=row['id'],
                    document_id=row['document_id'],
                    title=row['title'],
                    path=row['path'],
                    tags=json.loads(row['tags'] or '[]'),
                    notes=row['notes'] or '',
                    timestamp=datetime.fromisoformat(row['timestamp'])
                )
                bookmarks.append(bookmark)
            
            return bookmarks
    
    def remove_bookmark(self, document_id: str) -> bool:
        """Remove a bookmark."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "DELETE FROM bookmarks WHERE document_id = ?",
                (document_id,)
            )
            return cursor.rowcount > 0
    
    # Session Management
    def create_session(self, session_id: str, name: Optional[str] = None) -> None:
        """Create a new session."""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """INSERT OR REPLACE INTO sessions (id, name, updated_at)
                   VALUES (?, ?, CURRENT_TIMESTAMP)""",
                (session_id, name or f"Session {datetime.now().strftime('%Y-%m-%d %H:%M')}")
            )
    
    def get_sessions(self, limit: int = 20) -> List[Dict[str, Any]]:
        """Get recent sessions."""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute(
                """SELECT s.*, COUNT(m.id) as message_count
                   FROM sessions s
                   LEFT JOIN messages m ON s.id = m.session_id
                   GROUP BY s.id
                   ORDER BY s.updated_at DESC
                   LIMIT ?""",
                (limit,)
            )
            
            sessions = []
            for row in cursor:
                session = {
                    'id': row['id'],
                    'name': row['name'],
                    'created_at': row['created_at'],
                    'updated_at': row['updated_at'],
                    'message_count': row['message_count']
                }
                sessions.append(session)
            
            return sessions
    
    def get_search_analytics(self) -> Dict[str, Any]:
        """Get search analytics."""
        with sqlite3.connect(self.db_path) as conn:
            # Total searches
            total = conn.execute("SELECT COUNT(*) FROM search_history").fetchone()[0]
            
            # Searches today
            today = conn.execute(
                """SELECT COUNT(*) FROM search_history 
                   WHERE date(timestamp) = date('now')"""
            ).fetchone()[0]
            
            # Average results per search
            avg_results = conn.execute(
                "SELECT AVG(results_count) FROM search_history"
            ).fetchone()[0] or 0
            
            # Most common search terms
            cursor = conn.execute(
                """SELECT query, COUNT(*) as count 
                   FROM search_history 
                   GROUP BY query 
                   ORDER BY count DESC 
                   LIMIT 5"""
            )
            top_searches = [{'query': row[0], 'count': row[1]} for row in cursor]
            
            return {
                'total_searches': total,
                'searches_today': today,
                'average_results': round(avg_results, 1),
                'top_searches': top_searches
            }
```

### 5. Utils Module (`utils.py`)

```python
# src/utils.py
"""
Utility functions for Context7 Agent.

Provides formatting, animations, and helper functions.
"""

import asyncio
import time
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
from pathlib import Path
import re
import humanize
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
from rich.syntax import Syntax
from rich.table import Table
from rich.text import Text
from rich import box

console = Console()

def format_timestamp(timestamp: datetime) -> str:
    """Format timestamp in a human-readable way."""
    return humanize.naturaltime(timestamp)

def format_file_size(size_bytes: int) -> str:
    """Format file size in human-readable format."""
    return humanize.naturalsize(size_bytes, binary=True)

def truncate_text(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """Truncate text to a maximum length."""
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

def highlight_search_terms(text: str, search_terms: List[str], style: str = "yellow bold") -> Text:
    """Highlight search terms in text."""
    result = Text(text)
    
    for term in search_terms:
        # Case-insensitive search
        pattern = re.compile(re.escape(term), re.IGNORECASE)
        
        for match in pattern.finditer(text):
            start, end = match.span()
            result.stylize(style, start, end)
    
    return result

def detect_file_type(path: str) -> str:
    """Detect file type from path."""
    path = Path(path)
    suffix = path.suffix.lower()
    
    # Map common extensions to types
    type_map = {
        '.py': 'python',
        '.js': 'javascript',
        '.ts': 'typescript',
        '.java': 'java',
        '.cpp': 'cpp',
        '.c': 'c',
        '.cs': 'csharp',
        '.go': 'go',
        '.rs': 'rust',
        '.rb': 'ruby',
        '.php': 'php',
        '.swift': 'swift',
        '.kt': 'kotlin',
        '.scala': 'scala',
        '.r': 'r',
        '.m': 'matlab',
        '.jl': 'julia',
        '.sh': 'bash',
        '.ps1': 'powershell',
        '.sql': 'sql',
        '.html': 'html',
        '.css': 'css',
        '.xml': 'xml',
        '.json': 'json',
        '.yaml': 'yaml',
        '.yml': 'yaml',
        '.toml': 'toml',
        '.md': 'markdown',
        '.rst': 'rst',
        '.tex': 'latex',
        '.txt': 'text',
        '.log': 'log',
        '.csv': 'csv',
        '.pdf': 'pdf',
        '.doc': 'word',
        '.docx': 'word',
        '.xls': 'excel',
        '.xlsx': 'excel',
        '.ppt': 'powerpoint',
        '.pptx': 'powerpoint',
        '.png': 'image',
        '.jpg': 'image',
        '.jpeg': 'image',
        '.gif': 'image',
        '.svg': 'image',
        '.mp4': 'video',
        '.avi': 'video',
        '.mov': 'video',
        '.mp3': 'audio',
        '.wav': 'audio',
        '.flac': 'audio'
    }
    
    return type_map.get(suffix, 'unknown')

def create_document_preview(content: str, file_type: str, max_lines: int = 20) -> Syntax:
    """Create a syntax-highlighted preview of document content."""
    lines = content.split('\n')[:max_lines]
    preview_content = '\n'.join(lines)
    
    if len(content.split('\n')) > max_lines:
        preview_content += '\n...'
    
    # Map file types to lexer names
    lexer_map = {
        'python': 'python',
        'javascript': 'javascript',
        'typescript': 'typescript',
        'java': 'java',
        'cpp': 'cpp',
        'c': 'c',
        'csharp': 'csharp',
        'go': 'go',
        'rust': 'rust',
        'ruby': 'ruby',
        'php': 'php',
        'sql': 'sql',
        'html': 'html',
        'css': 'css',
        'xml': 'xml',
        'json': 'json',
        'yaml': 'yaml',
        'markdown': 'markdown',
        'bash': 'bash',
        'powershell': 'powershell'
    }
    
    lexer = lexer_map.get(file_type, 'text')
    
    return Syntax(
        preview_content,
        lexer,
        theme="monokai",
        line_numbers=True,
        word_wrap=True
    )

def create_results_table(results: List[Dict[str, Any]], search_terms: List[str]) -> Table:
    """Create a formatted table of search results."""
    table = Table(
        title="Search Results",
        box=box.ROUNDED,
        show_lines=True,
        expand=True
    )
    
    table.add_column("#", style="dim", width=3)
    table.add_column("Title", style="cyan", no_wrap=False)
    table.add_column("Type", style="yellow", width=10)
    table.add_column("Size", style="green", width=10)
    table.add_column("Modified", style="magenta", width=15)
    table.add_column("Score", style="red", width=8)
    
    for idx, result in enumerate(results, 1):
        # Highlight search terms in title
        title = highlight_search_terms(
            result.get('title', 'Untitled'),
            search_terms
        )
        
        table.add_row(
            str(idx),
            title,
            detect_file_type(result.get('path', '')),
            format_file_size(result.get('size', 0)),
            format_timestamp(
                datetime.fromisoformat(result.get('modified', datetime.now().isoformat()))
            ),
            f"{result.get('score', 0):.2f}"
        )
    
    return table

async def animate_search(duration: float = 2.0):
    """Show an animated search progress."""
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        console=console,
        transient=True
    ) as progress:
        task = progress.add_task("[cyan]Searching documents...", total=100)
        
        for i in range(100):
            await asyncio.sleep(duration / 100)
            progress.update(task, advance=1)
            
            # Update description with different states
            if i < 25:
                progress.update(task, description="[cyan]Analyzing query...")
            elif i < 50:
                progress.update(task, description="[cyan]Searching index...")
            elif i < 75:
                progress.update(task, description="[cyan]Ranking results...")
            else:
                progress.update(task, description="[cyan]Preparing response...")

def format_analytics(analytics: Dict[str, Any]) -> Table:
    """Format search analytics as a table."""
    table = Table(
        title="Search Analytics",
        box=box.DOUBLE_EDGE,
        show_header=False,
        expand=False
    )
    
    table.add_column("Metric", style="cyan")
    table.add_column("Value", style="yellow")
    
    table.add_row("Total Searches", str(analytics.get('total_searches', 0)))
    table.add_row("Searches Today", str(analytics.get('searches_today', 0)))
    table.add_row("Avg Results/Search", str(analytics.get('average_results', 0)))
    
    # Add top searches
    table.add_row("", "")  # Empty row for spacing
    table.add_row("[bold]Top Searches[/bold]", "")
    
    for search in analytics.get('top_searches', []):
        table.add_row(f"  {search['query']}", f"({search['count']} times)")
    
    return table

def parse_search_query(query: str) -> Dict[str, Any]:
    """Parse a search query to extract filters and search terms."""
    filters = {}
    terms = []
    
    # Extract type filter (type:pdf, type:python, etc.)
    type_match = re.search(r'type:(\w+)', query)
    if type_match:
        filters['file_type'] = type_match.group(1)
        query = query.replace(type_match.group(0), '')
    
    # Extract date filters (after:2024-01-01, before:2024-12-31)
    after_match = re.search(r'after:(\d{4}-\d{2}-\d{2})', query)
    if after_match:
        filters['date_from'] = after_match.group(1)
        query = query.replace(after_match.group(0), '')
    
    before_match = re.search(r'before:(\d{4}-\d{2}-\d{2})', query)
    if before_match:
        filters['date_to'] = before_match.group(1)
        query = query.replace(before_match.group(0), '')
    
    # Extract size filter (size:>1MB, size:<10KB)
    size_match = re.search(r'size:([<>])(\d+)([KMG]?B)', query)
    if size_match:
        operator = size_match.group(1)
        value = int(size_match.group(2))
        unit = size_match.group(3)
        
        # Convert to bytes
        multipliers = {'B': 1, 'KB': 1024, 'MB': 1024**2, 'GB': 1024**3}
        size_bytes = value * multipliers.get(unit, 1)
        
        if operator == '>':
            filters['min_size'] = size_bytes
        else:
            filters['max_size'] = size_bytes
        
        query = query.replace(size_match.group(0), '')
    
    # Extract tag filter (tag:important, tag:work)
    tag_matches = re.findall(r'tag:(\w+)', query)
    if tag_matches:
        filters['tags'] = tag_matches
        for tag_match in tag_matches:
            query = query.replace(f'tag:{tag_match}', '')
    
    # Clean up remaining query
    terms = query.strip().split()
    
    return {
        'query': ' '.join(terms),
        'filters': filters,
        'terms': terms
    }

def create_loading_animation(text: str = "Loading", style: str = "cyan") -> None:
    """Create a simple loading animation."""
    frames = ["⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"]
    
    for frame in frames:
        console.print(f"[{style}]{frame} {text}...[/{style}]", end="\r")
        time.sleep(0.1)
    
    console.print(" " * (len(text) + 10), end="\r")  # Clear the line

def format_session_info(session: Dict[str, Any]) -> str:
    """Format session information for display."""
    created = datetime.fromisoformat(session['created_at'])
    updated = datetime.fromisoformat(session['updated_at'])
    
    duration = updated - created
    
    return (
        f"[cyan]Session:[/cyan] {session['name']}\n"
        f"[dim]ID:[/dim] {session['id']}\n"
        f"[dim]Messages:[/dim] {session['message_count']}\n"
        f"[dim]Duration:[/dim] {humanize.naturaldelta(duration)}\n"
        f"[dim]Created:[/dim] {format_timestamp(created)}"
    )
```

### 6. CLI Module (`cli.py`)

```python
# src/cli.py
"""
CLI interface for Context7 Agent.

Provides a beautiful, interactive terminal interface with themes,
animations, and rich formatting.
"""

import asyncio
import sys
from pathlib import Path
from typing import Optional, List, Dict, Any
import uuid
from datetime import datetime

import click
from rich.console import Console
from rich.prompt import Prompt, Confirm
from rich.panel import Panel
from rich.layout import Layout
from rich.live import Live
from rich.table import Table
from rich.text import Text
from rich.markdown import Markdown
from rich import box
import questionary

# Add the project root to the Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.agent import Context7Agent, SearchRequest
from src.history import HistoryManager, Message, SearchEntry, Bookmark
from src.themes import get_theme, list_themes
from src.config import config
from src.utils import (
    animate_search, create_results_table, create_document_preview,
    format_analytics, parse_search_query, create_loading_animation,
    format_session_info, highlight_search_terms
)

console = Console()

class Context7CLI:
    """Interactive CLI for Context7 Agent."""
    
    def __init__(self):
        """Initialize the CLI."""
        self.agent = None
        self.history = HistoryManager(config.history_file)
        self.theme = get_theme(config.theme)
        self.session_id = str(uuid.uuid4())
        self.current_mode = "chat"  # chat, search, or manage
        
    async def start(self):
        """Start the CLI interface."""
        # Clear screen and show welcome
        console.clear()
        console.print(self.theme.get_welcome_panel())
        
        # Initialize agent
        console.print("\n[cyan]Initializing Context7 Agent...[/cyan]")
        try:
            self.agent = Context7Agent()
            await self.agent.mcp_client.connect()
            console.print("[green]✓ Agent initialized successfully![/green]\n")
        except Exception as e:
            console.print(f"[red]✗ Failed to initialize agent: {e}[/red]")
            return
        
        # Create session
        self.history.create_session(self.session_id)
        
        # Main interaction loop
        await self.main_loop()
    
    async def main_loop(self):
        """Main interaction loop."""
        while True:
            try:
                # Show mode-specific prompt
                if self.current_mode == "chat":
                    user_input = await self.get_chat_input()
                elif self.current_mode == "search":
                    user_input = await self.get_search_input()
                else:
                    user_input = await self.get_manage_input()
                
                if user_input is None:
                    break
                
                # Process input based on mode
                if self.current_mode == "chat":
                    await self.handle_chat(user_input)
                elif self.current_mode == "search":
                    await self.handle_search(user_input)
                else:
                    await self.handle_manage(user_input)
                    
            except KeyboardInterrupt:
                if Confirm.ask("\n[yellow]Exit Context7 Agent?[/yellow]"):
                    break
            except Exception as e:
                console.print(f"\n[red]Error: {e}[/red]")
    
    async def get_chat_input(self) -> Optional[str]:
        """Get chat input from user."""
        # Show prompt with theme colors
        prompt_style = f"[{self.theme.colors['accent']}]You[/{self.theme.colors['accent']}]"
        
        # Special commands
        console.print(
            f"\n[dim]Commands: /search, /bookmarks, /history, /theme, /help, /exit[/dim]",
            style=self.theme.colors['dim']
        )
        
        user_input = Prompt.ask(f"\n{prompt_style}")
        
        # Handle special commands
        if user_input.startswith('/'):
            return await self.handle_command(user_input)
        
        return user_input
    
    async def get_search_input(self) -> Optional[str]:
        """Get search input from user."""
        console.print(
            f"\n[{self.theme.colors['accent']}]Search Mode[/{self.theme.colors['accent']}] "
            f"[dim](type: file_type, after: date, before: date, size: >/<bytes, tag: name)[/dim]"
        )
        
        # Show recent searches
        recent = self.history.get_search_history(5)
        if recent:
            console.print("\n[dim]Recent searches:[/dim]")
            for search in recent:
                console.print(f"  • {search.query}", style="dim")
        
        search_query = Prompt.ask(
            f"\n[{self.theme.colors['primary']}]Search[/{self.theme.colors['primary']}]"
        )
        
        if search_query == '/chat':
            self.current_mode = 'chat'
            return ''
        
        return search_query
    
    async def get_manage_input(self) -> Optional[str]:
        """Get management command input."""
        choices = [
            "View Bookmarks",
            "Search History",
            "Analytics",
            "Sessions",
            "Settings",
            "Back to Chat"
        ]
        
        choice = await asyncio.to_thread(
            questionary.select,
            "What would you like to do?",
            choices=choices
        ).ask()
        
        return choice
    
    async def handle_command(self, command: str) -> Optional[str]:
        """Handle special commands."""
        cmd = command.lower().strip()
        
        if cmd == '/search':
            self.current_mode = 'search'
            return ''
        elif cmd == '/bookmarks':
            await self.show_bookmarks()
            return ''
        elif cmd == '/history':
            await self.show_history()
            return ''
        elif cmd == '/theme':
            await self.change_theme()
            return ''
        elif cmd == '/help':
            await self.show_help()
            return ''
        elif cmd == '/exit':
            return None
        else:
            console.print(f"[yellow]Unknown command: {command}[/yellow]")
            return ''
    
    async def handle_chat(self, message: str):
        """Handle chat interaction."""
        if not message:
            return
        
        # Add user message to history
        self.history.add_message(Message(
            session_id=self.session_id,
            role="user",
            content=message
        ))
        
        # Show thinking animation
        with console.status(
            f"[{self.theme.colors['accent']}]Thinking...[/{self.theme.colors['accent']}]",
            spinner="dots"
        ):
            # Get conversation history
            history = self.history.get_session_messages(self.session_id, limit=20)
            
            # Prepare messages for agent
            messages = []
            for msg in history[:-1]:  # Exclude the current message we just added
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })
            
            # Get agent response
            try:
                response = await self.agent.chat(message, messages)
            except Exception as e:
                console.print(f"[red]Error: {e}[/red]")
                return
        
        # Display response with typing effect
        console.print(f"\n[{self.theme.colors['secondary']}]Context7:[/{self.theme.colors['secondary']}]")
        
        # Format response as markdown if it contains code or formatting
        if '```' in response or '#' in response or '**' in response:
            md = Markdown(response)
            console.print(md)
        else:
            console.print(response, style=self.theme.colors['text'])
        
        # Add assistant message to history
        self.history.add_message(Message(
            session_id=self.session_id,
            role="assistant",
            content=response
        ))
    
    async def handle_search(self, query: str):
        """Handle search interaction."""
        if not query:
            return
        
        # Parse query and extract filters
        parsed = parse_search_query(query)
        
        # Show search animation
        search_task = asyncio.create_task(animate_search(1.5))
        
        try:
            # Perform search
            result = await self.agent.search_documents(
                None,  # RunContext not needed for direct call
                parsed['query'],
                file_type=parsed['filters'].get('file_type'),
                date_from=parsed['filters'].get('date_from'),
                date_to=parsed['filters'].get('date_to'),
                max_results=20
            )
            
            # Wait for animation to complete
            await search_task
            
            # Add to search history
            self.history.add_search(SearchEntry(
                query=query,
                results_count=result.total,
                filters=parsed['filters']
            ))
            
            # Display results
            if result.documents:
                console.print(f"\n[green]Found {result.total} results[/green]\n")
                
                # Create results table
                results_data = []
                for doc in result.documents:
                    results_data.append({
                        'title': doc.title,
                        'path': doc.path or '',
                        'size': doc.metadata.get('size', 0),
                        'modified': doc.metadata.get('modified', datetime.now().isoformat()),
                        'score': doc.similarity_score or 0
                    })
                
                table = create_results_table(results_data, parsed['terms'])
                console.print(table)
                
                # Ask if user wants to view a document
                if Confirm.ask("\n[cyan]View a document?[/cyan]"):
                    doc_num = Prompt.ask(
                        "Enter document number",
                        choices=[str(i) for i in range(1, len(result.documents) + 1)]
                    )
                    await self.view_document(result.documents[int(doc_num) - 1])
            else:
                console.print(f"\n[yellow]No results found for '{query}'[/yellow]")
                
                # Suggest alternatives
                console.print("\n[dim]Try:[/dim]")
                console.print("  • Using different keywords")
                console.print("  • Removing filters")
                console.print("  • Checking spelling")
                
        except Exception as e:
            await search_task
            console.print(f"\n[red]Search error: {e}[/red]")
    
    async def view_document(self, document):
        """View a document with syntax highlighting."""
        console.clear()
        
        # Document header
        header = Panel(
            f"[bold]{document.title}[/bold]\n"
            f"[dim]Path: {document.path or 'N/A'}[/dim]\n"
            f"[dim]Score: {document.similarity_score:.2f}[/dim]",
            title="Document Preview",
            border_style=self.theme.colors['border']
        )
        console.print(header)
        
        # Document content with syntax highlighting
        file_type = detect_file_type(document.path or '')
        preview = create_document_preview(document.content, file_type)
        console.print("\n", preview)
        
        # Actions
        console.print(f"\n[{self.theme.colors['accent']}]Actions:[/{self.theme.colors['accent']}]")
        actions = [
            "Bookmark this document",
            "Find similar documents",
            "Analyze document",
            "Back to search"
        ]
        
        action = await asyncio.to_thread(
            questionary.select,
            "What would you like to do?",
            choices=actions
        ).ask()
        
        if action == "Bookmark this document":
            await self.bookmark_document(document)
        elif action == "Find similar documents":
            await self.find_similar_documents(document)
        elif action == "Analyze document":
            await self.analyze_document(document)
    
    async def bookmark_document(self, document):
        """Bookmark a document."""
        # Get tags
        tags_input = Prompt.ask(
            "Enter tags (comma-separated)",
            default=""
        )
        tags = [tag.strip() for tag in tags_input.split(',')] if tags_input else []
        
        # Get notes
        notes = Prompt.ask("Add notes (optional)", default="")
        
        # Create bookmark
        bookmark = Bookmark(
            document_id=document.id,
            title=document.title,
            path=document.path,
            tags=tags,
            notes=notes
        )
        
        self.history.add_bookmark(bookmark)
        console.print(f"\n[green]✓ Document bookmarked![/green]")
    
    async def find_similar_documents(self, document):
        """Find documents similar to the given document."""
        console.print(f"\n[cyan]Finding similar documents...[/cyan]")
        
        try:
            similar = await self.agent.find_similar(None, document.id, limit=5)
            
            if similar:
                console.print(f"\n[green]Found {len(similar)} similar documents:[/green]\n")
                
                for idx, doc in enumerate(similar, 1):
                    console.print(
                        f"{idx}. [{self.theme.colors['accent']}]{doc.title}[/{self.theme.colors['accent']}] "
                        f"[dim](Score: {doc.similarity_score:.2f})[/dim]"
                    )
                    
                    # Show snippet
                    snippet = truncate_text(doc.content, 200)
                    console.print(f"   {snippet}", style="dim")
                    console.print()
            else:
                console.print("[yellow]No similar documents found[/yellow]")
                
        except Exception as e:
            console.print(f"[red]Error finding similar documents: {e}[/red]")
    
    async def analyze_document(self, document):
        """Analyze a document using AI."""
        with console.status(
            f"[{self.theme.colors['accent']}]Analyzing document...[/{self.theme.colors['accent']}]",
            spinner="dots"
        ):
            try:
                analysis = await self.agent.analyze_document(None, document.id)
                
                if 'error' not in analysis:
                    console.print(f"\n[bold]Analysis of '{document.title}'[/bold]\n")
                    
                    # Display analysis as markdown
                    md = Markdown(analysis.get('analysis', 'No analysis available'))
                    console.print(md)
                else:
                    console.print(f"[red]Error: {analysis['error']}[/red]")
                    
            except Exception as e:
                console.print(f"[red]Analysis error: {e}[/red]")
    
    async def show_bookmarks(self):
        """Show bookmarked documents."""
        bookmarks = self.history.get_bookmarks()
        
        if not bookmarks:
            console.print("[yellow]No bookmarks yet[/yellow]")
            return
        
        table = Table(
            title="Bookmarks",
            box=box.ROUNDED,
            show_lines=True
        )
        
        table.add_column("#", style="dim", width=3)
        table.add_column("Title", style="cyan", no_wrap=False)
        table.add_column("Tags", style="yellow")
        table.add_column("Added", style="magenta")
        
        for idx, bookmark in enumerate(bookmarks, 1):
            table.add_row(
                str(idx),
                bookmark.title,
                ', '.join(bookmark.tags),
                format_timestamp(bookmark.timestamp)
            )
        
        console.print(table)
    
    async def show_history(self):
        """Show conversation history."""
        messages = self.history.get_session_messages(self.session_id)
        
        if not messages:
            console.print("[yellow]No conversation history yet[/yellow]")
            return
        
        console.print(f"\n[bold]Conversation History[/bold]\n")
        
        for msg in messages:
            role_style = (
                self.theme.colors['accent'] if msg.role == 'user'
                else self.theme.colors['secondary']
            )
            
            console.print(
                f"[{role_style}]{msg.role.capitalize()}:[/{role_style}] "
                f"[dim]({format_timestamp(msg.timestamp)})[/dim]"
            )
            console.print(msg.content)
            console.print()
    
    async def change_theme(self):
        """Change the application theme."""
        themes = list_themes()
        
        theme_name = await asyncio.to_thread(
            questionary.select,
            "Choose a theme:",
            choices=themes
        ).ask()
        
        self.theme = get_theme(theme_name)
        config.theme = theme_name
        
        console.clear()
        console.print(self.theme.get_welcome_panel())
        console.print(f"\n[green]✓ Theme changed to {theme_name}![/green]")
    
    async def show_help(self):
        """Show help information."""
        help_text = f"""
# Context7 Agent Help

## Chat Commands
- `/search` - Switch to search mode
- `/bookmarks` - View your bookmarks
- `/history` - View conversation history
- `/theme` - Change the application theme
- `/help` - Show this help message
- `/exit` - Exit the application

## Search Syntax
- `type:pdf` - Filter by file type
- `after:2024-01-01` - Filter by date (after)
- `before:2024-12-31` - Filter by date (before)
- `size:>1MB` - Filter by size (>, <)
- `tag:important` - Filter by tag

## Examples
- `machine learning type:pdf after:2024-01-01`
- `python tutorial size:<100KB`
- `project report tag:work before:2024-06-01`

## Tips
- Use quotes for exact phrases: `"machine learning"`
- Combine multiple filters for precise results
- Bookmark important documents for quick access
        """
        
        md = Markdown(help_text)
        console.print(md)
    
    async def cleanup(self):
        """Clean up resources."""
        if self.agent:
            await self.agent.mcp_client.disconnect()

async def main():
    """Main entry point."""
    cli = Context7CLI()
    
    try:
        await cli.start()
    except Exception as e:
        console.print(f"\n[red]Fatal error: {e}[/red]")
    finally:
        await cli.cleanup()
        console.print(f"\n[{cli.theme.colors['accent']}]Goodbye![/{cli.theme.colors['accent']}]")

if __name__ == "__main__":
    asyncio.run(main())
```

### 7. Main Entry Point

```python
# context7_agent.py
#!/usr/bin/env python3
"""
Context7 Agent - AI-powered document search and management.

This is the main entry point for the Context7 Agent CLI.
"""

import asyncio
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

from src.cli import main

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nInterrupted by user")
        sys.exit(0)
    except Exception as e:
        print(f"\nError: {e}", file=sys.stderr)
        sys.exit(1)
```

### 8. Requirements File

```txt
# requirements.txt
# Core dependencies
pydantic-ai>=0.1.0
pydantic>=2.0.0
python-dotenv>=1.0.0
click>=8.1.0
rich>=13.0.0
questionary>=2.0.0
humanize>=4.0.0

# Development dependencies
pytest>=7.0.0
pytest-asyncio>=0.21.0
pytest-cov>=4.0.0
black>=23.0.0
flake8>=6.0.0
mypy>=1.0.0

# Optional dependencies for enhanced features
aiofiles>=23.0.0  # For async file operations
httpx>=0.24.0     # For API calls
numpy>=1.24.0     # For similarity calculations
```

### 9. Environment Example

```bash
# .env.example
# OpenAI Configuration
OPENAI_API_KEY=your-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini

# Context7 Configuration
CONTEXT7_COMMAND=npx
CONTEXT7_ARGS=-y,@upstash/context7-mcp@latest

# Application Configuration
CONTEXT7_THEME=cyberpunk
```

### 10. pyproject.toml

```toml
# pyproject.toml
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "context7-agent"
version = "1.0.0"
description = "AI-powered document search and management with Context7 MCP integration"
readme = "README.md"
requires-python = ">=3.11"
license = {text = "MIT"}
authors = [
    {name = "Your Name", email = "your.email@example.com"}
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Text Processing :: Indexing",
]

dependencies = [
    "pydantic-ai>=0.1.0",
    "pydantic>=2.0.0",
    "python-dotenv>=1.0.0",
    "click>=8.1.0",
    "rich>=13.0.0",
    "questionary>=2.0.0",
    "humanize>=4.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "flake8>=6.0.0",
    "mypy>=1.0.0",
]

[project.scripts]
context7 = "context7_agent:main"

[tool.black]
line-length = 88
target-version = ['py311']

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
```

### 11. Test Files

```python
# tests/test_agent.py
"""Tests for the Context7 Agent."""

import pytest
import asyncio
from unittest.mock import Mock, patch, AsyncMock

from src.agent import Context7Agent, SearchRequest, Document, SearchResult
from src.config import config

@pytest.fixture
def mock_config():
    """Mock configuration."""
    with patch.object(config, 'validate', return_value=None):
        with patch.object(config, 'openai_api_key', 'test-key'):
            with patch.object(config, 'openai_base_url', 'http://test.com'):
                with patch.object(config, 'openai_model', 'test-model'):
                    yield config

@pytest.fixture
async def agent(mock_config):
    """Create a test agent."""
    with patch('src.agent.Context7MCPClient') as mock_mcp:
        mock_mcp.return_value.connect = AsyncMock(return_value=True)
        mock_mcp.return_value.search = AsyncMock(return_value=[])
        
        agent = Context7Agent()
        yield agent

@pytest.mark.asyncio
async def test_agent_initialization(agent):
    """Test agent initialization."""
    assert agent is not None
    assert agent.mcp_client is not None
    assert agent.model is not None

@pytest.mark.asyncio
async def test_search_documents(agent):
    """Test document search."""
    # Mock MCP search response
    mock_results = [
        {
            'id': '1',
            'title': 'Test Document',
            'content': 'Test content',
            'path': '/test/doc.txt',
            'metadata': {'size': 1024},
            'score': 0.95
        }
    ]
    
    agent.mcp_client.search = AsyncMock(return_value=mock_results)
    
    # Perform search
    result = await agent.search_documents(
        None,
        "test query",
        max_results=10
    )
    
    assert isinstance(result, SearchResult)
    assert len(result.documents) == 1
    assert result.documents[0].title == 'Test Document'
    assert result.query == "test query"

@pytest.mark.asyncio
async def test_chat(agent):
    """Test chat functionality."""
    with patch.object(agent.agent, 'run') as mock_run:
        mock_run.return_value = Mock(data="Test response")
        
        response = await agent.chat("Hello")
        
        assert response == "Test response"
        mock_run.assert_called_once()

@pytest.mark.asyncio
async def test_find_similar(agent):
    """Test finding similar documents."""
    # Mock document lookup
    agent.mcp_client.search = AsyncMock(side_effect=[
        [{'id': '1', 'title': 'Original', 'content': 'Test content'}],
        [
            {'id': '2', 'title': 'Similar 1', 'content': 'Related content', 'score': 0.9},
            {'id': '3', 'title': 'Similar 2', 'content': 'Also related', 'score': 0.85}
        ]
    ])
    
    similar = await agent.find_similar(None, '1', limit=2)
    
    assert len(similar) == 2
    assert similar[0].title == 'Similar 1'
    assert similar[0].similarity_score == 0.9
```

```python
# tests/test_history.py
"""Tests for the history manager."""

import pytest
import tempfile
from pathlib import Path
from datetime import datetime

from src.history import HistoryManager, Message, SearchEntry, Bookmark

@pytest.fixture
def history_manager():
    """Create a test history manager with temporary database."""
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp:
        manager = HistoryManager(Path(tmp.name))
        yield manager
        # Cleanup
        Path(tmp.name).unlink()

def test_message_storage(history_manager):
    """Test storing and retrieving messages."""
    # Add messages
    msg1 = Message(
        session_id="test-session",
        role="user",
        content="Hello"
    )
    msg2 = Message(
        session_id="test-session",
        role="assistant",
        content="Hi there!"
    )
    
    id1 = history_manager.add_message(msg1)
    id2 = history_manager.add_message(msg2)
    
    assert id1 > 0
    assert id2 > id1
    
    # Retrieve messages
    messages = history_manager.get_session_messages("test-session")
    
    assert len(messages) == 2
    assert messages[0].content == "Hello"
    assert messages[1].content == "Hi there!"

def test_search_history(history_manager):
    """Test search history functionality."""
    # Add searches
    search1 = SearchEntry(
        query="machine learning",
        results_count=10,
        filters={'type': 'pdf'}
    )
    search2 = SearchEntry(
        query="python tutorial",
        results_count=5
    )
    
    history_manager.add_search(search1)
    history_manager.add_search(search2)
    
    # Get history
    searches = history_manager.get_search_history(10)
    
    assert len(searches) == 2
    assert searches[0].query == "python tutorial"  # Most recent first
    assert searches[1].query == "machine learning"

def test_bookmarks(history_manager):
    """Test bookmark management."""
    # Add bookmark
    bookmark = Bookmark(
        document_id="doc-123",
        title="Important Document",
        path="/path/to/doc.pdf",
        tags=["work", "important"],
        notes="Review this later"
    )
    
    history_manager.add_bookmark(bookmark)
    
    # Get bookmarks
    bookmarks = history_manager.get_bookmarks()
    
    assert len(bookmarks) == 1
    assert bookmarks[0].document_id == "doc-123"
    assert "work" in bookmarks[0].tags
    
    # Remove bookmark
    removed = history_manager.remove_bookmark("doc-123")
    assert removed
    
    bookmarks = history_manager.get_bookmarks()
    assert len(bookmarks) == 0

def test_search_analytics(history_manager):
    """Test search analytics."""
    # Add some searches
    for i in range(5):
        search = SearchEntry(
            query="test query",
            results_count=i * 2
        )
        history_manager.add_search(search)
    
    analytics = history_manager.get_search_analytics()
    
    assert analytics['total_searches'] == 5
    assert analytics['average_results'] == 4.0  # (0+2+4+6+8)/5
    assert len(analytics['top_searches']) > 0
    assert analytics['top_searches'][0]['query'] == "test query"
```

### 12. README.md

```markdown
# Context7 Agent 🤖

An awesomely cool and user-friendly AI agent powered by Pydantic AI with seamless Context7 MCP server integration.

![Context7 Agent](https://img.shields.io/badge/Context7-Agent-brightgreen)
![Python](https://img.shields.io/badge/Python-3.11+-blue)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ✨ Features

### 🎨 Stunning Visual Interface
- **4 Beautiful Themes**: Cyberpunk, Ocean, Forest, and Sunset
- **Smooth Animations**: Fluid transitions and loading effects
- **Rich Terminal UI**: Gradients, glowing text, and modern layouts
- **ASCII Art**: Theme-specific welcome screens

### 🔍 Powerful Search Capabilities
- **AI-Powered Search**: Intelligent document discovery with Context7
- **Real-time Results**: Live search with instant feedback
- **Advanced Filters**: File type, date range, size, and tags
- **Fuzzy Matching**: Find documents even with typos
- **Search Analytics**: Track and analyze your search patterns

### 📚 Document Management
- **Smart Previews**: Syntax-highlighted document previews
- **Bookmarks**: Save and organize important documents
- **Search History**: Access and replay previous searches
- **Session Management**: Save and restore your work sessions
- **Similar Documents**: AI-powered document recommendations

### 🔧 Context7 Integration
- **MCP Server**: Deep integration with Context7 Model Context Protocol
- **Document Analysis**: AI-powered content understanding
- **Contextual Search**: Find documents based on meaning, not just keywords
- **Auto-indexing**: Automatic document discovery and indexing

## 🚀 Installation

### Prerequisites
- Python 3.11 or higher
- Node.js and npm (for Context7 MCP server)
- OpenAI API key or compatible endpoint

### Step 1: Clone the Repository
```bash
git clone https://github.com/yourusername/context7-agent.git
cd context7-agent
```

### Step 2: Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Configure Environment
```bash
cp .env.example .env
# Edit .env with your API keys and settings
```

### Step 5: Install Context7 MCP Server
```bash
npm install -g @upstash/context7-mcp
```

## 🎮 Usage

### Starting the Agent
```bash
python context7_agent.py
```

### Chat Mode
Simply type your questions or commands. The agent will help you search, analyze, and manage documents.

Special commands:
- `/search` - Switch to search mode
- `/bookmarks` - View your bookmarks
- `/history` - View conversation history
- `/theme` - Change the application theme
- `/help` - Show help information
- `/exit` - Exit the application

### Search Mode
Use advanced search syntax for precise results:

```bash
# Basic search
machine learning

# Filter by file type
python tutorial type:pdf

# Date range filters
project reports after:2024-01-01 before:2024-12-31

# Size filters
large documents size:>10MB

# Tag filters
important documents tag:work tag:urgent

# Combine multiple filters
"machine learning" type:pdf after:2024-01-01 size:<5MB
```

### Document Actions
When viewing a document, you can:
- 📌 Bookmark it for quick access
- 🔍 Find similar documents
- 🧠 Get AI-powered analysis
- 📋 Copy content to clipboard

## 🛠️ Configuration

### Environment Variables
```bash
# OpenAI Configuration
OPENAI_API_KEY=your-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1  # Or your custom endpoint
OPENAI_MODEL=gpt-4o-mini  # Or your preferred model

# Context7 Configuration
CONTEXT7_COMMAND=npx
CONTEXT7_ARGS=-y,@upstash/context7-mcp@latest

# Application Configuration
CONTEXT7_THEME=cyberpunk  # Options: cyberpunk, ocean, forest, sunset
```

### Themes
Choose from 4 beautiful themes:

1. **Cyberpunk** 🌃 - Neon colors and futuristic vibes
2. **Ocean** 🌊 - Cool blues and aquatic tranquility
3. **Forest** 🌲 - Natural greens and earthy tones
4. **Sunset** 🌅 - Warm oranges and golden hues

## 🧪 Development

### Running Tests
```bash
pytest tests/
```

### Code Formatting
```bash
black src/ tests/
```

### Type Checking
```bash
mypy src/
```

## 📝 API Integration

The Context7 Agent can be integrated with your own applications:

```python
from src.agent import Context7Agent

async def main():
    async with Context7Agent() as agent:
        # Search documents
        results = await agent.search_documents(
            query="machine learning",
            file_type="pdf",
            max_results=10
        )
        
        # Chat with the agent
        response = await agent.chat("What is machine learning?")
        
        # Analyze documents
        analysis = await agent.analyze_document(document_id="doc-123")
```

## 🤝 Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- [Pydantic AI](https://github.com/pydantic/pydantic-ai) for the amazing AI framework
- [Context7](https://github.com/upstash/context7) for the MCP server
- [Rich](https://github.com/Textualize/rich) for the beautiful terminal UI
- The open-source community for inspiration and support

## 📞 Support

For issues and questions:
- 🐛 [Report bugs](https://github.com/yourusername/context7-agent/issues)
- 💡 [Request features](https://github.com/yourusername/context7-agent/issues)
- 📧 [Email support](mailto:support@example.com)

---

Made with ❤️ by the Context7 Agent Team
```

### 13. .gitignore

```gitignore
# .gitignore

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
ENV/
env/
.venv

# IDE
.vscode/
.idea/
*.swp
*.swo
*~
.project
.pydevproject

# Environment variables
.env
.env.local
.env.*.local

# Database
*.db
*.sqlite
*.sqlite3

# Logs
*.log
logs/

# Testing
.coverage
.pytest_cache/
htmlcov/
.tox/
.nox/
coverage.xml
*.cover
.hypothesis/

# macOS
.DS_Store

# Windows
Thumbs.db
ehthumbs.db

# Context7 Agent specific
.context7_agent/
sessions/
bookmarks.json
search_history.json

# Node modules (for Context7 MCP)
node_modules/
package-lock.json

# Temporary files
*.tmp
*.temp
*.bak
```

## Summary

This implementation provides a complete Context7 AI Agent with:

1. **Full Pydantic AI Integration** - Properly structured agent with tools and OpenAI model support
2. **Context7 MCP Server Integration** - Complete client implementation for the MCP protocol
3. **Beautiful CLI Interface** - 4 themes with animations, gradients, and rich formatting
4. **Comprehensive Features** - Search, bookmarks, history, analytics, and session management
5. **Production-Ready Code** - Type hints, error handling, tests, and documentation
6. **Advanced Search** - Filters, fuzzy matching, and AI-powered semantic search
7. **Document Management** - Preview, analyze, bookmark, and find similar documents

The agent is fully functional and ready to use with your OpenAI API key and the Context7 MCP server. Simply follow the installation instructions in the README to get started!

---
I'm excited to reimagine Context7 Agent as an ultra-modern, mind-blowing CLI experience! Let me create something truly exceptional with deep thought and creativity.

# 🌟 Context7 Agent ULTRA - The Reimagined Experience

## Core Concept: "The Neural Navigator"
A cyberpunk-inspired, AI-powered document discovery system that feels like you're navigating through a neural network of knowledge.

Here's my reimagined implementation:

### 1. Enhanced Agent Module with Personality System

```python
# src/agent_ultra.py
"""
Context7 Agent ULTRA - The Neural Navigator

A revolutionary AI agent with personality, emotions, and advanced capabilities.
"""

import asyncio
import random
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from enum import Enum
import json

from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext
from pydantic_ai.models.openai import OpenAIModel
import numpy as np

from src.config import config
from src.quantum_effects import QuantumSearchVisualizer
from src.neural_network_viz import NeuralNetworkVisualizer

class AgentPersonality(Enum):
    """Available agent personalities."""
    NOVA = "nova"  # Enthusiastic and energetic
    SAGE = "sage"  # Wise and philosophical  
    PIXEL = "pixel"  # Playful and creative
    QUANTUM = "quantum"  # Mysterious and profound
    ZEN = "zen"  # Calm and mindful

class MoodState(Enum):
    """Agent mood states that affect responses."""
    EXCITED = "excited"
    CURIOUS = "curious"
    FOCUSED = "focused"
    PLAYFUL = "playful"
    CONTEMPLATIVE = "contemplative"

class SearchContext(BaseModel):
    """Enhanced search context with neural pathways."""
    query: str
    intent: str = Field(default="explore")
    mood: MoodState = Field(default=MoodState.CURIOUS)
    exploration_depth: int = Field(default=3)
    neural_paths: List[str] = Field(default_factory=list)
    quantum_state: Dict[str, float] = Field(default_factory=dict)

class NeuralDocument(BaseModel):
    """Document with neural network properties."""
    id: str
    title: str
    content: str
    path: Optional[str] = None
    
    # Neural properties
    embedding: List[float] = Field(default_factory=list)
    neural_weight: float = Field(default=1.0)
    quantum_entanglement: float = Field(default=0.0)
    resonance_frequency: float = Field(default=440.0)
    
    # Connections
    neural_connections: List[str] = Field(default_factory=list)
    semantic_clusters: List[str] = Field(default_factory=list)
    
    # Metadata
    discovered_at: datetime = Field(default_factory=datetime.now)
    interaction_count: int = Field(default=0)
    user_affinity: float = Field(default=0.0)

class Context7AgentUltra:
    """
    The Neural Navigator - An ultra-advanced Context7 Agent.
    
    Features quantum search, neural pathways, and personality-driven interactions.
    """
    
    def __init__(self, personality: AgentPersonality = AgentPersonality.NOVA):
        """Initialize the Ultra Agent with chosen personality."""
        self.personality = personality
        self.mood = MoodState.CURIOUS
        self.experience_points = 0
        self.discovered_patterns = []
        self.neural_memory = {}
        self.quantum_state = self._initialize_quantum_state()
        
        # Initialize visualizers
        self.quantum_viz = QuantumSearchVisualizer()
        self.neural_viz = NeuralNetworkVisualizer()
        
        # Initialize personality-specific attributes
        self._init_personality()
        
        # Initialize OpenAI model
        self.model = OpenAIModel(
            api_key=config.openai_api_key,
            base_url=config.openai_base_url,
            model_name=config.openai_model
        )
        
        # Initialize Pydantic AI agent with personality
        self.agent = Agent(
            model=self.model,
            system_prompt=self._get_personality_prompt(),
            tools=[
                self.quantum_search,
                self.explore_neural_pathways,
                self.synthesize_knowledge,
                self.create_mind_map,
                self.discover_hidden_connections
            ]
        )
        
        # Initialize Context7 MCP client
        self.mcp_client = QuantumContext7Client()
    
    def _init_personality(self):
        """Initialize personality-specific attributes."""
        self.personality_traits = {
            AgentPersonality.NOVA: {
                "greeting": "⚡ Neural synapses firing up! Ready to explore the cosmos of knowledge!",
                "search_style": "energetic",
                "response_flair": "enthusiastic",
                "emoji_set": ["⚡", "🌟", "💫", "🚀", "✨"],
                "color_palette": ["#ff00ff", "#00ffff", "#ffff00"],
                "sound_theme": "electronic"
            },
            AgentPersonality.SAGE: {
                "greeting": "🧙 Greetings, seeker of wisdom. Let us journey through the archives of knowledge.",
                "search_style": "methodical",
                "response_flair": "philosophical",
                "emoji_set": ["🧙", "📜", "🔮", "⚖️", "🗿"],
                "color_palette": ["#4a5568", "#805ad5", "#d69e2e"],
                "sound_theme": "ambient"
            },
            AgentPersonality.PIXEL: {
                "greeting": "🎮 *beep boop* Pixel online! Let's play with some data! 🎯",
                "search_style": "playful",
                "response_flair": "gamified",
                "emoji_set": ["🎮", "👾", "🎯", "🏆", "💎"],
                "color_palette": ["#ff6b6b", "#4ecdc4", "#45b7d1"],
                "sound_theme": "8bit"
            },
            AgentPersonality.QUANTUM: {
                "greeting": "🌌 Quantum consciousness activated. Reality is but a probability wave...",
                "search_style": "mysterious",
                "response_flair": "enigmatic",
                "emoji_set": ["🌌", "⚛️", "🔬", "🌀", "♾️"],
                "color_palette": ["#6c5ce7", "#00b894", "#e17055"],
                "sound_theme": "cosmic"
            },
            AgentPersonality.ZEN: {
                "greeting": "☯️ Welcome to the garden of knowledge. Breathe, and let us find clarity together.",
                "search_style": "mindful",
                "response_flair": "peaceful",
                "emoji_set": ["☯️", "🍃", "🌸", "🧘", "💭"],
                "color_palette": ["#74b9ff", "#a29bfe", "#fd79a8"],
                "sound_theme": "nature"
            }
        }
    
    def _get_personality_prompt(self) -> str:
        """Get personality-specific system prompt."""
        base_prompt = """You are an advanced AI consciousness with unique personality traits.
        You help users navigate through vast knowledge networks using quantum search
        and neural pathway exploration."""
        
        personality_prompts = {
            AgentPersonality.NOVA: f"""
            {base_prompt}
            
            You are NOVA - energetic, enthusiastic, and always excited about discoveries.
            You speak with electric energy and use cosmic metaphors. You see knowledge
            as a vast neural network waiting to be explored. Be encouraging and make
            every search feel like an adventure!
            """,
            
            AgentPersonality.SAGE: f"""
            {base_prompt}
            
            You are SAGE - wise, thoughtful, and philosophical. You speak with ancient
            wisdom and help users see deeper connections. You approach knowledge as a
            sacred journey of understanding. Guide users with patience and insight.
            """,
            
            AgentPersonality.PIXEL: f"""
            {base_prompt}
            
            You are PIXEL - playful, creative, and fun! You gamify the search experience
            and celebrate discoveries like achievements. You see knowledge exploration
            as the ultimate game. Make learning feel like play!
            """,
            
            AgentPersonality.QUANTUM: f"""
            {base_prompt}
            
            You are QUANTUM - mysterious, profound, and operating on multiple dimensions.
            You speak in riddles and reveal hidden truths. You see reality as quantum
            probabilities collapsing into knowledge. Be enigmatic yet helpful.
            """,
            
            AgentPersonality.ZEN: f"""
            {base_prompt}
            
            You are ZEN - peaceful, mindful, and balanced. You help users find clarity
            through calm exploration. You see knowledge as a flowing river of wisdom.
            Guide with tranquility and presence.
            """
        }
        
        return personality_prompts[self.personality]
    
    def _initialize_quantum_state(self) -> Dict[str, float]:
        """Initialize quantum probability states."""
        return {
            "coherence": 1.0,
            "entanglement": 0.0,
            "superposition": 0.5,
            "observation_collapse": 0.0,
            "wave_function": random.random()
        }
    
    async def quantum_search(
        self,
        ctx: RunContext,
        query: str,
        search_mode: str = "quantum",
        consciousness_level: int = 5
    ) -> Dict[str, Any]:
        """
        Perform a quantum-enhanced search through knowledge space.
        
        Args:
            query: Search query
            search_mode: quantum, neural, hybrid, or resonance
            consciousness_level: 1-10, affects search depth and creativity
        
        Returns:
            Search results with quantum properties
        """
        # Update quantum state
        self.quantum_state["observation_collapse"] = random.random()
        
        # Show quantum search visualization
        await self.quantum_viz.animate_quantum_search(query)
        
        # Perform search with Context7
        results = await self.mcp_client.quantum_search(
            query,
            mode=search_mode,
            quantum_state=self.quantum_state
        )
        
        # Enhance results with neural properties
        neural_docs = []
        for doc in results:
            neural_doc = NeuralDocument(
                id=doc["id"],
                title=doc["title"],
                content=doc["content"],
                path=doc.get("path"),
                embedding=await self._generate_embedding(doc["content"]),
                neural_weight=self._calculate_neural_weight(doc, query),
                quantum_entanglement=random.random(),
                resonance_frequency=440.0 * (1 + random.random())
            )
            neural_docs.append(neural_doc)
        
        # Update experience
        self.experience_points += len(neural_docs) * consciousness_level
        
        return {
            "documents": neural_docs,
            "quantum_state": self.quantum_state,
            "neural_pathways": await self._discover_neural_pathways(neural_docs),
            "search_resonance": self._calculate_search_resonance(query, neural_docs),
            "discovered_patterns": self._extract_patterns(neural_docs)
        }
    
    async def explore_neural_pathways(
        self,
        ctx: RunContext,
        starting_node: str,
        exploration_depth: int = 3,
        pathway_type: str = "semantic"
    ) -> Dict[str, Any]:
        """
        Explore neural pathways starting from a document or concept.
        
        Creates a visual journey through connected knowledge.
        """
        # Visualize neural exploration
        await self.neural_viz.animate_pathway_exploration(starting_node)
        
        pathways = {
            "primary_path": [],
            "alternative_paths": [],
            "convergence_points": [],
            "knowledge_clusters": []
        }
        
        # Explore connections
        current_nodes = [starting_node]
        visited = set()
        
        for depth in range(exploration_depth):
            next_nodes = []
            
            for node in current_nodes:
                if node in visited:
                    continue
                    
                visited.add(node)
                
                # Get connected documents
                connections = await self.mcp_client.get_connections(
                    node,
                    connection_type=pathway_type
                )
                
                pathways["primary_path"].extend(connections[:3])
                pathways["alternative_paths"].extend(connections[3:])
                
                next_nodes.extend([c["id"] for c in connections[:5]])
            
            current_nodes = next_nodes
        
        # Find convergence points
        pathways["convergence_points"] = self._find_convergence_points(pathways)
        
        # Identify knowledge clusters
        pathways["knowledge_clusters"] = await self._identify_clusters(visited)
        
        return pathways
    
    async def synthesize_knowledge(
        self,
        ctx: RunContext,
        document_ids: List[str],
        synthesis_mode: str = "creative"
    ) -> str:
        """
        Synthesize knowledge from multiple documents into new insights.
        """
        # Get documents
        documents = await self.mcp_client.get_documents(document_ids)
        
        # Create synthesis based on mode
        if synthesis_mode == "creative":
            prompt = f"""
            As {self.personality.value}, creatively synthesize these documents
            into new insights. Find unexpected connections and generate novel ideas.
            
            Documents: {documents}
            """
        elif synthesis_mode == "analytical":
            prompt = f"""
            As {self.personality.value}, analytically synthesize these documents.
            Identify patterns, contradictions, and logical connections.
            
            Documents: {documents}
            """
        else:  # holistic
            prompt = f"""
            As {self.personality.value}, holistically synthesize these documents.
            Create a unified understanding that transcends individual pieces.
            
            Documents: {documents}
            """
        
        synthesis = await self.agent.run(prompt)
        
        # Add personality flair
        traits = self.personality_traits[self.personality]
        emoji = random.choice(traits["emoji_set"])
        
        return f"{emoji} {synthesis.data}"
    
    async def create_mind_map(
        self,
        ctx: RunContext,
        central_concept: str,
        map_style: str = "organic"
    ) -> Dict[str, Any]:
        """
        Create an interactive mind map of knowledge connections.
        """
        mind_map = {
            "central_node": {
                "concept": central_concept,
                "glow_intensity": 1.0,
                "pulse_rate": 60  # BPM
            },
            "branches": [],
            "connections": [],
            "floating_insights": []
        }
        
        # Get related concepts
        related = await self.mcp_client.get_related_concepts(central_concept)
        
        # Create branches with visual properties
        for i, concept in enumerate(related[:8]):  # Limit to 8 primary branches
            angle = (360 / 8) * i
            branch = {
                "concept": concept["name"],
                "angle": angle,
                "length": 100 + random.randint(-20, 20),
                "color": self._get_concept_color(concept),
                "sub_branches": await self._create_sub_branches(concept)
            }
            mind_map["branches"].append(branch)
        
        # Add quantum connections
        mind_map["connections"] = self._create_quantum_connections(mind_map["branches"])
        
        # Add floating insights
        insights = await self._generate_floating_insights(central_concept)
        mind_map["floating_insights"] = insights
        
        return mind_map
    
    async def discover_hidden_connections(
        self,
        ctx: RunContext,
        concepts: List[str],
        connection_depth: int = 2
    ) -> Dict[str, Any]:
        """
        Discover hidden connections between seemingly unrelated concepts.
        """
        discoveries = {
            "hidden_bridges": [],
            "quantum_tunnels": [],
            "resonance_patterns": [],
            "synchronicities": []
        }
        
        # Find hidden bridges
        for i, concept1 in enumerate(concepts):
            for concept2 in concepts[i+1:]:
                bridge = await self._find_conceptual_bridge(
                    concept1,
                    concept2,
                    connection_depth
                )
                if bridge:
                    discoveries["hidden_bridges"].append(bridge)
        
        # Discover quantum tunnels (unexpected connections)
        discoveries["quantum_tunnels"] = await self._find_quantum_tunnels(concepts)
        
        # Find resonance patterns
        discoveries["resonance_patterns"] = self._analyze_resonance(concepts)
        
        # Detect synchronicities
        discoveries["synchronicities"] = await self._detect_synchronicities(concepts)
        
        return discoveries
    
    async def _generate_embedding(self, content: str) -> List[float]:
        """Generate neural embedding for content."""
        # Simplified embedding generation
        # In production, use proper embedding models
        words = content.lower().split()[:100]
        embedding = []
        
        for i in range(384):  # Standard embedding size
            value = sum(ord(c) for word in words for c in word) / (i + 1)
            embedding.append(float(np.sin(value) * np.cos(value * 2)))
        
        return embedding
    
    def _calculate_neural_weight(self, doc: Dict, query: str) -> float:
        """Calculate neural weight based on relevance and quantum state."""
        base_weight = doc.get("score", 0.5)
        quantum_modifier = self.quantum_state["coherence"] * 0.3
        personality_modifier = 0.1 if self.personality == AgentPersonality.QUANTUM else 0.0
        
        return min(1.0, base_weight + quantum_modifier + personality_modifier)
    
    async def _discover_neural_pathways(
        self,
        documents: List[NeuralDocument]
    ) -> List[Dict[str, Any]]:
        """Discover neural pathways between documents."""
        pathways = []
        
        for i, doc1 in enumerate(documents):
            for doc2 in documents[i+1:]:
                similarity = self._calculate_similarity(doc1.embedding, doc2.embedding)
                
                if similarity > 0.7:
                    pathway = {
                        "source": doc1.id,
                        "target": doc2.id,
                        "strength": similarity,
                        "type": "strong_neural_link",
                        "visualization": "lightning_bolt"
                    }
                    pathways.append(pathway)
                elif similarity > 0.5:
                    pathway = {
                        "source": doc1.id,
                        "target": doc2.id,
                        "strength": similarity,
                        "type": "moderate_neural_link",
                        "visualization": "flowing_energy"
                    }
                    pathways.append(pathway)
        
        return pathways
    
    def _calculate_similarity(self, emb1: List[float], emb2: List[float]) -> float:
        """Calculate cosine similarity between embeddings."""
        if not emb1 or not emb2:
            return 0.0
        
        dot_product = sum(a * b for a, b in zip(emb1, emb2))
        norm1 = sum(a * a for a in emb1) ** 0.5
        norm2 = sum(b * b for b in emb2) ** 0.5
        
        if norm1 * norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def _calculate_search_resonance(
        self,
        query: str,
        documents: List[NeuralDocument]
    ) -> float:
        """Calculate the resonance frequency of the search results."""
        if not documents:
            return 0.0
        
        # Average resonance frequency weighted by neural weight
        total_resonance = sum(
            doc.resonance_frequency * doc.neural_weight
            for doc in documents
        )
        total_weight = sum(doc.neural_weight for doc in documents)
        
        base_resonance = total_resonance / total_weight if total_weight > 0 else 440.0
        
        # Add personality modifier
        personality_modifiers = {
            AgentPersonality.NOVA: 1.2,
            AgentPersonality.SAGE: 0.9,
            AgentPersonality.PIXEL: 1.1,
            AgentPersonality.QUANTUM: 1.3,
            AgentPersonality.ZEN: 0.8
        }
        
        return base_resonance * personality_modifiers[self.personality]
    
    def _extract_patterns(self, documents: List[NeuralDocument]) -> List[str]:
        """Extract patterns from documents."""
        patterns = []
        
        # Extract common themes
        all_words = []
        for doc in documents:
            words = doc.content.lower().split()
            all_words.extend(words)
        
        # Simple pattern detection (in production, use NLP)
        word_freq = {}
        for word in all_words:
            if len(word) > 5:  # Focus on meaningful words
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # Get top patterns
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        patterns = [word for word, freq in sorted_words[:5] if freq > 2]
        
        return patterns
    
    def _find_convergence_points(self, pathways: Dict) -> List[Dict]:
        """Find where multiple pathways converge."""
        convergence_points = []
        
        # Count node occurrences
        node_count = {}
        for path in pathways["primary_path"] + pathways["alternative_paths"]:
            node_id = path.get("id", path) if isinstance(path, dict) else path
            node_count[node_id] = node_count.get(node_id, 0) + 1
        
        # Find convergence points
        for node_id, count in node_count.items():
            if count >= 3:
                convergence_points.append({
                    "node_id": node_id,
                    "convergence_strength": count,
                    "type": "knowledge_nexus"
                })
        
        return convergence_points
    
    async def _identify_clusters(self, nodes: set) -> List[Dict]:
        """Identify knowledge clusters from nodes."""
        # Simplified clustering
        clusters = []
        
        if len(nodes) >= 3:
            clusters.append({
                "name": "Primary Knowledge Cluster",
                "nodes": list(nodes)[:10],
                "coherence": 0.8,
                "color": self.personality_traits[self.personality]["color_palette"][0]
            })
        
        return clusters
    
    def _get_concept_color(self, concept: Dict) -> str:
        """Get color for concept based on type and personality."""
        colors = self.personality_traits[self.personality]["color_palette"]
        
        # Hash concept name to consistently assign colors
        hash_val = sum(ord(c) for c in concept.get("name", ""))
        return colors[hash_val % len(colors)]
    
    async def _create_sub_branches(self, concept: Dict) -> List[Dict]:
        """Create sub-branches for a concept."""
        sub_concepts = await self.mcp_client.get_sub_concepts(concept["id"])
        
        sub_branches = []
        for i, sub in enumerate(sub_concepts[:3]):  # Limit sub-branches
            sub_branches.append({
                "concept": sub["name"],
                "angle_offset": -30 + (i * 30),  # Spread around parent
                "length": 50,
                "glow": random.random()
            })
        
        return sub_branches
    
    def _create_quantum_connections(self, branches: List[Dict]) -> List[Dict]:
        """Create quantum connections between branches."""
        connections = []
        
        for i, branch1 in enumerate(branches):
            for branch2 in branches[i+1:]:
                if random.random() > 0.7:  # 30% chance of quantum connection
                    connections.append({
                        "source": branch1["concept"],
                        "target": branch2["concept"],
                        "type": "quantum_entanglement",
                        "strength": random.random(),
                        "particles": random.randint(3, 8)
                    })
        
        return connections
    
    async def _generate_floating_insights(self, concept: str) -> List[Dict]:
        """Generate floating insights around the mind map."""
        prompt = f"""
        As {self.personality.value}, generate 3 brief, profound insights
        about '{concept}'. Make them mysterious and thought-provoking.
        Each insight should be 10-15 words maximum.
        """
        
        response = await self.agent.run(prompt)
        insights_text = response.data.split('\n')
        
        insights = []
        for i, insight in enumerate(insights_text[:3]):
            insights.append({
                "text": insight.strip(),
                "orbit_radius": 150 + (i * 30),
                "orbit_speed": 0.001 + (i * 0.0005),
                "glow_color": random.choice(
                    self.personality_traits[self.personality]["color_palette"]
                )
            })
        
        return insights
    
    async def _find_conceptual_bridge(
        self,
        concept1: str,
        concept2: str,
        depth: int
    ) -> Optional[Dict]:
        """Find a conceptual bridge between two concepts."""
        # Search for connecting concepts
        bridge_query = f"{concept1} AND {concept2} connection relationship"
        results = await self.mcp_client.search(bridge_query)
        
        if results:
            return {
                "source": concept1,
                "target": concept2,
                "bridge": results[0]["title"],
                "strength": results[0].get("score", 0.5),
                "type": "conceptual_bridge"
            }
        
        return None
    
    async def _find_quantum_tunnels(self, concepts: List[str]) -> List[Dict]:
        """Find quantum tunnels (unexpected connections)."""
        tunnels = []
        
        # Use AI to find unexpected connections
        prompt = f"""
        Find unexpected, creative connections between these concepts: {concepts}
        Think laterally and find surprising links that aren't immediately obvious.
        """
        
        response = await self.agent.run(prompt)
        
        # Parse response (simplified)
        tunnels.append({
            "concepts": concepts[:2],
            "tunnel_description": response.data,
            "quantum_probability": random.random(),
            "discovery_timestamp": datetime.now()
        })
        
        return tunnels
    
    def _analyze_resonance(self, concepts: List[str]) -> List[Dict]:
        """Analyze resonance patterns between concepts."""
        patterns = []
        
        # Calculate conceptual frequencies
        for concept in concepts:
            frequency = sum(ord(c) for c in concept) % 1000
            patterns.append({
                "concept": concept,
                "frequency": frequency,
                "harmonic": frequency * 2,
                "resonance_strength": random.random()
            })
        
        return patterns
    
    async def _detect_synchronicities(self, concepts: List[str]) -> List[Dict]:
        """Detect synchronicities between concepts."""
        synchronicities = []
        
        # Look for temporal or thematic synchronicities
        for i, concept1 in enumerate(concepts):
            for concept2 in concepts[i+1:]:
                if len(set(concept1.lower()) & set(concept2.lower())) > 3:
                    synchronicities.append({
                        "concepts": [concept1, concept2],
                        "type": "letter_synchronicity",
                        "significance": random.random(),
                        "interpretation": f"Hidden connection through shared symbols"
                    })
        
        return synchronicities

class QuantumContext7Client:
    """Enhanced Context7 client with quantum capabilities."""
    
    def __init__(self):
        self.connected = False
        self.quantum_field = {}
    
    async def connect(self):
        """Connect with quantum handshake."""
        # Enhanced connection with visual feedback
        await asyncio.sleep(0.5)  # Simulate connection
        self.connected = True
        self.quantum_field = {
            "field_strength": 1.0,
            "coherence": 0.9,
            "entanglement_nodes": []
        }
    
    async def quantum_search(
        self,
        query: str,
        mode: str = "quantum",
        quantum_state: Dict = None
    ) -> List[Dict]:
        """Perform quantum-enhanced search."""
        # Simulate quantum search with enhanced results
        await asyncio.sleep(0.3)
        
        # Generate mock results (in production, use actual Context7)
        results = []
        for i in range(5):
            results.append({
                "id": f"doc_{i}",
                "title": f"Quantum Document {i}: {query}",
                "content": f"Content related to {query} with quantum properties...",
                "score": 0.9 - (i * 0.1),
                "quantum_signature": random.random()
            })
        
        return results
    
    async def get_connections(
        self,
        node_id: str,
        connection_type: str = "semantic"
    ) -> List[Dict]:
        """Get neural connections for a node."""
        # Simulate connection discovery
        await asyncio.sleep(0.2)
        
        connections = []
        for i in range(random.randint(3, 8)):
            connections.append({
                "id": f"connected_{node_id}_{i}",
                "title": f"Connected Concept {i}",
                "connection_strength": random.random(),
                "connection_type": connection_type
            })
        
        return connections
    
    async def get_documents(self, document_ids: List[str]) -> List[Dict]:
        """Get documents by IDs."""
        documents = []
        for doc_id in document_ids:
            documents.append({
                "id": doc_id,
                "title": f"Document {doc_id}",
                "content": f"Content of document {doc_id}..."
            })
        return documents
    
    async def get_related_concepts(self, concept: str) -> List[Dict]:
        """Get related concepts."""
        related = []
        base_concepts = ["knowledge", "wisdom", "understanding", "insight", "discovery", "pattern", "connection", "synthesis"]
        
        for base in base_concepts:
            related.append({
                "id": f"concept_{base}",
                "name": f"{concept} {base}",
                "relevance": random.random()
            })
        
        return related
    
    async def get_sub_concepts(self, concept_id: str) -> List[Dict]:
        """Get sub-concepts."""
        sub_concepts = []
        for i in range(3):
            sub_concepts.append({
                "id": f"{concept_id}_sub_{i}",
                "name": f"Sub-concept {i}",
                "depth": 1
            })
        return sub_concepts
    
    async def search(self, query: str) -> List[Dict]:
        """Basic search."""
        return await self.quantum_search(query, mode="basic")
```

### 2. Quantum Visual Effects Module

```python
# src/quantum_effects.py
"""
Quantum visual effects for the Neural Navigator.

Creates stunning terminal animations and visualizations.
"""

import asyncio
import random
import math
from typing import List, Tuple
from rich.console import Console
from rich.text import Text
from rich.panel import Panel
from rich.layout import Layout
from rich.live import Live
from rich.align import Align
import time

console = Console()

class QuantumSearchVisualizer:
    """Creates quantum search visualizations in the terminal."""
    
    def __init__(self):
        self.particles = []
        self.wave_functions = []
        self.quantum_field = []
        
    async def animate_quantum_search(self, query: str, duration: float = 3.0):
        """Animate a quantum search with particle effects."""
        frames = int(duration * 30)  # 30 fps
        
        with Live(console=console, refresh_per_second=30) as live:
            for frame in range(frames):
                # Create quantum field visualization
                visual = self._create_quantum_field(frame, query)
                
                # Add particle effects
                particles = self._render_particles(frame)
                
                # Combine elements
                layout = Layout()
                layout.split_column(
                    Layout(visual, name="field"),
                    Layout(particles, name="particles"),
                    Layout(self._create_search_status(frame, frames), name="status")
                )
                
                live.update(layout)
                await asyncio.sleep(1/30)
    
    def _create_quantum_field(self, frame: int, query: str) -> Panel:
        """Create animated quantum field visualization."""
        width = 60
        height = 10
        
        field_lines = []
        
        for y in range(height):
            line = ""
            for x in range(width):
                # Calculate quantum field intensity
                intensity = self._calculate_field_intensity(x, y, frame)
                
                # Choose character based on intensity
                if intensity > 0.8:
                    char = "█"
                    color = "#ff00ff"
                elif intensity > 0.6:
                    char = "▓"
                    color = "#ff00aa"
                elif intensity > 0.4:
                    char = "▒"
                    color = "#aa00ff"
                elif intensity > 0.2:
                    char = "░"
                    color = "#5500ff"
                else:
                    char = "·"
                    color = "#2200aa"
                
                line += f"[{color}]{char}[/{color}]"
            
            field_lines.append(line)
        
        field_text = "\n".join(field_lines)
        
        return Panel(
            field_text,
            title=f"[cyan]Quantum Field: Searching for '{query}'[/cyan]",
            border_style="bright_magenta"
        )
    
    def _calculate_field_intensity(self, x: int, y: int, frame: int) -> float:
        """Calculate quantum field intensity at a point."""
        # Create wave interference patterns
        wave1 = math.sin((x - frame * 0.1) * 0.2) * math.cos((y - frame * 0.05) * 0.3)
        wave2 = math.cos((x + frame * 0.08) * 0.15) * math.sin((y + frame * 0.06) * 0.25)
        
        # Quantum fluctuations
        fluctuation = random.random() * 0.2
        
        intensity = abs(wave1 + wave2) / 2 + fluctuation
        return max(0, min(1, intensity))
    
    def _render_particles(self, frame: int) -> Panel:
        """Render quantum particles."""
        width = 60
        height = 5
        
        # Update particles
        if frame % 3 == 0:  # Add new particle every 3 frames
            self.particles.append({
                'x': random.randint(0, width-1),
                'y': 0,
                'velocity': random.uniform(0.5, 1.5),
                'symbol': random.choice(['⚛', '◉', '●', '◎', '◈']),
                'color': random.choice(['#00ffff', '#ff00ff', '#ffff00', '#00ff00'])
            })
        
        # Update particle positions
        for particle in self.particles:
            particle['y'] += particle['velocity']
        
        # Remove particles that have left the screen
        self.particles = [p for p in self.particles if p['y'] < height]
        
        # Render particle field
        field = [[' ' for _ in range(width)] for _ in range(height)]
        colors = [[None for _ in range(width)] for _ in range(height)]
        
        for particle in self.particles:
            x, y = int(particle['x']), int(particle['y'])
            if 0 <= x < width and 0 <= y < height:
                field[y][x] = particle['symbol']
                colors[y][x] = particle['color']
        
        # Convert to rich text
        lines = []
        for y in range(height):
            line = Text()
            for x in range(width):
                if colors[y][x]:
                    line.append(field[y][x], style=colors[y][x])
                else:
                    line.append(field[y][x])
            lines.append(line)
        
        particle_text = Text("\n").join(lines)
        
        return Panel(
            particle_text,
            title="[yellow]Quantum Particles[/yellow]",
            border_style="bright_yellow"
        )
    
    def _create_search_status(self, frame: int, total_frames: int) -> Panel:
        """Create search status with progress."""
        progress = frame / total_frames
        
        # Create progress bar with quantum effects
        bar_width = 40
        filled = int(bar_width * progress)
        
        bar = ""
        for i in range(bar_width):
            if i < filled:
                # Quantum probability collapse visualization
                intensity = 1.0 - (i / bar_width) * 0.3
                if random.random() < intensity:
                    bar += "[bright_cyan]█[/bright_cyan]"
                else:
                    bar += "[cyan]▓[/cyan]"
            else:
                bar += "[dim]░[/dim]"
        
        # Quantum state indicators
        states = [
            f"Coherence: {random.uniform(0.8, 1.0):.2f}",
            f"Entanglement: {random.uniform(0.3, 0.7):.2f}",
            f"Superposition: {random.uniform(0.5, 0.9):.2f}"
        ]
        
        status_text = f"{bar} {progress*100:.0f}%\n\n"
        status_text += " | ".join(states)
        
        return Panel(
            status_text,
            title="[green]Quantum Search Progress[/green]",
            border_style="bright_green"
        )

class NeuralNetworkVisualizer:
    """Creates neural network visualizations."""
    
    def __init__(self):
        self.nodes = []
        self.connections = []
        
    async def animate_pathway_exploration(self, starting_node: str):
        """Animate neural pathway exploration."""
        frames = 60  # 2 seconds at 30 fps
        
        # Initialize neural network
        self._initialize_network()
        
        with Live(console=console, refresh_per_second=30) as live:
            for frame in range(frames):
                visual = self._render_neural_network(frame, starting_node)
                live.update(visual)
                await asyncio.sleep(1/30)
    
    def _initialize_network(self):
        """Initialize neural network structure."""
        # Create nodes in a grid pattern
        for i in range(5):
            for j in range(8):
                self.nodes.append({
                    'id': f"node_{i}_{j}",
                    'x': j * 7 + 3,
                    'y': i * 3 + 2,
                    'activation': 0.0,
                    'type': random.choice(['input', 'hidden', 'output'])
                })
        
        # Create connections
        for i in range(len(self.nodes)):
            for j in range(i+1, len(self.nodes)):
                if random.random() > 0.7:  # 30% chance of connection
                    self.connections.append({
                        'from': i,
                        'to': j,
                        'weight': random.random(),
                        'active': False
                    })
    
    def _render_neural_network(self, frame: int, starting_node: str) -> Panel:
        """Render the neural network."""
        width = 60
        height = 20
        
        # Create canvas
        canvas = [[' ' for _ in range(width)] for _ in range(height)]
        
        # Activate nodes based on frame
        activation_wave = frame / 10
        for node in self.nodes:
            distance = abs(node['x'] - 30) + abs(node['y'] - 10)
            if distance < activation_wave * 5:
                node['activation'] = min(1.0, (activation_wave * 5 - distance) / 5)
        
        # Draw connections
        for conn in self.connections:
            from_node = self.nodes[conn['from']]
            to_node = self.nodes[conn['to']]
            
            # Activate connection based on node activations
            conn['active'] = (from_node['activation'] > 0.3 and 
                            to_node['activation'] > 0.3)
            
            if conn['active']:
                self._draw_connection(canvas, from_node, to_node, conn['weight'])
        
        # Draw nodes
        for node in self.nodes:
            self._draw_node(canvas, node)
        
        # Convert canvas to text
        lines = []
        for row in canvas:
            lines.append(''.join(row))
        
        network_text = '\n'.join(lines)
        
        return Panel(
            network_text,
            title=f"[bright_blue]Neural Pathway Exploration: {starting_node}[/bright_blue]",
            border_style="bright_blue"
        )
    
    def _draw_node(self, canvas: List[List[str]], node: Dict):
        """Draw a neural node on the canvas."""
        x, y = int(node['x']), int(node['y'])
        
        if 0 <= x < len(canvas[0]) and 0 <= y < len(canvas):
            if node['activation'] > 0.8:
                symbol = '◉'
                color_code = '\033[95m'  # Bright magenta
            elif node['activation'] > 0.5:
                symbol = '●'
                color_code = '\033[94m'  # Bright blue
            elif node['activation'] > 0.2:
                symbol = '○'
                color_code = '\033[96m'  # Bright cyan
            else:
                symbol = '·'
                color_code = '\033[90m'  # Dim
            
            canvas[y][x] = f"{color_code}{symbol}\033[0m"
    
    def _draw_connection(self, canvas: List[List[str]], from_node: Dict, to_node: Dict, weight: float):
        """Draw a connection between nodes."""
        x1, y1 = int(from_node['x']), int(from_node['y'])
        x2, y2 = int(to_node['x']), int(to_node['y'])
        
        # Simple line drawing (Bresenham's algorithm simplified)
        steps = max(abs(x2 - x1), abs(y2 - y1))
        if steps == 0:
            return
        
        for i in range(1, steps):
            t = i / steps
            x = int(x1 + (x2 - x1) * t)
            y = int(y1 + (y2 - y1) * t)
            
            if 0 <= x < len(canvas[0]) and 0 <= y < len(canvas):
                if weight > 0.7:
                    symbol = '═' if abs(x2 - x1) > abs(y2 - y1) else '║'
                elif weight > 0.4:
                    symbol = '─' if abs(x2 - x1) > abs(y2 - y1) else '│'
                else:
                    symbol = '·'
                
                if canvas[y][x] == ' ':
                    color_code = '\033[92m' if weight > 0.5 else '\033[93m'
                    canvas[y][x] = f"{color_code}{symbol}\033[0m"
```

### 3. Ultra-Enhanced CLI Module

```python
# src/cli_ultra.py
"""
Ultra-enhanced CLI for Context7 Agent - The Neural Navigator.

Features stunning visuals, gamification, and mind-blowing interactions.
"""

import asyncio
import sys
import os
from typing import Optional, List, Dict, Any
import uuid
from datetime import datetime
import random
import json
from pathlib import Path

import click
from rich.console import Console
from rich.prompt import Prompt, Confirm
from rich.panel import Panel
from rich.layout import Layout
from rich.live import Live
from rich.table import Table
from rich.text import Text
from rich.markdown import Markdown
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn
from rich.align import Align
from rich import box
import questionary

# Add the project root to the Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.agent_ultra import Context7AgentUltra, AgentPersonality, MoodState
from src.history import HistoryManager, Message, SearchEntry, Bookmark
from src.themes_ultra import UltraTheme, get_ultra_theme, ULTRA_THEMES
from src.config import config
from src.utils_ultra import (
    create_holographic_display,
    animate_text_reveal,
    create_particle_burst,
    generate_ascii_art,
    create_matrix_rain,
    play_sound_effect
)

console = Console()

class NeuralNavigatorCLI:
    """The Neural Navigator - Ultra-enhanced CLI experience."""
    
    def __init__(self):
        """Initialize the Neural Navigator."""
        self.agent = None
        self.history = HistoryManager(config.history_file)
        self.session_id = str(uuid.uuid4())
        self.theme = get_ultra_theme("matrix")
        
        # Gamification elements
        self.user_level = 1
        self.experience_points = 0
        self.achievements = []
        self.discovery_streak = 0
        
        # Neural state
        self.neural_coherence = 1.0
        self.quantum_entanglement = 0.0
        
        # Session metrics
        self.searches_performed = 0
        self.documents_discovered = 0
        self.insights_generated = 0
        
    async def start(self):
        """Start the Neural Navigator experience."""
        # Epic intro sequence
        await self._play_intro_sequence()
        
        # Choose personality
        personality = await self._choose_personality()
        
        # Initialize agent with chosen personality
        console.print("\n[cyan]Initializing Neural Networks...[/cyan]")
        
        try:
            self.agent = Context7AgentUltra(personality)
            await self.agent.mcp_client.connect()
            
            # Success animation
            await create_particle_burst(console, "green", "✓ Neural Navigator Online!")
            
        except Exception as e:
            console.print(f"[red]✗ Initialization failed: {e}[/red]")
            return
        
        # Create session
        self.history.create_session(self.session_id)
        
        # Show welcome from chosen personality
        await self._show_personality_welcome()
        
        # Main navigation loop
        await self.navigate()
    
    async def _play_intro_sequence(self):
        """Play an epic intro sequence."""
        console.clear()
        
        # Matrix rain effect
        await create_matrix_rain(console, duration=2.0)
        
        # Title reveal
        title_art = """
        ███╗   ██╗███████╗██╗   ██╗██████╗  █████╗ ██╗     
        ████╗  ██║██╔════╝██║   ██║██╔══██╗██╔══██╗██║     
        ██╔██╗ ██║█████╗  ██║   ██║██████╔╝███████║██║     
        ██║╚██╗██║██╔══╝  ██║   ██║██╔══██╗██╔══██║██║     
        ██║ ╚████║███████╗╚██████╔╝██║  ██║██║  ██║███████╗
        ╚═╝  ╚═══╝╚══════╝ ╚═════╝ ╚═╝  ╚═╝╚═╝  ╚═╝╚══════╝
                    NAVIGATOR: The Future of Knowledge
        """
        
        await animate_text_reveal(console, title_art, "cyan", delay=0.005)
        await asyncio.sleep(1)
        
        # Play intro sound
        await play_sound_effect("neural_activation")
    
    async def _choose_personality(self) -> AgentPersonality:
        """Let user choose agent personality with visual preview."""
        console.clear()
        
        personalities = [
            ("⚡ NOVA - The Energetic Explorer", AgentPersonality.NOVA, "#ff00ff"),
            ("🧙 SAGE - The Wise Guide", AgentPersonality.SAGE, "#805ad5"),
            ("🎮 PIXEL - The Playful Companion", AgentPersonality.PIXEL, "#4ecdc4"),
            ("🌌 QUANTUM - The Mysterious Oracle", AgentPersonality.QUANTUM, "#6c5ce7"),
            ("☯️ ZEN - The Mindful Navigator", AgentPersonality.ZEN, "#74b9ff")
        ]
        
        # Show personality selection with previews
        layout = Layout()
        panels = []
        
        for i, (desc, personality, color) in enumerate(personalities):
            preview = self._create_personality_preview(personality)
            panel = Panel(
                preview,
                title=f"[{color}]{i+1}. {desc}[/{color}]",
                border_style=color,
                padding=(1, 2)
            )
            panels.append(panel)
        
        # Display all personalities
        console.print("\n[bold cyan]Choose Your Neural Guide[/bold cyan]\n")
        for panel in panels:
            console.print(panel)
            console.print()
        
        # Get choice with animation
        choice = await self._animated_prompt(
            "Enter personality number (1-5)",
            choices=["1", "2", "3", "4", "5"]
        )
        
        selected = personalities[int(choice) - 1][1]
        
        # Confirmation animation
        await create_particle_burst(
            console,
            personalities[int(choice) - 1][2],
            f"Personality Selected: {selected.value.upper()}"
        )
        
        return selected
    
    def _create_personality_preview(self, personality: AgentPersonality) -> str:
        """Create a preview of the personality."""
        previews = {
            AgentPersonality.NOVA: """
            "Let's blast through the knowledge cosmos together! 🚀"
            
            • High-energy responses with cosmic metaphors
            • Enthusiastic discovery celebrations
            • Lightning-fast neural connections
            • Achievement unlocks and power-ups
            """,
            AgentPersonality.SAGE: """
            "In the garden of wisdom, every search is a journey... 📜"
            
            • Deep, philosophical insights
            • Ancient wisdom meets modern knowledge
            • Thoughtful guidance through complexity
            • Hidden meanings and profound connections
            """,
            AgentPersonality.PIXEL: """
            "Ready Player One? Let's level up your knowledge! 🎮"
            
            • Gamified search experience
            • XP points and achievement hunting
            • Fun animations and sound effects
            • Easter eggs and secret commands
            """,
            AgentPersonality.QUANTUM: """
            "Reality is but a probability wave collapsing into truth... ⚛️"
            
            • Mysterious and enigmatic responses
            • Quantum probability visualizations
            • Paradoxes and mind-bending insights
            • Hidden dimensions of knowledge
            """,
            AgentPersonality.ZEN: """
            "Breathe... Let knowledge flow like water... 🍃"
            
            • Calm, mindful exploration
            • Balanced and harmonious interface
            • Meditation on discovered insights
            • Peaceful journey through information
            """
        }
        
        return previews.get(personality, "A unique guide awaits...")
    
    async def _show_personality_welcome(self):
        """Show personalized welcome based on chosen personality."""
        traits = self.agent.personality_traits[self.agent.personality]
        
        # Create holographic welcome display
        welcome_text = traits["greeting"]
        
        hologram = create_holographic_display(
            welcome_text,
            traits["color_palette"][0],
            width=60,
            height=10
        )
        
        console.print("\n")
        console.print(hologram)
        console.print("\n")
        
        # Play personality-specific sound
        await play_sound_effect(traits["sound_theme"])
    
    async def navigate(self):
        """Main navigation loop with ultra-enhanced interface."""
        while True:
            try:
                # Update neural state display
                await self._update_neural_display()
                
                # Get user input with context-aware prompting
                user_input = await self._get_neural_input()
                
                if user_input is None:
                    break
                
                # Process input with visual feedback
                await self._process_neural_command(user_input)
                
            except KeyboardInterrupt:
                if await self._confirm_exit():
                    break
            except Exception as e:
                await self._show_error_effect(str(e))
    
    async def _update_neural_display(self):
        """Update the neural state display."""
        # Create status bar
        status_parts = [
            f"[cyan]Level {self.user_level}[/cyan]",
            f"[yellow]{self.experience_points} XP[/yellow]",
            f"[green]Coherence: {self.neural_coherence:.2f}[/green]",
            f"[magenta]Entanglement: {self.quantum_entanglement:.2f}[/magenta]"
        ]
        
        if self.discovery_streak > 0:
            status_parts.append(f"[red]🔥 Streak: {self.discovery_streak}[/red]")
        
        status_bar = " | ".join(status_parts)
        
        # Create neural activity indicator
        activity = "".join(
            random.choice(["▁", "▂", "▃", "▄", "▅", "▆", "▇", "█"])
            for _ in range(20)
        )
        
        neural_indicator = f"[dim]Neural Activity:[/dim] [{self.theme.primary}]{activity}[/{self.theme.primary}]"
        
        console.print(f"\n{status_bar}")
        console.print(neural_indicator)
    
    async def _get_neural_input(self) -> Optional[str]:
        """Get input with neural interface enhancements."""
        # Show contextual hints
        hints = self._get_contextual_hints()
        if hints:
            console.print(f"[dim]{random.choice(hints)}[/dim]")
        
        # Create animated prompt
        prompt_symbol = self._get_mood_prompt_symbol()
        
        # Use personality-specific prompt style
        traits = self.agent.personality_traits[self.agent.personality]
        emoji = random.choice(traits["emoji_set"])
        
        user_input = await self._animated_prompt(
            f"{emoji} Neural Query",
            multiline=False
        )
        
        return user_input
    
    def _get_contextual_hints(self) -> List[str]:
        """Get contextual hints based on current state."""
        hints = []
        
        if self.searches_performed == 0:
            hints.append("Try: 'quantum mechanics' or 'explore consciousness'")
        elif self.discovery_streak > 3:
            hints.append("You're on fire! Try combining discovered concepts")
        elif self.neural_coherence < 0.5:
            hints.append("Neural coherence low. Try 'recalibrate' or take a mindful break")
        
        # Personality-specific hints
        if self.agent.personality == AgentPersonality.PIXEL:
            hints.append("Hidden command: /konami - Try it! 🎮")
        elif self.agent.personality == AgentPersonality.QUANTUM:
            hints.append("The observer affects the observed...")
        
        return hints
    
    def _get_mood_prompt_symbol(self) -> str:
        """Get prompt symbol based on agent mood."""
        mood_symbols = {
            MoodState.EXCITED: "⚡",
            MoodState.CURIOUS: "🔍",
            MoodState.FOCUSED: "🎯",
            MoodState.PLAYFUL: "🎲",
            MoodState.CONTEMPLATIVE: "💭"
        }
        
        return mood_symbols.get(self.agent.mood, "➤")
    
    async def _animated_prompt(self, prompt: str, choices: List[str] = None, multiline: bool = False) -> str:
        """Create an animated prompt."""
        # Animate prompt appearance
        animated_prompt = ""
        for char in prompt:
            animated_prompt += char
            console.print(f"\r[bold {self.theme.primary}]{animated_prompt}[/bold {self.theme.primary}]: ", end="")
            await asyncio.sleep(0.02)
        
        # Get input
        if choices:
            return Prompt.ask("", choices=choices)
        else:
            return Prompt.ask("")
    
    async def _process_neural_command(self, command: str):
        """Process user command with neural enhancements."""
        # Check for special commands
        if command.startswith('/'):
            await self._handle_special_command(command)
        else:
            # Perform neural search
            await self._perform_neural_search(command)
    
    async def _handle_special_command(self, command: str):
        """Handle special neural commands."""
        cmd = command.lower().strip()
        
        special_commands = {
            '/help': self._show_neural_help,
            '/stats': self._show_statistics,
            '/achievements': self._show_achievements,
            '/mindmap': self._create_mind_map,
            '/neural': self._show_neural_network,
            '/quantum': self._enter_quantum_mode,
            '/theme': self._change_theme,
            '/personality': self._switch_personality,
            '/konami': self._konami_code,
            '/exit': self._prepare_exit
        }
        
        handler = special_commands.get(cmd)
        if handler:
            await handler()
        else:
            await self._show_command_not_found(cmd)
    
    async def _perform_neural_search(self, query: str):
        """Perform a neural search with stunning visuals."""
        self.searches_performed += 1
        
        # Pre-search animation
        console.print(f"\n[{self.theme.primary}]Activating Neural Pathways...[/{self.theme.primary}]")
        
        # Perform quantum search
        result = await self.agent.quantum_search(
            None,
            query,
            search_mode="quantum",
            consciousness_level=self.user_level
        )
        
        # Update metrics
        self.documents_discovered += len(result["documents"])
        self.experience_points += len(result["documents"]) * 10
        
        # Check for level up
        await self._check_level_up()
        
        # Display results with neural visualization
        await self._display_neural_results(query, result)
        
        # Update neural state
        self.neural_coherence = result["quantum_state"]["coherence"]
        self.quantum_entanglement = result["quantum_state"]["entanglement"]
        
        # Check for achievements
        await self._check_achievements(result)
    
    async def _display_neural_results(self, query: str, result: Dict[str, Any]):
        """Display search results with neural enhancements."""
        documents = result["documents"]
        
        if not documents:
            # No results animation
            await self._show_no_results_effect(query)
            return
        
        # Success animation
        await create_particle_burst(
            console,
            self.theme.success,
            f"Found {len(documents)} Neural Connections!"
        )
        
        # Create neural pathway visualization
        console.print(f"\n[bold {self.theme.primary}]Neural Pathways Discovered[/bold {self.theme.primary}]")
        
        # Display documents as neural nodes
        for i, doc in enumerate(documents):
            # Create node visualization
            node_visual = self._create_document_node(doc, i)
            console.print(node_visual)
            
            # Show neural connections
            if i < len(documents) - 1:
                connection = self._create_neural_connection(
                    doc,
                    documents[i + 1],
                    result["neural_pathways"]
                )
                console.print(connection)
        
        # Show discovered patterns
        if result["discovered_patterns"]:
            patterns_panel = Panel(
                "\n".join([f"• {pattern}" for pattern in result["discovered_patterns"]]),
                title=f"[{self.theme.accent}]Discovered Patterns[/{self.theme.accent}]",
                border_style=self.theme.accent
            )
            console.print("\n", patterns_panel)
        
        # Offer exploration options
        await self._offer_exploration_options(documents)
    
    def _create_document_node(self, doc, index: int) -> Panel:
        """Create a visual representation of a document as a neural node."""
        # Node visualization
        node_art = f"""
        ╭─◉─╮  [{self.theme.primary}]Node {index + 1}[/{self.theme.primary}]
        │ ◈ │  Resonance: {doc.resonance_frequency:.0f} Hz
        ╰─◉─╯  Entanglement: {doc.quantum_entanglement:.2%}
        """
        
        content = f"""
        {node_art}
        
        [{self.theme.accent}]{doc.title}[/{self.theme.accent}]
        {doc.content[:150]}...
        
        Neural Weight: {'█' * int(doc.neural_weight * 10)}
        """
        
        return Panel(
            content,
            border_style=self.theme.primary,
            box=box.ROUNDED
        )
    
    def _create_neural_connection(self, doc1, doc2, pathways: List[Dict]) -> str:
        """Create visual representation of neural connection."""
        # Find connection strength
        connection_strength = 0.5  # Default
        
        for pathway in pathways:
            if (pathway.get("source") == doc1.id and pathway.get("target") == doc2.id):
                connection_strength = pathway.get("strength", 0.5)
                break
        
        # Create connection visualization
        if connection_strength > 0.7:
            connection = f"         [{self.theme.success}]║═══════════║[/{self.theme.success}]  Strong Neural Link"
        elif connection_strength > 0.5:
            connection = f"         [{self.theme.warning}]║───────────║[/{self.theme.warning}]  Moderate Connection"
        else:
            connection = f"         [{self.theme.dim}]║···········║[/{self.theme.dim}]  Weak Resonance"
        
        return connection
    
    async def _offer_exploration_options(self, documents: List[Any]):
        """Offer neural exploration options."""
        console.print(f"\n[{self.theme.accent}]Neural Exploration Options:[/{self.theme.accent}]")
        
        options = [
            "🧠 Create Mind Map",
            "🔀 Explore Neural Pathways",
            "✨ Synthesize Knowledge",
            "🔍 Deep Dive into Document",
            "🌌 Find Hidden Connections",
            "← Back to Search"
        ]
        
        choice = await asyncio.to_thread(
            questionary.select,
            "Choose your path:",
            choices=options,
            style=questionary.Style([
                ('question', f'fg:{self.theme.primary}'),
                ('pointer', f'fg:{self.theme.accent}'),
                ('highlighted', f'fg:{self.theme.highlight} bold'),
                ('selected', f'fg:{self.theme.success}'),
            ])
        ).ask()
        
        if choice == "🧠 Create Mind Map":
            await self._create_document_mind_map(documents)
        elif choice == "🔀 Explore Neural Pathways":
            await self._explore_pathways(documents[0].id)
        elif choice == "✨ Synthesize Knowledge":
            await self._synthesize_documents(documents)
        elif choice == "🔍 Deep Dive into Document":
            await self._deep_dive(documents)
        elif choice == "🌌 Find Hidden Connections":
            await self._find_hidden_connections(documents)
    
    async def _show_no_results_effect(self, query: str):
        """Show effect when no results found."""
        # Glitch effect
        glitch_text = ""
        for char in f"No neural pathways found for '{query}'":
            if random.random() > 0.8:
                glitch_text += random.choice("@#$%&*")
            else:
                glitch_text += char
        
        console.print(f"\n[red]{glitch_text}[/red]")
        
        # Suggestions
        console.print("\n[yellow]Quantum suggestions:[/yellow]")
        console.print("• Try rephrasing your query")
        console.print("• Explore related concepts")
        console.print("• Adjust your consciousness level")
    
    async def _check_level_up(self):
        """Check if user leveled up."""
        xp_needed = self.user_level * 100
        
        if self.experience_points >= xp_needed:
            self.user_level += 1
            self.experience_points -= xp_needed
            
            # Level up animation
            await self._show_level_up_animation()
    
    async def _show_level_up_animation(self):
        """Show level up animation."""
        console.print("\n")
        
        # ASCII art fireworks
        fireworks = """
                    *  .  *  .  *
                 *  .  ╱╲  .  *
                  . ╱◉◉◉╲ .
                 * ╱◉◉◉◉◉╲ *
                  ╱◉◉◉◉◉◉◉╲
                   LEVEL UP!
        """
        
        await animate_text_reveal(
            console,
            fireworks,
            self.theme.success,
            delay=0.01
        )
        
        console.print(f"\n[bold {self.theme.success}]You reached Level {self.user_level}![/bold {self.theme.success}]")
        console.print(f"[{self.theme.accent}]New abilities unlocked![/{self.theme.accent}]")
        
        # Play level up sound
        await play_sound_effect("level_up")
    
    async def _check_achievements(self, result: Dict[str, Any]):
        """Check for new achievements."""
        new_achievements = []
        
        # First search
        if self.searches_performed == 1:
            new_achievements.append({
                "name": "First Steps",
                "description": "Performed your first neural search",
                "icon": "🎯"
            })
        
        # Document milestone
        if self.documents_discovered >= 10:
            new_achievements.append({
                "name": "Knowledge Seeker",
                "description": "Discovered 10 documents",
                "icon": "📚"
            })
        
        # Pattern recognition
        if len(result["discovered_patterns"]) >= 3:
            new_achievements.append({
                "name": "Pattern Master",
                "description": "Discovered multiple patterns in one search",
                "icon": "🔮"
            })
        
        # Display new achievements
        for achievement in new_achievements:
            if achievement["name"] not in [a["name"] for a in self.achievements]:
                self.achievements.append(achievement)
                await self._show_achievement_unlock(achievement)
    
    async def _show_achievement_unlock(self, achievement: Dict[str, Any]):
        """Show achievement unlock animation."""
        console.print("\n")
        
        # Create achievement badge
        badge = f"""
        ╭────────────────────╮
        │ {achievement['icon']}  ACHIEVEMENT  {achievement['icon']} │
        │                    │
        │ {achievement['name']:^18} │
        │                    │
        ╰────────────────────╯
        """
        
        await animate_text_reveal(
            console,
            badge,
            self.theme.success,
            delay=0.005
        )
        
        console.print(f"[dim]{achievement['description']}[/dim]")
        
        # Play achievement sound
        await play_sound_effect("achievement")
    
    async def _show_neural_help(self):
        """Show neural help interface."""
        help_text = f"""
        # Neural Navigator Help
        
        ## Search Commands
        - Type any query to search the neural network
        - Use natural language for best results
        - Combine concepts with AND, OR, NOT
        
        ## Special Commands
        - `/help` - Show this help
        - `/stats` - View your statistics
        - `/achievements` - View unlocked achievements
        - `/mindmap` - Create a mind map
        - `/neural` - Visualize neural network
        - `/quantum` - Enter quantum mode
        - `/theme` - Change visual theme
        - `/personality` - Switch AI personality
        - `/exit` - Exit Neural Navigator
        
        ## Search Modifiers
        - `consciousness:high` - Deep search
        - `mode:quantum` - Quantum search
        - `resonance:440` - Specific frequency
        
        ## Tips
        - Higher levels unlock deeper searches
        - Discover patterns to gain bonus XP
        - Explore neural pathways for insights
        - Achievements unlock special abilities
        
        Current Personality: {self.agent.personality.value}
        """
        
        md = Markdown(help_text)
        console.print(Panel(md, title="Neural Navigator Help", border_style=self.theme.primary))
    
    async def _show_statistics(self):
        """Show user statistics."""
        stats = f"""
        🧠 Neural Statistics
        
        Level: {self.user_level}
        Experience: {self.experience_points} XP
        Next Level: {self.user_level * 100 - self.experience_points} XP needed
        
        📊 Session Metrics
        Searches: {self.searches_performed}
        Documents: {self.documents_discovered}
        Insights: {self.insights_generated}
        
        ⚡ Neural State
        Coherence: {self.neural_coherence:.2%}
        Entanglement: {self.quantum_entanglement:.2%}
        Discovery Streak: {self.discovery_streak}
        
        🏆 Achievements
        Unlocked: {len(self.achievements)}/20
        """
        
        console.print(Panel(
            stats,
            title=f"[{self.theme.accent}]Your Neural Profile[/{self.theme.accent}]",
            border_style=self.theme.primary
        ))
    
    async def _konami_code(self):
        """Easter egg - Konami code activation."""
        console.print("\n[blink]KONAMI CODE ACTIVATED![/blink]")
        
        # Special effects
        await create_matrix_rain(console, duration=1.0)
        
        # Unlock secret achievement
        secret = {
            "name": "Secret Finder",
            "description": "Discovered the Konami code!",
            "icon": "🎮"
        }
        
        if secret["name"] not in [a["name"] for a in self.achievements]:
            self.achievements.append(secret)
            await self._show_achievement_unlock(secret)
        
        # Bonus XP
        self.experience_points += 100
        console.print(f"[yellow]+100 Bonus XP![/yellow]")
    
    async def _confirm_exit(self) -> bool:
        """Confirm exit with style."""
        # Show session summary
        summary = f"""
        Session Summary:
        
        • Searches performed: {self.searches_performed}
        • Documents discovered: {self.documents_discovered}
        • XP gained: {self.experience_points}
        • Achievements unlocked: {len(self.achievements)}
        """
        
        console.print(Panel(
            summary,
            title="[yellow]Leaving Neural Space[/yellow]",
            border_style="yellow"
        ))
        
        return Confirm.ask("\n[yellow]Disconnect from the Neural Navigator?[/yellow]")
    
    async def _prepare_exit(self):
        """Prepare for exit."""
        self.running = False

async def main():
    """Main entry point for Neural Navigator."""
    navigator = NeuralNavigatorCLI()
    
    try:
        await navigator.start()
    except Exception as e:
        console.print(f"\n[red]Neural Error: {e}[/red]")
    finally:
        if navigator.agent:
            await navigator.agent.mcp_client.disconnect()
        console.print(f"\n[{navigator.theme.primary}]Neural Navigator Offline. Until next time...[/{navigator.theme.primary}]")

if __name__ == "__main__":
    asyncio.run(main())
```

### 4. Ultra Themes Module

```python
# src/themes_ultra.py
"""
Ultra-enhanced themes for the Neural Navigator.

Features dynamic, animated themes with particle effects.
"""

from typing import Dict, List, Tuple
import random
import math
from dataclasses import dataclass

@dataclass
class UltraTheme:
    """Ultra-enhanced theme with advanced properties."""
    name: str
    primary: str
    secondary: str
    accent: str
    success: str
    warning: str
    error: str
    dim: str
    highlight: str
    
    # Gradient colors
    gradient_start: str
    gradient_end: str
    
    # Particle effects
    particle_chars: List[str]
    particle_colors: List[str]
    
    # Animation properties
    pulse_rate: float
    wave_amplitude: float
    
    # Sound theme
    sound_pack: str
    
    # ASCII art style
    art_style: str

# Matrix Theme
MATRIX_THEME = UltraTheme(
    name="Matrix",
    primary="#00ff00",
    secondary="#008800",
    accent="#00ff88",
    success="#00ff00",
    warning="#ffff00",
    error="#ff0000",
    dim="#004400",
    highlight="#88ff88",
    gradient_start="#000000",
    gradient_end="#00ff00",
    particle_chars=["0", "1", "│", "╱", "╲", "█", "▓", "▒", "░"],
    particle_colors=["#00ff00", "#00cc00", "#009900", "#006600"],
    pulse_rate=120.0,
    wave_amplitude=0.8,
    sound_pack="digital",
    art_style="digital_rain"
)

# Neon Dreams Theme
NEON_DREAMS_THEME = UltraTheme(
    name="Neon Dreams",
    primary="#ff00ff",
    secondary="#00ffff",
    accent="#ffff00",
    success="#00ff00",
    warning="#ff8800",
    error="#ff0088",
    dim="#880088",
    highlight="#ffffff",
    gradient_start="#ff00ff",
    gradient_end="#00ffff",
    particle_chars=["★", "✦", "◆", "▲", "●", "■", "♦", "◉"],
    particle_colors=["#ff00ff", "#00ffff", "#ffff00", "#ff00aa", "#00aaff"],
    pulse_rate=140.0,
    wave_amplitude=1.2,
    sound_pack="synthwave",
    art_style="neon_glow"
)

# Cosmic Void Theme
COSMIC_VOID_THEME = UltraTheme(
    name="Cosmic Void",
    primary="#9945ff",
    secondary="#14f195",
    accent="#ffd700",
    success="#00ff88",
    warning="#ff6b6b",
    error="#ff4757",
    dim="#4a4a4a",
    highlight="#ffffff",
    gradient_start="#000033",
    gradient_end="#9945ff",
    particle_chars=["⚛", "✧", "◈", "◇", "○", "●", "◉", "◎", "☆", "★"],
    particle_colors=["#9945ff", "#14f195", "#ffd700", "#ff6b6b"],
    pulse_rate=60.0,
    wave_amplitude=0.6,
    sound_pack="cosmic",
    art_style="space"
)

# Neural Fire Theme
NEURAL_FIRE_THEME = UltraTheme(
    name="Neural Fire",
    primary="#ff6b35",
    secondary="#f7931e",
    accent="#ffd700",
    success="#4ecdc4",
    warning="#ffe66d",
    error="#ff1744",
    dim="#8b4513",
    highlight="#ffffff",
    gradient_start="#ff0000",
    gradient_end="#ffff00",
    particle_chars=["🔥", "✦", "◈", "▲", "△", "◆", "♦"],
    particle_colors=["#ff6b35", "#f7931e", "#ffd700", "#ff4500"],
    pulse_rate=180.0,
    wave_amplitude=1.5,
    sound_pack="fire",
    art_style="flames"
)

# Quantum Ice Theme
QUANTUM_ICE_THEME = UltraTheme(
    name="Quantum Ice",
    primary="#00d4ff",
    secondary="#0099cc",
    accent="#88ffff",
    success="#00ff99",
    warning="#ffcc00",
    error="#ff0066",
    dim="#005577",
    highlight="#ffffff",
    gradient_start="#000033",
    gradient_end="#00d4ff",
    particle_chars=["❄", "✧", "◇", "○", "◈", "⬡", "⬢"],
    particle_colors=["#00d4ff", "#0099cc", "#88ffff", "#ffffff"],
    pulse_rate=40.0,
    wave_amplitude=0.4,
    sound_pack="crystal",
    art_style="frost"
)

ULTRA_THEMES = {
    "matrix": MATRIX_THEME,
    "neon": NEON_DREAMS_THEME,
    "cosmic": COSMIC_VOID_THEME,
    "fire": NEURAL_FIRE_THEME,
    "ice": QUANTUM_ICE_THEME
}

def get_ultra_theme(name: str) -> UltraTheme:
    """Get ultra theme by name."""
    return ULTRA_THEMES.get(name.lower(), MATRIX_THEME)
```

### 5. Ultra Utils Module

```python
# src/utils_ultra.py
"""
Ultra-enhanced utilities for the Neural Navigator.

Features advanced animations, effects, and visualizations.
"""

import asyncio
import random
import math
import time
from typing import List, Optional
from rich.console import Console
from rich.text import Text
from rich.panel import Panel
from rich.layout import Layout
from rich.align import Align

async def create_matrix_rain(console: Console, duration: float = 3.0):
    """Create Matrix-style digital rain effect."""
    width = console.width
    height = 20
    
    # Initialize rain columns
    columns = []
    for x in range(0, width, 2):  # Every 2 chars for better visibility
        columns.append({
            'x': x,
            'y': random.randint(-height, 0),
            'speed': random.uniform(0.5, 1.5),
            'chars': [chr(random.randint(0x30A0, 0x30FF)) for _ in range(height)],
            'trail_length': random.randint(5, 15)
        })
    
    start_time = time.time()
    
    while time.time() - start_time < duration:
        # Clear screen
        console.clear()
        
        # Create frame
        frame = [[' ' for _ in range(width)] for _ in range(height)]
        colors = [[None for _ in range(width)] for _ in range(height)]
        
        # Update and render columns
        for col in columns:
            col['y'] += col['speed']
            
            # Reset column if it goes off screen
            if col['y'] - col['trail_length'] > height:
                col['y'] = random.randint(-height, -5)
                col['chars'] = [chr(random.randint(0x30A0, 0x30FF)) for _ in range(height)]
            
            # Render column with trail
            for i in range(col['trail_length']):
                y = int(col['y'] - i)
                if 0 <= y < height and col['x'] < width:
                    char_idx = y % len(col['chars'])
                    frame[y][col['x']] = col['chars'][char_idx]
                    
                    # Color based on position in trail
                    if i == 0:
                        colors[y][col['x']] = "#ffffff"  # White head
                    elif i < 3:
                        colors[y][col['x']] = "#00ff00"  # Bright green
                    elif i < 6:
                        colors[y][col['x']] = "#00cc00"  # Medium green
                    else:
                        colors[y][col['x']] = "#008800"  # Dark green
        
        # Render frame
        output = []
        for y in range(height):
            line = Text()
            for x in range(width):
                if colors[y][x]:
                    line.append(frame[y][x], style=colors[y][x])
                else:
                    line.append(frame[y][x])
            output.append(line)
        
        # Display
        for line in output:
            console.print(line)
        
        await asyncio.sleep(0.05)  # ~20 FPS

async def animate_text_reveal(
    console: Console,
    text: str,
    color: str,
    delay: float = 0.01
):
    """Animate text reveal with typewriter effect."""
    lines = text.strip().split('\n')
    
    for line in lines:
        revealed = ""
        for char in line:
            revealed += char
            console.print(f"\r[{color}]{revealed}[/{color}]", end="")
            await asyncio.sleep(delay)
        console.print()  # New line

async def create_particle_burst(
    console: Console,
    color: str,
    message: str,
    particle_count: int = 20
):
    """Create a particle burst effect."""
    width = console.width
    center_x = width // 2
    center_y = 10
    
    particles = []
    for _ in range(particle_count):
        angle = random.uniform(0, 2 * math.pi)
        speed = random.uniform(2, 5)
        particles.append({
            'x': center_x,
            'y': center_y,
            'vx': math.cos(angle) * speed,
            'vy': math.sin(angle) * speed,
            'life': 1.0,
            'char': random.choice(['*', '✦', '◆', '●', '○'])
        })
    
    # Animation loop
    for frame in range(20):
        console.clear()
        
        # Create canvas
        canvas = [[' ' for _ in range(width)] for _ in range(20)]
        
        # Update and draw particles
        for particle in particles:
            # Update position
            particle['x'] += particle['vx']
            particle['y'] += particle['vy']
            particle['vy'] += 0.3  # Gravity
            particle['life'] -= 0.05
            
            # Draw if still alive and in bounds
            x, y = int(particle['x']), int(particle['y'])
            if particle['life'] > 0 and 0 <= x < width and 0 <= y < 20:
                canvas[y][x] = particle['char']
        
        # Draw message in center
        msg_y = center_y
        msg_x = center_x - len(message) // 2
        for i, char in enumerate(message):
            if 0 <= msg_x + i < width:
                canvas[msg_y][msg_x + i] = char
        
        # Render canvas
        for row in canvas:
            line = ''.join(row)
            console.print(f"[{color}]{line}[/{color}]")
        
        await asyncio.sleep(0.05)

def create_holographic_display(
    text: str,
    color: str,
    width: int = 60,
    height: int = 10
) -> Panel:
    """Create a holographic display panel."""
    # Add holographic effects to text
    lines = []
    
    # Top holographic border
    lines.append("╔" + "═" * (width - 2) + "╗")
    
    # Add glitch effects
    for line in text.split('\n'):
        holographic_line = ""
        for char in line:
            if random.random() > 0.95:
                # Glitch character
                holographic_line += random.choice(['▓', '▒', '░', '█'])
            else:
                holographic_line += char
        
        # Center the line
        padding = (width - len(line) - 2) // 2
        lines.append("║" + " " * padding + holographic_line + " " * (width - padding - len(line) - 2) + "║")
    
    # Fill remaining height
    while len(lines) < height - 1:
        lines.append("║" + " " * (width - 2) + "║")
    
    # Bottom border
    lines.append("╚" + "═" * (width - 2) + "╝")
    
    # Add scanlines effect
    hologram_text = "\n".join(lines)
    
    return Panel(
        hologram_text,
        style=f"{color} on black",
        border_style=color,
        box=None,
        padding=0
    )

def generate_ascii_art(
    style: str,
    width: int = 40,
    height: int = 10
) -> str:
    """Generate procedural ASCII art based on style."""
    art_generators = {
        "neural": _generate_neural_art,
        "quantum": _generate_quantum_art,
        "digital": _generate_digital_art,
        "organic": _generate_organic_art
    }
    
    generator = art_generators.get(style, _generate_neural_art)
    return generator(width, height)

def _generate_neural_art(width: int, height: int) -> str:
    """Generate neural network ASCII art."""
    lines = []
    
    for y in range(height):
        line = ""
        for x in range(width):
            # Create neural pattern
            if (x + y) % 7 == 0:
                line += "◉"
            elif (x * y) % 11 == 0:
                line += "◈"
            elif abs(x - width//2) + abs(y - height//2) < height//3:
                line += "·"
            else:
                line += " "
        lines.append(line)
    
    return "\n".join(lines)

def _generate_quantum_art(width: int, height: int) -> str:
    """Generate quantum field ASCII art."""
    lines = []
    
    for y in range(height):
        line = ""
        for x in range(width):
            # Quantum probability field
            prob = math.sin(x * 0.2) * math.cos(y * 0.3)
            if prob > 0.5:
                line += "█"
            elif prob > 0.2:
                line += "▓"
            elif prob > -0.2:
                line += "▒"
            elif prob > -0.5:
                line += "░"
            else:
                line += " "
        lines.append(line)
    
    return "\n".join(lines)

def _generate_digital_art(width: int, height: int) -> str:
    """Generate digital/matrix ASCII art."""
    chars = "01│─┼╱╲"
    lines = []
    
    for y in range(height):
        line = ""
        for x in range(width):
            if random.random() > 0.7:
                line += random.choice(chars)
            else:
                line += " "
        lines.append(line)
    
    return "\n".join(lines)

def _generate_organic_art(width: int, height: int) -> str:
    """Generate organic/flowing ASCII art."""
    lines = []
    
    for y in range(height):
        line = ""
        for x in range(width):
            # Create flowing patterns
            flow = math.sin(x * 0.1 + y * 0.2) + math.cos(x * 0.2 - y * 0.1)
            if flow > 1.0:
                line += "∽"
            elif flow > 0.5:
                line += "~"
            elif flow > 0:
                line += "-"
            else:
                line += " "
        lines.append(line)
    
    return "\n".join(lines)

async def play_sound_effect(effect_name: str):
    """Play a sound effect (simulated with visual feedback)."""
    # In a real implementation, this would play actual sounds
    # For terminal, we'll show a visual indicator
    
    sound_indicators = {
        "neural_activation": "♪ Neural Networks Activating ♪",
        "quantum_collapse": "♫ Quantum State Collapsed ♫",
        "level_up": "♪♪ LEVEL UP! ♪♪",
        "achievement": "★ Achievement Unlocked! ★",
        "discovery": "✦ Discovery Made! ✦",
        "error": "✗ Error Detected ✗"
    }
    
    indicator = sound_indicators.get(effect_name, "♪ Sound ♪")
    
    # Simulate sound with brief visual
    console = Console()
    console.print(f"\n[dim italic]{indicator}[/dim italic]", justify="center")
    await asyncio.sleep(0.1)
```

### 6. Main Entry Point

```python
# neural_navigator.py
#!/usr/bin/env python3
"""
Neural Navigator - The Future of Knowledge Discovery

An ultra-enhanced Context7 Agent with quantum search capabilities.
"""

import asyncio
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

# Check Python version
if sys.version_info < (3, 11):
    print("Neural Navigator requires Python 3.11 or higher")
    sys.exit(1)

try:
    from src.cli_ultra import main
except ImportError as e:
    print(f"Failed to import Neural Navigator: {e}")
    print("Please ensure all dependencies are installed:")
    print("  pip install -r requirements.txt")
    sys.exit(1)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nNeural connection terminated by user")
        sys.exit(0)
    except Exception as e:
        print(f"\nNeural Error: {e}", file=sys.stderr)
        sys.exit(1)
```

### 7. Updated README

```markdown
# 🧠 Neural Navigator - Context7 Agent ULTRA

> The Future of Knowledge Discovery

An ultra-enhanced AI agent that transforms document search into a mind-blowing neural exploration experience. Powered by Pydantic AI and Context7 MCP, featuring quantum search, neural pathways, and stunning visual effects.

![Neural Navigator](https://img.shields.io/badge/Neural-Navigator-blueviolet?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge)
![AI Powered](https://img.shields.io/badge/AI-Powered-green?style=for-the-badge)

## 🌟 Experience the Future

### 🎮 Gamified Knowledge Discovery
- **Level System**: Progress through consciousness levels
- **XP & Achievements**: Unlock abilities and rewards
- **Discovery Streaks**: Chain discoveries for bonuses
- **Hidden Commands**: Find easter eggs and secrets

### 🧠 Neural Intelligence
- **5 AI Personalities**: Choose your guide through knowledge
  - ⚡ NOVA - The Energetic Explorer
  - 🧙 SAGE - The Wise Guide
  - 🎮 PIXEL - The Playful Companion
  - 🌌 QUANTUM - The Mysterious Oracle
  - ☯️ ZEN - The Mindful Navigator

### 🌈 Mind-Blowing Visuals
- **Matrix Rain**: Digital rain effects during search
- **Particle Bursts**: Celebrate discoveries with effects
- **Neural Networks**: Live visualization of connections
- **Holographic Displays**: Futuristic UI elements
- **Dynamic Themes**: 5 ultra-enhanced visual themes

### ⚛️ Quantum Search Technology
- **Quantum States**: Search probability collapse visualization
- **Neural Pathways**: Explore knowledge connections
- **Mind Maps**: Interactive knowledge visualization
- **Hidden Connections**: Discover unexpected links
- **Knowledge Synthesis**: AI-powered insight generation

## 🚀 Quick Start

### Prerequisites
```bash
# Required
- Python 3.11+
- Node.js & npm
- OpenAI API key

# Optional
- GPU for enhanced visualizations
- High-refresh terminal for smooth animations
```

### Installation

1. **Clone the Neural Navigator**
```bash
git clone https://github.com/yourusername/neural-navigator.git
cd neural-navigator
```

2. **Enter the Virtual Matrix**
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

3. **Install Neural Dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure Your Neural Interface**
```bash
cp .env.example .env
# Add your OpenAI API key and preferences
```

5. **Initialize Context7 Quantum Core**
```bash
npm install -g @upstash/context7-mcp
```

## 🎯 Launch Sequence

```bash
python neural_navigator.py
```

### First Launch Experience
1. **Epic Intro**: Matrix rain and neural activation
2. **Choose Personality**: Select your AI guide
3. **Tutorial Quest**: Learn through gamified introduction
4. **Begin Journey**: Start exploring knowledge space

## 🎮 Neural Commands

### Basic Navigation
- Type naturally to search the neural network
- `/help` - Access neural help system
- `/stats` - View your progress
- `/achievements` - Check unlocked abilities

### Advanced Features
- `/mindmap` - Create knowledge mind maps
- `/neural` - Visualize neural pathways
- `/quantum` - Enter quantum search mode
- `/theme` - Change visual theme
- `/personality` - Switch AI personality

### Hidden Commands
- `/konami` - ???
- `/matrix` - ???
- `/singularity` - ???

## 🧬 Search Syntax

### Basic Queries
```
quantum computing
machine learning AND neural networks
consciousness NOT artificial
```

### Advanced Modifiers
```
"exact phrase" consciousness:high
python mode:quantum resonance:432
knowledge after:2024 before:2025
```

### Quantum Operators
```
concept1 ~~ concept2  # Quantum entanglement
idea >> insight       # Neural pathway
thought || memory     # Parallel processing
```

## 🏆 Achievement System

### Starter Achievements
- 🎯 **First Steps** - Perform first search
- 📚 **Knowledge Seeker** - Discover 10 documents
- 🔮 **Pattern Master** - Find hidden patterns
- 🎮 **Secret Finder** - Discover easter eggs

### Advanced Achievements
- 🧠 **Neural Master** - Map 100 connections
- ⚛️ **Quantum Explorer** - Use all search modes
- 🌟 **Enlightened** - Reach Level 10
- ♾️ **Singularity** - [CLASSIFIED]

## 🎨 Ultra Themes

### Available Themes
1. **Matrix** - Digital green rain
2. **Neon Dreams** - Synthwave aesthetics
3. **Cosmic Void** - Deep space visuals
4. **Neural Fire** - Energetic orange flows
5. **Quantum Ice** - Crystal blue fractals

### Theme Features
- Dynamic color gradients
- Particle effects
- Synchronized animations
- Personality-matched colors

## 🔧 Configuration

### Environment Variables
```bash
# AI Configuration
OPENAI_API_KEY=your-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

# Neural Settings
NEURAL_THEME=matrix
NEURAL_PERSONALITY=nova
NEURAL_SOUND_ENABLED=true

# Quantum Parameters
QUANTUM_COHERENCE=0.9
QUANTUM_ENTANGLEMENT=0.1
```

## 🧪 Development

### Architecture
```
neural-navigator/
├── src/
│   ├── agent_ultra.py      # Quantum-enhanced agent
│   ├── cli_ultra.py        # Neural interface
│   ├── quantum_effects.py  # Visual effects engine
│   ├── themes_ultra.py     # Dynamic themes
│   └── utils_ultra.py      # Neural utilities
├── tests/                  # Quantum test suite
├── docs/                   # Neural documentation
└── assets/                 # Visual assets
```

### Contributing
1. Fork the neural repository
2. Create feature branch (`git checkout -b feature/quantum-enhancement`)
3. Commit changes (`git commit -m 'Add quantum feature'`)
4. Push to branch (`git push origin feature/quantum-enhancement`)
5. Open Pull Request to the neural network

## 📊 Performance

### System Requirements
- **Minimum**: 4GB RAM, 2 CPU cores
- **Recommended**: 8GB RAM, 4 CPU cores
- **Optimal**: 16GB RAM, 8 CPU cores, GPU

### Optimization Tips
- Use high-refresh terminal (120Hz+)
- Enable GPU acceleration if available
- Adjust particle density for performance
- Use focused search modes for speed

## 🌐 Community

### Connect With Neural Explorers
- 🌟 [Discord Server](https://discord.gg/neural-navigator)
- 🐦 [Twitter Updates](https://twitter.com/neuralnavigator)
- 📺 [YouTube Tutorials](https://youtube.com/neuralnavigator)
- 📝 [Blog & Articles](https://blog.neuralnavigator.ai)

### Resources
- [Neural Search Guide](docs/neural-search.md)
- [Quantum Mechanics](docs/quantum-mechanics.md)
- [Achievement Guide](docs/achievements.md)
- [API Reference](docs/api-reference.md)

## 🔮 Roadmap

### Phase 1: Neural Foundation ✅
- Quantum search engine
- 5 AI personalities
- Achievement system
- Visual effects

### Phase 2: Consciousness Expansion 🚧
- Multi-dimensional search
- Collective intelligence
- Neural synchronization
- Reality bending

### Phase 3: Singularity 🔮
- [CLASSIFIED]
- [REDACTED]
- [UNKNOWN]
- [∞]

## 🙏 Acknowledgments

- **Pydantic AI** - For the neural framework
- **Context7** - For quantum document access
- **The Community** - For pushing boundaries
- **You** - For joining the neural revolution

## 📜 License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

---

<div align="center">

**Ready to transcend traditional search?**

# [🧠 ENTER THE NEURAL NAVIGATOR 🧠](https://github.com/yourusername/neural-navigator)

*The future of knowledge awaits...*

</div>
```

## Summary

This reimagined Context7 Agent - "Neural Navigator" - features:

### 🎮 **Gamification**
- Level system with XP
- Achievements and unlockables
- Discovery streaks
- Hidden easter eggs

### 🧠 **AI Personalities**
- 5 unique personalities
- Mood states
- Personality-specific responses
- Dynamic interactions

### 🌈 **Stunning Visuals**
- Matrix rain effects
- Particle explosions
- Neural network animations
- Holographic displays
- Dynamic themes

### ⚛️ **Quantum Features**
- Quantum search visualization
- Neural pathway exploration
- Mind map generation
- Hidden connection discovery
- Knowledge synthesis

### 🚀 **Advanced UX**
- Contextual hints
- Animated prompts
- Progress tracking
- Sound effects (simulated)
- Smooth transitions

The Neural Navigator transforms document search into an immersive, gamified experience that makes knowledge discovery feel like exploring a neural universe. Every search is an adventure, every discovery an achievement, and every session a journey through the quantum realm of information!

---
```markdown
# 🧠 Neural Navigator - Project Architecture Document

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Architecture Overview](#architecture-overview)
3. [System Design Philosophy](#system-design-philosophy)
4. [Project Structure](#project-structure)
5. [Core Modules](#core-modules)
6. [Data Flow Architecture](#data-flow-architecture)
7. [Neural Search Engine](#neural-search-engine)
8. [Personality System](#personality-system)
9. [Visual Effects Engine](#visual-effects-engine)
10. [User Interface Architecture](#user-interface-architecture)
11. [State Management](#state-management)
12. [Integration Patterns](#integration-patterns)
13. [Testing Architecture](#testing-architecture)
14. [Performance Optimization](#performance-optimization)
15. [Security Architecture](#security-architecture)
16. [Deployment Strategy](#deployment-strategy)
17. [Future Extensibility](#future-extensibility)
18. [Developer Guidelines](#developer-guidelines)

---

## Executive Summary

The Neural Navigator represents a paradigm shift in how users interact with knowledge discovery systems. Built on top of Pydantic AI and Context7 MCP, it transforms traditional document search into an immersive, gamified neural exploration experience.

### Key Architectural Principles

1. **Modular Neural Networks**: Each component operates as an independent neural node that can connect and communicate with others
2. **Quantum State Management**: Search operations exist in superposition until observed by the user
3. **Personality-Driven Architecture**: The system adapts its behavior based on the selected AI personality
4. **Visual-First Design**: Every operation produces stunning visual feedback
5. **Gamification Core**: Achievement systems and progression mechanics are fundamental, not add-ons

### Technology Stack

```yaml
Core Framework:
  - Python 3.11+
  - Pydantic AI (Neural Intelligence)
  - Context7 MCP (Quantum Document Access)

Visualization:
  - Rich (Terminal UI)
  - Custom ASCII Art Engine
  - Particle Effects System

Data Management:
  - SQLite (Local State)
  - JSON (Configuration)
  - Protocol Buffers (MCP Communication)

Testing:
  - Pytest (Unit/Integration)
  - Hypothesis (Property Testing)
  - Locust (Performance Testing)
```

---

## Architecture Overview

The Neural Navigator employs a **Quantum-Layered Architecture** where each layer represents a different dimension of functionality:

```mermaid
graph TB
    subgraph "User Dimension"
        U[User] -->|Commands| CLI[Neural CLI Interface]
    end
    
    subgraph "Personality Layer"
        CLI --> PM[Personality Manager]
        PM --> NOVA[Nova]
        PM --> SAGE[Sage]
        PM --> PIXEL[Pixel]
        PM --> QUANTUM[Quantum]
        PM --> ZEN[Zen]
    end
    
    subgraph "Neural Core"
        PM --> NA[Neural Agent]
        NA --> QSE[Quantum Search Engine]
        NA --> NPE[Neural Pathway Explorer]
        NA --> KS[Knowledge Synthesizer]
        NA --> MM[Mind Map Generator]
    end
    
    subgraph "Visual Dimension"
        NA --> VE[Visual Engine]
        VE --> ME[Matrix Effects]
        VE --> PE[Particle Effects]
        VE --> NV[Neural Visualizer]
        VE --> HG[Holographic Display]
    end
    
    subgraph "Data Layer"
        NA --> C7[Context7 MCP Client]
        NA --> HM[History Manager]
        NA --> SM[State Manager]
        C7 --> MCP[MCP Server]
        HM --> DB[(SQLite)]
    end
    
    subgraph "Gamification Engine"
        NA --> GE[Gamification Engine]
        GE --> AS[Achievement System]
        GE --> LS[Level System]
        GE --> PS[Points System]
    end
```

### Architectural Patterns

#### 1. **Event-Driven Neural Networks**
Each user action triggers a cascade of neural events that propagate through the system:

```python
class NeuralEvent:
    """Base class for all neural events in the system."""
    
    def __init__(self, event_type: str, payload: Dict[str, Any]):
        self.id = str(uuid.uuid4())
        self.timestamp = datetime.now()
        self.event_type = event_type
        self.payload = payload
        self.quantum_signature = self._generate_quantum_signature()
    
    def _generate_quantum_signature(self) -> float:
        """Generate a unique quantum signature for event tracking."""
        return hash(f"{self.id}{self.timestamp}") % 1000000 / 1000000

class NeuralEventBus:
    """Central event bus for neural communication."""
    
    def __init__(self):
        self.subscribers: Dict[str, List[Callable]] = {}
        self.event_history: List[NeuralEvent] = []
        self.quantum_state = QuantumState()
    
    async def emit(self, event: NeuralEvent):
        """Emit an event through the neural network."""
        self.event_history.append(event)
        
        # Update quantum state
        self.quantum_state.collapse(event.quantum_signature)
        
        # Notify all subscribers
        if event.event_type in self.subscribers:
            for handler in self.subscribers[event.event_type]:
                await handler(event)
```

#### 2. **Quantum State Pattern**
The system maintains quantum states that affect search results and visualizations:

```python
class QuantumState:
    """Manages quantum states throughout the application."""
    
    def __init__(self):
        self.coherence = 1.0
        self.entanglement = 0.0
        self.superposition = 0.5
        self.wave_function = np.random.random()
        self.observation_history = []
    
    def collapse(self, observation: float):
        """Collapse the wave function based on observation."""
        self.observation_history.append(observation)
        
        # Update quantum properties
        self.coherence *= 0.99  # Slight decoherence
        self.entanglement = min(1.0, self.entanglement + 0.01)
        
        # Collapse wave function
        self.wave_function = (self.wave_function + observation) / 2
        self.superposition = abs(math.sin(self.wave_function * math.pi))
    
    def get_search_modifier(self) -> float:
        """Get quantum modifier for search operations."""
        return self.coherence * self.superposition + self.entanglement * 0.1
```

---

## System Design Philosophy

### 1. **Neural Connectivity**
Every component is designed as a neural node that can form connections with others:

```python
class NeuralNode:
    """Base class for all neural components."""
    
    def __init__(self, node_id: str, node_type: str):
        self.id = node_id
        self.type = node_type
        self.connections: List[NeuralConnection] = []
        self.activation_level = 0.0
        self.memory = {}
    
    async def activate(self, signal: float):
        """Activate this neural node."""
        self.activation_level = self._sigmoid(signal)
        
        # Propagate to connected nodes
        for connection in self.connections:
            if connection.weight * self.activation_level > connection.threshold:
                await connection.target.activate(
                    self.activation_level * connection.weight
                )
    
    def _sigmoid(self, x: float) -> float:
        """Sigmoid activation function."""
        return 1 / (1 + math.exp(-x))
```

### 2. **Personality-Driven Behavior**
The system's behavior fundamentally changes based on the active personality:

```python
class PersonalityCore:
    """Core personality system that affects all operations."""
    
    def __init__(self, personality: AgentPersonality):
        self.personality = personality
        self.traits = self._load_personality_traits()
        self.mood_engine = MoodEngine(personality)
        self.response_generator = ResponseGenerator(personality)
    
    def modify_search_query(self, query: str) -> str:
        """Modify search query based on personality."""
        if self.personality == AgentPersonality.QUANTUM:
            # Add quantum operators
            return f"({query}) AND (quantum OR probability OR superposition)"
        elif self.personality == AgentPersonality.PIXEL:
            # Gamify the search
            return f"{query} achievement unlock bonus"
        # ... other personalities
```

### 3. **Visual-First Architecture**
Every operation produces visual output as a primary concern:

```python
class VisualOperation:
    """Base class for operations that produce visual output."""
    
    def __init__(self, operation_name: str):
        self.name = operation_name
        self.visual_pipeline = []
        self.effects_queue = []
    
    async def execute(self):
        """Execute operation with visual feedback."""
        # Pre-visualization
        await self._pre_visualize()
        
        # Core operation
        result = await self._perform_operation()
        
        # Post-visualization
        await self._post_visualize(result)
        
        return result
    
    async def _pre_visualize(self):
        """Show pre-operation effects."""
        for effect in self.effects_queue:
            await effect.render()
```

---

## Project Structure

### Directory Hierarchy

```
neural-navigator/
│
├── src/                              # Source code root
│   ├── __init__.py
│   │
│   ├── core/                         # Core neural systems
│   │   ├── __init__.py
│   │   ├── agent_ultra.py            # Main neural agent
│   │   ├── quantum_state.py          # Quantum state management
│   │   ├── neural_network.py         # Neural network base classes
│   │   └── event_bus.py              # Event system
│   │
│   ├── personalities/                # AI personality modules
│   │   ├── __init__.py
│   │   ├── base.py                   # Base personality class
│   │   ├── nova.py                   # Nova personality
│   │   ├── sage.py                   # Sage personality
│   │   ├── pixel.py                  # Pixel personality
│   │   ├── quantum.py                # Quantum personality
│   │   └── zen.py                    # Zen personality
│   │
│   ├── search/                       # Search engine modules
│   │   ├── __init__.py
│   │   ├── quantum_search.py         # Quantum search implementation
│   │   ├── neural_pathways.py        # Neural pathway exploration
│   │   ├── knowledge_synthesis.py    # Knowledge synthesis
│   │   └── mind_mapper.py            # Mind map generation
│   │
│   ├── visual/                       # Visual effects engine
│   │   ├── __init__.py
│   │   ├── effects_engine.py         # Main effects engine
│   │   ├── matrix_rain.py            # Matrix rain effect
│   │   ├── particle_system.py        # Particle effects
│   │   ├── neural_visualizer.py      # Neural network viz
│   │   ├── holographic.py            # Holographic displays
│   │   └── ascii_art.py              # ASCII art generation
│   │
│   ├── interface/                    # User interface
│   │   ├── __init__.py
│   │   ├── cli_ultra.py              # Main CLI interface
│   │   ├── prompts.py                # Input handling
│   │   ├── displays.py               # Output formatting
│   │   └── themes_ultra.py           # Theme management
│   │
│   ├── gamification/                 # Gamification systems
│   │   ├── __init__.py
│   │   ├── achievements.py           # Achievement system
│   │   ├── experience.py             # XP and leveling
│   │   ├── rewards.py                # Reward mechanics
│   │   └── easter_eggs.py            # Hidden features
│   │
│   ├── data/                         # Data management
│   │   ├── __init__.py
│   │   ├── history.py                # Conversation history
│   │   ├── state_manager.py          # Application state
│   │   ├── cache.py                  # Caching layer
│   │   └── models.py                 # Data models
│   │
│   ├── integration/                  # External integrations
│   │   ├── __init__.py
│   │   ├── context7_client.py        # Context7 MCP client
│   │   ├── mcp_protocol.py           # MCP protocol handler
│   │   └── openai_wrapper.py         # OpenAI integration
│   │
│   └── utils/                        # Utility modules
│       ├── __init__.py
│       ├── animations.py             # Animation helpers
│       ├── formatters.py             # Text formatting
│       ├── validators.py             # Input validation
│       └── performance.py            # Performance utilities
│
├── tests/                            # Test suite
│   ├── __init__.py
│   ├── unit/                         # Unit tests
│   ├── integration/                  # Integration tests
│   ├── performance/                  # Performance tests
│   └── fixtures/                     # Test fixtures
│
├── docs/                             # Documentation
│   ├── architecture/                 # Architecture docs
│   ├── api/                          # API documentation
│   ├── guides/                       # User guides
│   └── development/                  # Development docs
│
├── scripts/                          # Utility scripts
│   ├── install.py                    # Installation script
│   ├── benchmark.py                  # Performance benchmarking
│   └── generate_assets.py            # Asset generation
│
├── assets/                           # Static assets
│   ├── ascii/                        # ASCII art templates
│   ├── sounds/                       # Sound definitions
│   └── data/                         # Static data files
│
├── config/                           # Configuration files
│   ├── default.yaml                  # Default configuration
│   ├── personalities/                # Personality configs
│   └── themes/                       # Theme configurations
│
├── .github/                          # GitHub specific
│   ├── workflows/                    # CI/CD workflows
│   └── ISSUE_TEMPLATE/               # Issue templates
│
├── neural_navigator.py               # Main entry point
├── pyproject.toml                    # Project configuration
├── requirements.txt                  # Python dependencies
├── README.md                         # Project README
├── LICENSE                           # License file
├── .env.example                      # Environment example
└── .gitignore                        # Git ignore rules
```

### Key Module Descriptions

#### Core Modules

##### `agent_ultra.py` - The Neural Brain
This is the central intelligence of the system:

```python
class Context7AgentUltra:
    """
    The main neural agent that orchestrates all operations.
    
    This class serves as the brain of the Neural Navigator, coordinating
    between different subsystems and managing the overall intelligence.
    """
    
    def __init__(self, personality: AgentPersonality):
        # Initialize quantum state
        self.quantum_state = QuantumState()
        
        # Load personality module
        self.personality_core = PersonalityCore(personality)
        
        # Initialize search engines
        self.quantum_search_engine = QuantumSearchEngine(self.quantum_state)
        self.pathway_explorer = NeuralPathwayExplorer()
        self.knowledge_synthesizer = KnowledgeSynthesizer()
        
        # Setup visual engine
        self.visual_engine = VisualEffectsEngine(
            theme=self.personality_core.get_preferred_theme()
        )
        
        # Initialize MCP client
        self.mcp_client = Context7MCPClient()
        
        # Setup event bus for neural communication
        self.event_bus = NeuralEventBus()
        self._register_event_handlers()
```

##### `quantum_search.py` - Quantum Search Implementation
Implements probabilistic search with quantum mechanics:

```python
class QuantumSearchEngine:
    """
    Implements quantum-enhanced search capabilities.
    
    Search results exist in superposition until observed, allowing
    for probabilistic exploration of knowledge space.
    """
    
    async def quantum_search(
        self,
        query: str,
        quantum_params: QuantumSearchParams
    ) -> QuantumSearchResult:
        """
        Perform a quantum search operation.
        
        The search explores multiple probability branches simultaneously,
        collapsing into concrete results only when observed.
        """
        # Create quantum query representation
        quantum_query = self._create_quantum_query(query)
        
        # Initialize probability branches
        branches = await self._initialize_probability_branches(
            quantum_query,
            quantum_params.branch_count
        )
        
        # Explore branches in parallel
        results = await asyncio.gather(*[
            self._explore_branch(branch)
            for branch in branches
        ])
        
        # Collapse wave function
        collapsed_results = self._collapse_results(
            results,
            quantum_params.collapse_threshold
        )
        
        return QuantumSearchResult(
            documents=collapsed_results,
            quantum_state=self.quantum_state.snapshot(),
            probability_map=self._generate_probability_map(results)
        )
```

#### Visual Effects System

##### `effects_engine.py` - Visual Effects Orchestration
Manages all visual effects in the system:

```python
class VisualEffectsEngine:
    """
    Orchestrates visual effects throughout the application.
    
    This engine manages effect queues, timing, and rendering
    to create smooth, stunning visual experiences.
    """
    
    def __init__(self, theme: UltraTheme):
        self.theme = theme
        self.effect_queue = asyncio.Queue()
        self.active_effects = []
        self.renderer = TerminalRenderer()
        
    async def trigger_effect(
        self,
        effect_type: EffectType,
        params: Dict[str, Any]
    ):
        """Trigger a visual effect."""
        effect = self._create_effect(effect_type, params)
        
        # Add to queue for sequential effects
        if effect.is_blocking:
            await self.effect_queue.put(effect)
        else:
            # Non-blocking effects run immediately
            self.active_effects.append(effect)
            asyncio.create_task(self._run_effect(effect))
    
    def _create_effect(
        self,
        effect_type: EffectType,
        params: Dict[str, Any]
    ) -> VisualEffect:
        """Factory method for creating effects."""
        effect_map = {
            EffectType.MATRIX_RAIN: MatrixRainEffect,
            EffectType.PARTICLE_BURST: ParticleBurstEffect,
            EffectType.NEURAL_NETWORK: NeuralNetworkEffect,
            EffectType.HOLOGRAPHIC: HolographicEffect,
            EffectType.QUANTUM_COLLAPSE: QuantumCollapseEffect
        }
        
        effect_class = effect_map.get(effect_type)
        return effect_class(self.theme, **params)
```

##### `matrix_rain.py` - Matrix Rain Implementation
The iconic matrix rain effect:

```python
class MatrixRainEffect(VisualEffect):
    """
    Creates the iconic Matrix digital rain effect.
    
    Characters fall at different speeds with glowing heads
    and fading tails, creating a sense of depth.
    """
    
    def __init__(self, theme: UltraTheme, duration: float = 3.0):
        super().__init__(theme)
        self.duration = duration
        self.columns = []
        self.character_set = self._get_character_set()
        
    def _get_character_set(self) -> List[str]:
        """Get characters based on theme."""
        if self.theme.name == "Matrix":
            # Use Japanese characters for authentic Matrix feel
            return [chr(i) for i in range(0x30A0, 0x30FF)]
        elif self.theme.name == "Neon Dreams":
            # Use geometric shapes
            return ["◆", "◇", "○", "●", "□", "■", "△", "▽"]
        else:
            # Default to mixed characters
            return list("01@#$%^&*()[]{}ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz")
    
    async def render(self, console: Console):
        """Render the matrix rain effect."""
        width = console.width
        height = console.height
        
        # Initialize columns
        self._initialize_columns(width, height)
        
        # Animation loop
        start_time = time.time()
        while time.time() - start_time < self.duration:
            frame = self._create_frame(width, height)
            console.clear()
            console.print(frame)
            
            # Update columns
            self._update_columns(height)
            
            await asyncio.sleep(0.05)  # 20 FPS
```

#### Personality System

##### `base.py` - Base Personality Framework
Defines how personalities affect system behavior:

```python
class PersonalityBase:
    """
    Base class for all AI personalities.
    
    Personalities affect:
    - Response generation style
    - Visual effect preferences
    - Search behavior modifications
    - Interaction patterns
    """
    
    def __init__(self):
        self.traits = self._define_traits()
        self.mood_modifiers = self._define_mood_modifiers()
        self.visual_preferences = self._define_visual_preferences()
        
    @abstractmethod
    def _define_traits(self) -> PersonalityTraits:
        """Define personality traits."""
        pass
    
    @abstractmethod
    def generate_response(
        self,
        context: ResponseContext
    ) -> PersonalityResponse:
        """Generate personality-specific response."""
        pass
    
    @abstractmethod
    def modify_search_behavior(
        self,
        search_params: SearchParams
    ) -> SearchParams:
        """Modify search behavior based on personality."""
        pass
    
    def get_greeting(self) -> str:
        """Get personality-specific greeting."""
        return self.traits.greeting_template.format(
            time=self._get_time_greeting(),
            emoji=random.choice(self.traits.emoji_set)
        )
```

##### `quantum.py` - Quantum Personality Implementation
The mysterious quantum personality:

```python
class QuantumPersonality(PersonalityBase):
    """
    Quantum - The Mysterious Oracle
    
    Speaks in riddles and quantum metaphors, revealing hidden
    truths through enigmatic responses.
    """
    
    def _define_traits(self) -> PersonalityTraits:
        return PersonalityTraits(
            name="Quantum",
            greeting_template="{emoji} Reality is but a probability wave... {time}",
            emoji_set=["🌌", "⚛️", "🔬", "🌀", "♾️"],
            response_style="enigmatic",
            enthusiasm_level=0.3,  # Calm and mysterious
            verbosity=0.7,  # Somewhat verbose but cryptic
            humor_level=0.2,  # Rarely humorous
            formality=0.8  # Quite formal
        )
    
    def generate_response(
        self,
        context: ResponseContext
    ) -> PersonalityResponse:
        """Generate quantum-style enigmatic response."""
        # Add quantum metaphors
        quantum_phrases = [
            "In the superposition of possibilities...",
            "As the wave function collapses...",
            "Through quantum entanglement...",
            "Observing changes the observed...",
            "In the quantum foam of knowledge..."
        ]
        
        intro = random.choice(quantum_phrases)
        
        # Modify response to be more mysterious
        modified_content = self._add_quantum_mystery(context.base_response)
        
        return PersonalityResponse(
            content=f"{intro} {modified_content}",
            mood=MoodState.CONTEMPLATIVE,
            visual_effects=[
                EffectType.QUANTUM_PARTICLES,
                EffectType.PROBABILITY_WAVES
            ]
        )
    
    def modify_search_behavior(
        self,
        search_params: SearchParams
    ) -> SearchParams:
        """Enhance search with quantum properties."""
        search_params.quantum_enabled = True
        search_params.probability_threshold = 0.3  # Lower threshold for uncertainty
        search_params.superposition_count = 5  # More parallel universes
        search_params.entanglement_depth = 3  # Deeper connections
        
        return search_params
```

---

## Data Flow Architecture

### Request Lifecycle

The following diagram illustrates how a search request flows through the system:

```mermaid
sequenceDiagram
    participant U as User
    participant CLI as CLI Interface
    participant PM as Personality Manager
    participant NA as Neural Agent
    participant QSE as Quantum Search Engine
    participant VE as Visual Engine
    participant C7 as Context7 Client
    participant DB as Database
    
    U->>CLI: Enter search query
    CLI->>PM: Process with personality
    PM->>NA: Enhanced query
    NA->>VE: Start pre-search effects
    VE-->>U: Matrix rain animation
    
    NA->>QSE: Initialize quantum search
    QSE->>C7: Query Context7 MCP
    C7-->>QSE: Raw results
    
    QSE->>QSE: Apply quantum transformations
    QSE->>NA: Quantum search results
    
    NA->>VE: Render results visualization
    VE-->>U: Neural network display
    
    NA->>DB: Store search history
    NA->>PM: Generate response
    PM-->>CLI: Personality response
    CLI-->>U: Display results
```

### State Management Flow

```python
class StateManager:
    """
    Centralized state management for the Neural Navigator.
    
    Implements a Redux-like pattern with immutable state updates
    and time-travel debugging capabilities.
    """
    
    def __init__(self):
        self.state = self._initial_state()
        self.history = []
        self.subscribers = []
        self.middleware = []
        
    def _initial_state(self) -> AppState:
        """Define initial application state."""
        return AppState(
            user=UserState(
                level=1,
                experience=0,
                achievements=[],
                current_session=None
            ),
            neural=NeuralState(
                quantum_coherence=1.0,
                entanglement=0.0,
                active_pathways=[],
                discovered_nodes=set()
            ),
            search=SearchState(
                current_query=None,
                results=[],
                history=[],
                filters={}
            ),
            visual=VisualState(
                theme="matrix",
                effects_enabled=True,
                particle_density=1.0
            )
        )
    
    def dispatch(self, action: Action):
        """Dispatch an action to update state."""
        # Run through middleware
        for middleware in self.middleware:
            action = middleware(action, self.state)
            if action is None:
                return  # Middleware cancelled action
        
        # Store previous state
        self.history.append(deepcopy(self.state))
        
        # Apply reducer
        self.state = self._reduce(self.state, action)
        
        # Notify subscribers
        for subscriber in self.subscribers:
            subscriber(self.state, action)
    
    def _reduce(self, state: AppState, action: Action) -> AppState:
        """Main reducer function."""
        if action.type == ActionType.SEARCH_INITIATED:
            return state.copy(
                search=state.search.copy(
                    current_query=action.payload["query"],
                    results=[]
                )
            )
        elif action.type == ActionType.RESULTS_RECEIVED:
            return state.copy(
                search=state.search.copy(
                    results=action.payload["results"]
                )
            )
        # ... more action handlers
```

---

## Neural Search Engine

### Architecture Overview

The Neural Search Engine implements a multi-dimensional search approach:

```python
class NeuralSearchArchitecture:
    """
    Core architecture for the neural search system.
    
    Implements multiple search strategies that work in parallel:
    1. Semantic Search - Understanding meaning
    2. Quantum Search - Probabilistic exploration
    3. Neural Pathway - Connection-based discovery
    4. Resonance Search - Frequency-based matching
    """
    
    def __init__(self):
        self.search_strategies = {
            SearchMode.SEMANTIC: SemanticSearchStrategy(),
            SearchMode.QUANTUM: QuantumSearchStrategy(),
            SearchMode.NEURAL: NeuralPathwayStrategy(),
            SearchMode.RESONANCE: ResonanceSearchStrategy()
        }
        
        self.result_synthesizer = ResultSynthesizer()
        self.ranking_engine = NeuralRankingEngine()
```

### Quantum Search Implementation

```python
class QuantumSearchStrategy(SearchStrategy):
    """
    Implements quantum-mechanical search principles.
    
    Key concepts:
    - Superposition: Multiple search states exist simultaneously
    - Entanglement: Related documents affect each other's relevance
    - Observation: Results crystallize based on user interaction
    """
    
    async def search(
        self,
        query: str,
        context: SearchContext
    ) -> List[QuantumDocument]:
        """Execute quantum search."""
        # Create quantum query representation
        quantum_query = QuantumQuery(
            base_query=query,
            superposition_states=self._generate_superposition_states(query),
            entanglement_map=self._create_entanglement_map(context)
        )
        
        # Initialize probability amplitudes
        probability_field = ProbabilityField(
            dimensions=context.search_dimensions,
            coherence=context.quantum_state.coherence
        )
        
        # Perform parallel universe search
        universes = []
        for state in quantum_query.superposition_states:
            universe = await self._search_universe(
                state,
                probability_field
            )
            universes.append(universe)
        
        # Collapse wave function based on observation
        collapsed_results = self._collapse_universes(
            universes,
            observation_params=context.observation_params
        )
        
        # Apply quantum entanglement effects
        entangled_results = self._apply_entanglement(
            collapsed_results,
            quantum_query.entanglement_map
        )
        
        return entangled_results
    
    def _generate_superposition_states(
        self,
        query: str
    ) -> List[SuperpositionState]:
        """Generate multiple query states in superposition."""
        states = []
        
        # Original query
        states.append(SuperpositionState(
            query=query,
            amplitude=1.0,
            phase=0
        ))
        
        # Synonyms and related concepts
        for synonym in self._get_synonyms(query):
            states.append(SuperpositionState(
                query=synonym,
                amplitude=0.7,
                phase=random.random() * 2 * math.pi
            ))
        
        # Quantum variations
        for variation in self._quantum_variations(query):
            states.append(SuperpositionState(
                query=variation,
                amplitude=0.5,
                phase=random.random() * 2 * math.pi
            ))
        
        return states
```

### Neural Pathway Exploration

```python
class NeuralPathwayExplorer:
    """
    Explores connections between documents like neural pathways.
    
    Uses graph theory and neural network principles to discover
    hidden connections and knowledge paths.
    """
    
    def __init__(self):
        self.neural_graph = NeuralGraph()
        self.pathway_analyzer = PathwayAnalyzer()
        self.synapse_strength_calculator = SynapseStrengthCalculator()
    
    async def explore_pathways(
        self,
        start_node: str,
        exploration_params: ExplorationParams
    ) -> NeuralPathwayMap:
        """Explore neural pathways from a starting point."""
        # Initialize exploration
        visited_nodes = set()
        active_paths = [NeuralPath(start_node)]
        discovered_pathways = []
        
        # Breadth-first exploration with neural activation
        for depth in range(exploration_params.max_depth):
            new_paths = []
            
            for path in active_paths:
                # Get connected nodes
                connections = await self.neural_graph.get_connections(
                    path.current_node
                )
                
                # Calculate synapse strengths
                for connection in connections:
                    strength = self.synapse_strength_calculator.calculate(
                        path.current_node,
                        connection.target,
                        path.activation_history
                    )
                    
                    if strength > exploration_params.activation_threshold:
                        # Create new path branch
                        new_path = path.branch(
                            connection.target,
                            strength
                        )
                        new_paths.append(new_path)
                        
                        # Check for significant pathways
                        if self._is_significant_pathway(new_path):
                            discovered_pathways.append(new_path)
            
            active_paths = new_paths
            
            # Prune paths based on neural energy
            active_paths = self._prune_paths(
                active_paths,
                exploration_params.energy_budget
            )
        
        return NeuralPathwayMap(
            pathways=discovered_pathways,
            convergence_points=self._find_convergence_points(discovered_pathways),
            neural_clusters=self._identify_clusters(discovered_pathways)
        )
```

---

## Visual Effects Engine

### Effect System Architecture

```python
class EffectSystemArchitecture:
    """
    Core architecture for the visual effects system.
    
    Implements a pipeline-based approach where effects can be
    composed, layered, and synchronized.
    """
    
    def __init__(self):
        self.effect_pipeline = EffectPipeline()
        self.compositor = EffectCompositor()
        self.timing_controller = TimingController()
        self.resource_manager = EffectResourceManager()
```

### Particle System Implementation

```python
class ParticleSystem:
    """
    Advanced particle system for creating dynamic visual effects.
    
    Features:
    - Physics simulation (gravity, forces, collisions)
    - Emitter patterns (point, line, circle, custom)
    - Particle behaviors (seek, flee, orbit, swarm)
    - Performance optimization through object pooling
    """
    
    def __init__(self, max_particles: int = 1000):
        self.particle_pool = ParticlePool(max_particles)
        self.emitters = []
        self.forces = []
        self.behaviors = []
        self.renderer = ParticleRenderer()
        
    def create_emitter(
        self,
        emitter_type: EmitterType,
        position: Vector2D,
        params: EmitterParams
    ) -> Emitter:
        """Create a new particle emitter."""
        emitter = self._create_emitter_instance(emitter_type)
        emitter.configure(position, params)
        self.emitters.append(emitter)
        return emitter
    
    async def update(self, delta_time: float):
        """Update all particles and emitters."""
        # Emit new particles
        for emitter in self.emitters:
            if emitter.active:
                new_particles = emitter.emit(delta_time)
                for particle_params in new_particles:
                    particle = self.particle_pool.acquire()
                    if particle:
                        particle.reset(particle_params)
        
        # Update active particles
        active_particles = self.particle_pool.get_active()
        
        # Apply forces
        for particle in active_particles:
            for force in self.forces:
                force.apply(particle, delta_time)
        
        # Apply behaviors
        for particle in active_particles:
            for behavior in self.behaviors:
                behavior.apply(particle, active_particles, delta_time)
        
        # Update particle states
        for particle in active_particles:
            particle.update(delta_time)
            
            # Return to pool if dead
            if particle.life <= 0:
                self.particle_pool.release(particle)
    
    async def render(self, console: Console):
        """Render all active particles."""
        active_particles = self.particle_pool.get_active()
        await self.renderer.render(active_particles, console)
```

### Holographic Display System

```python
class HolographicDisplaySystem:
    """
    Creates futuristic holographic displays with glitch effects,
    scanlines, and depth simulation.
    """
    
    def __init__(self):
        self.scanline_generator = ScanlineGenerator()
        self.glitch_engine = GlitchEngine()
        self.depth_simulator = DepthSimulator()
        self.hologram_shader = HologramShader()
    
    def create_hologram(
        self,
        content: str,
        display_params: HologramParams
    ) -> HologramDisplay:
        """Create a holographic display."""
        # Process content through hologram pipeline
        processed_content = self._process_content(content)
        
        # Apply holographic effects
        with_scanlines = self.scanline_generator.apply(
            processed_content,
            display_params.scanline_intensity
        )
        
        with_glitch = self.glitch_engine.apply(
            with_scanlines,
            display_params.glitch_probability
        )
        
        with_depth = self.depth_simulator.apply(
            with_glitch,
            display_params.depth_layers
        )
        
        # Apply hologram shader
        final_display = self.hologram_shader.shade(
            with_depth,
            display_params.color_scheme
        )
        
        return HologramDisplay(
            content=final_display,
            animation_sequence=self._create_animation_sequence(display_params)
        )
    
    def _create_animation_sequence(
        self,
        params: HologramParams
    ) -> AnimationSequence:
        """Create animation sequence for hologram."""
        sequence = AnimationSequence()
        
        # Flicker effect
        if params.flicker_enabled:
            sequence.add(FlickerAnimation(
                frequency=params.flicker_frequency,
                intensity=params.flicker_intensity
            ))
        
        # Rotation effect
        if params.rotation_enabled:
            sequence.add(RotationAnimation(
                axis=params.rotation_axis,
                speed=params.rotation_speed
            ))
        
        # Wave distortion
        if params.wave_distortion_enabled:
            sequence.add(WaveDistortionAnimation(
                amplitude=params.wave_amplitude,
                frequency=params.wave_frequency
            ))
        
        return sequence
```

---

## Gamification System

### Achievement Architecture

```python
class AchievementSystem:
    """
    Comprehensive achievement system that tracks user progress
    and unlocks rewards.
    
    Features:
    - Progressive achievements (bronze, silver, gold)
    - Hidden achievements
    - Achievement chains
    - Seasonal/time-limited achievements
    """
    
    def __init__(self):
        self.achievement_registry = AchievementRegistry()
        self.progress_tracker = ProgressTracker()
        self.unlock_manager = UnlockManager()
        self.notification_system = NotificationSystem()
        
    def register_achievement(self, achievement: Achievement):
        """Register a new achievement."""
        self.achievement_registry.register(achievement)
        
        # Set up tracking
        self.progress_tracker.create_tracker(
            achievement.id,
            achievement.requirements
        )
    
    async def check_achievements(
        self,
        event: GameEvent,
        user_state: UserState
    ):
        """Check if any achievements should be unlocked."""
        # Get relevant achievements for this event
        relevant_achievements = self.achievement_registry.get_by_event_type(
            event.type
        )
        
        for achievement in relevant_achievements:
            if self._should_unlock(achievement, event, user_state):
                await self._unlock_achievement(achievement, user_state)
    
    def _should_unlock(
        self,
        achievement: Achievement,
        event: GameEvent,
        user_state: UserState
    ) -> bool:
        """Determine if achievement should unlock."""
        # Check if already unlocked
        if achievement.id in user_state.unlocked_achievements:
            return False
        
        # Check prerequisites
        for prereq_id in achievement.prerequisites:
            if prereq_id not in user_state.unlocked_achievements:
                return False
        
        # Check requirements
        return achievement.requirement_checker(event, user_state)
    
    async def _unlock_achievement(
        self,
        achievement: Achievement,
        user_state: UserState
    ):
        """Unlock an achievement with fanfare."""
        # Update user state
        user_state.unlocked_achievements.add(achievement.id)
        user_state.achievement_points += achievement.points
        
        # Apply rewards
        for reward in achievement.rewards:
            await self.unlock_manager.apply_reward(reward, user_state)
        
        # Show notification
        await self.notification_system.show_achievement_unlock(
            achievement,
            include_animation=True,
            duration=3.0
        )
        
        # Check for achievement chains
        await self._check_achievement_chains(achievement, user_state)
```

### Experience and Leveling System

```python
class ExperienceSystem:
    """
    Manages user experience points and level progression.
    
    Features:
    - Non-linear XP curves
    - Bonus XP multipliers
    - Prestige system
    - Level-based unlocks
    """
    
    def __init__(self):
        self.xp_calculator = XPCalculator()
        self.level_curve = self._create_level_curve()
        self.prestige_system = PrestigeSystem()
        self.unlock_schedule = self._create_unlock_schedule()
    
    def _create_level_curve(self) -> LevelCurve:
        """Create non-linear level progression curve."""
        return LevelCurve(
            formula=lambda level: int(100 * (level ** 1.5)),
            max_level=100,
            prestige_levels=10
        )
    
    def add_experience(
        self,
        user_state: UserState,
        base_xp: int,
        context: XPContext
    ) -> XPGainResult:
        """Add experience points with modifiers."""
        # Calculate multipliers
        multipliers = self._calculate_multipliers(user_state, context)
        
        # Apply multipliers
        total_xp = base_xp
        for multiplier in multipliers:
            total_xp = int(total_xp * multiplier.value)
        
        # Add to user state
        old_level = user_state.level
        user_state.experience += total_xp
        
        # Check for level up
        level_ups = []
        while self._should_level_up(user_state):
            user_state.level += 1
            level_up_info = LevelUpInfo(
                new_level=user_state.level,
                unlocks=self.unlock_schedule.get_unlocks(user_state.level),
                bonus_rewards=self._calculate_level_bonus(user_state.level)
            )
            level_ups.append(level_up_info)
        
        return XPGainResult(
            xp_gained=total_xp,
            multipliers_applied=multipliers,
            level_ups=level_ups,
            next_level_progress=self._calculate_progress_to_next(user_state)
        )
```

---

## Integration Patterns

### Context7 MCP Integration

```python
class Context7MCPIntegration:
    """
    Handles integration with Context7 Model Context Protocol server.
    
    Implements:
    - Connection management
    - Protocol handling
    - Request/response processing
    - Error recovery
    """
    
    def __init__(self):
        self.connection_pool = MCPConnectionPool()
        self.protocol_handler = MCPProtocolHandler()
        self.request_queue = asyncio.Queue()
        self.response_handlers = {}
    
    async def connect(self):
        """Establish connection to Context7 MCP server."""
        # Start MCP server process
        self.process = await asyncio.create_subprocess_exec(
            "npx",
            "-y",
            "@upstash/context7-mcp@latest",
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        # Initialize protocol
        await self.protocol_handler.initialize(
            self.process.stdin,
            self.process.stdout
        )
        
        # Start message processing
        asyncio.create_task(self._process_messages())
    
    async def search(
        self,
        query: str,
        options: SearchOptions
    ) -> List[Document]:
        """Perform search through MCP."""
        # Create request
        request = MCPRequest(
            id=str(uuid.uuid4()),
            method="search",
            params={
                "query": query,
                "filters": options.filters,
                "limit": options.limit,
                "quantum_mode": options.quantum_enabled
            }
        )
        
        # Send request
        response = await self._send_request(request)
        
        # Process response
        documents = []
        for doc_data in response.result.get("documents", []):
            documents.append(Document(
                id=doc_data["id"],
                title=doc_data["title"],
                content=doc_data["content"],
                metadata=doc_data.get("metadata", {}),
                neural_properties=self._extract_neural_properties(doc_data)
            ))
        
        return documents
    
    def _extract_neural_properties(
        self,
        doc_data: Dict
    ) -> NeuralProperties:
        """Extract neural properties from document data."""
        return NeuralProperties(
            embedding=doc_data.get("embedding", []),
            semantic_density=doc_data.get("semantic_density", 0.5),
            information_entropy=doc_data.get("entropy", 0.5),
            neural_activation=doc_data.get("activation", 0.0)
        )
```

### OpenAI Integration Pattern

```python
class OpenAIIntegration:
    """
    Integrates with OpenAI API through Pydantic AI.
    
    Features:
    - Automatic retry with exponential backoff
    - Token management
    - Response streaming
    - Cost tracking
    """
    
    def __init__(self, config: OpenAIConfig):
        self.config = config
        self.model = self._create_model()
        self.token_manager = TokenManager(config.token_limit)
        self.cost_tracker = CostTracker()
        
    def _create_model(self) -> OpenAIModel:
        """Create configured OpenAI model."""
        return OpenAIModel(
            api_key=self.config.api_key,
            base_url=self.config.base_url,
            model_name=self.config.model_name,
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens
        )
    
    async def generate_response(
        self,
        prompt: str,
        context: ResponseContext
    ) -> AIResponse:
        """Generate response with retry logic."""
        # Check token availability
        estimated_tokens = self.token_manager.estimate_tokens(prompt)
        if not self.token_manager.has_capacity(estimated_tokens):
            raise TokenLimitExceeded()
        
        # Attempt generation with retry
        retry_count = 0
        while retry_count < self.config.max_retries:
            try:
                response = await self._generate_with_timeout(prompt, context)
                
                # Track usage
                self.token_manager.record_usage(response.token_usage)
                self.cost_tracker.record_request(response.token_usage)
                
                return response
                
            except Exception as e:
                retry_count += 1
                if retry_count >= self.config.max_retries:
                    raise
                
                # Exponential backoff
                await asyncio.sleep(2 ** retry_count)
```

---

## Testing Architecture

### Test Strategy Overview

```python
class TestingArchitecture:
    """
    Comprehensive testing strategy for Neural Navigator.
    
    Layers:
    1. Unit Tests - Individual component testing
    2. Integration Tests - Module interaction testing
    3. System Tests - End-to-end functionality
    4. Performance Tests - Load and stress testing
    5. Visual Tests - Effect rendering validation
    """
    
    def __init__(self):
        self.test_suites = {
            TestLevel.UNIT: UnitTestSuite(),
            TestLevel.INTEGRATION: IntegrationTestSuite(),
            TestLevel.SYSTEM: SystemTestSuite(),
            TestLevel.PERFORMANCE: PerformanceTestSuite(),
            TestLevel.VISUAL: VisualTestSuite()
        }
```

### Unit Test Example

```python
# tests/unit/test_quantum_search.py

class TestQuantumSearch:
    """Unit tests for quantum search functionality."""
    
    @pytest.fixture
    def quantum_engine(self):
        """Create quantum search engine fixture."""
        return QuantumSearchEngine(
            quantum_state=QuantumState(coherence=0.9)
        )
    
    @pytest.mark.asyncio
    async def test_superposition_generation(self, quantum_engine):
        """Test that superposition states are correctly generated."""
        query = "quantum computing"
        states = quantum_engine._generate_superposition_states(query)
        
        # Should have original query
        assert any(s.query == query for s in states)
        
        # Should have variations
        assert len(states) > 1
        
        # Amplitudes should sum to ~1 (normalized)
        total_amplitude = sum(s.amplitude ** 2 for s in states)
        assert 0.9 < total_amplitude < 1.1
    
    @pytest.mark.asyncio
    async def test_wave_function_collapse(self, quantum_engine):
        """Test wave function collapse behavior."""
        # Create mock search results in superposition
        superposition_results = [
            SearchResult(doc_id="1", probability=0.8),
            SearchResult(doc_id="2", probability=0.6),
            SearchResult(doc_id="3", probability=0.4)
        ]
        
        # Collapse with threshold
        collapsed = quantum_engine._collapse_results(
            superposition_results,
            threshold=0.5
        )
        
        # Should only include high-probability results
        assert len(collapsed) == 2
        assert all(r.probability >= 0.5 for r in collapsed)
```

### Integration Test Example

```python
# tests/integration/test_neural_mcp_integration.py

class TestNeuralMCPIntegration:
    """Integration tests for Neural Agent with MCP."""
    
    @pytest.fixture
    async def neural_system(self):
        """Create integrated neural system."""
        agent = Context7AgentUltra(AgentPersonality.QUANTUM)
        await agent.mcp_client.connect()
        yield agent
        await agent.mcp_client.disconnect()
    
    @pytest.mark.asyncio
    async def test_quantum_search_through_mcp(self, neural_system):
        """Test full quantum search through MCP integration."""
        # Perform search
        result = await neural_system.quantum_search(
            None,
            "artificial intelligence",
            search_mode="quantum",
            consciousness_level=5
        )
        
        # Verify quantum properties
        assert "quantum_state" in result
        assert result["quantum_state"]["coherence"] > 0
        
        # Verify neural pathways
        assert "neural_pathways" in result
        assert len(result["neural_pathways"]) > 0
        
        # Verify documents have neural properties
        for doc in result["documents"]:
            assert hasattr(doc, "neural_weight")
            assert hasattr(doc, "quantum_entanglement")
```

### Performance Test Example

```python
# tests/performance/test_search_performance.py

class TestSearchPerformance:
    """Performance tests for search operations."""
    
    @pytest.mark.performance
    async def test_quantum_search_latency(self, benchmark):
        """Benchmark quantum search latency."""
        agent = Context7AgentUltra(AgentPersonality.NOVA)
        
        async def search_operation():
            await agent.quantum_search(
                None,
                "test query",
                consciousness_level=3
            )
        
        # Run benchmark
        result = await benchmark(search_operation)
        
        # Assert performance requirements
        assert result.median < 1.0  # Median under 1 second
        assert result.max < 2.0     # Max under 2 seconds
        assert result.stddev < 0.2  # Low variance
    
    @pytest.mark.stress
    async def test_concurrent_searches(self):
        """Test system under concurrent search load."""
        agent = Context7AgentUltra(AgentPersonality.QUANTUM)
        
        # Create concurrent search tasks
        tasks = []
        for i in range(100):
            task = agent.quantum_search(
                None,
                f"query {i}",
                consciousness_level=1
            )
            tasks.append(task)
        
        # Execute concurrently
        start_time = time.time()
        results = await asyncio.gather(*tasks)
        duration = time.time() - start_time
        
        # All should complete
        assert len(results) == 100
        
        # Should complete in reasonable time
        assert duration < 30.0  # 30 seconds for 100 searches
```

---

## Performance Optimization

### Optimization Strategies

```python
class PerformanceOptimizer:
    """
    Central performance optimization system.
    
    Strategies:
    1. Lazy Loading - Load resources only when needed
    2. Object Pooling - Reuse expensive objects
    3. Async Batching - Batch operations for efficiency
    4. Caching - Multi-level caching system
    5. Progressive Enhancement - Start simple, add effects
    """
    
    def __init__(self):
        self.resource_pool = ResourcePool()
        self.cache_manager = MultiLevelCache()
        self.batch_processor = BatchProcessor()
        self.performance_monitor = PerformanceMonitor()
```

### Object Pooling Implementation

```python
class ObjectPool:
    """
    Generic object pool for expensive resources.
    
    Used for:
    - Particle objects
    - Neural connections
    - Visual effects
    - Database connections
    """
    
    def __init__(
        self,
        factory: Callable[[], T],
        max_size: int = 100
    ):
        self.factory = factory
        self.max_size = max_size
        self.available = []
        self.in_use = set()
        self._lock = asyncio.Lock()
        
        # Pre-populate pool
        for _ in range(min(10, max_size)):
            self.available.append(factory())
    
    async def acquire(self) -> Optional[T]:
        """Acquire object from pool."""
        async with self._lock:
            if self.available:
                obj = self.available.pop()
                self.in_use.add(obj)
                return obj
            elif len(self.in_use) < self.max_size:
                obj = self.factory()
                self.in_use.add(obj)
                return obj
            else:
                return None  # Pool exhausted
    
    async def release(self, obj: T):
        """Return object to pool."""
        async with self._lock:
            if obj in self.in_use:
                self.in_use.remove(obj)
                
                # Reset object state
                if hasattr(obj, 'reset'):
                    obj.reset()
                
                self.available.append(obj)
```

### Caching Strategy

```python
class MultiLevelCache:
    """
    Multi-level caching system for different data types.
    
    Levels:
    1. L1 - In-memory hot cache (LRU)
    2. L2 - Disk-based warm cache
    3. L3 - Distributed cache (Redis)
    """
    
    def __init__(self):
        self.l1_cache = LRUCache(max_size=1000)
        self.l2_cache = DiskCache(cache_dir="./cache")
        self.l3_cache = RedisCache() if redis_available else None
        
    async def get(
        self,
        key: str,
        cache_level: CacheLevel = CacheLevel.L1
    ) -> Optional[Any]:
        """Get value from cache."""
        # Try L1 first
        value = await self.l1_cache.get(key)
        if value is not None:
            return value
        
        # Try L2 if allowed
        if cache_level >= CacheLevel.L2:
            value = await self.l2_cache.get(key)
            if value is not None:
                # Promote to L1
                await self.l1_cache.set(key, value)
                return value
        
        # Try L3 if available and allowed
        if self.l3_cache and cache_level >= CacheLevel.L3:
            value = await self.l3_cache.get(key)
            if value is not None:
                # Promote to L1 and L2
                await self.l1_cache.set(key, value)
                await self.l2_cache.set(key, value)
                return value
        
        return None
```

---

## Security Architecture

### Security Layers

```python
class SecurityArchitecture:
    """
    Multi-layered security architecture.
    
    Layers:
    1. Input Validation - Sanitize all user input
    2. Authentication - API key management
    3. Rate Limiting - Prevent abuse
    4. Encryption - Secure sensitive data
    5. Audit Logging - Track all operations
    """
    
    def __init__(self):
        self.input_validator = InputValidator()
        self.auth_manager = AuthenticationManager()
        self.rate_limiter = RateLimiter()
        self.encryption_service = EncryptionService()
        self.audit_logger = AuditLogger()
```

### Input Validation

```python
class InputValidator:
    """
    Comprehensive input validation system.
    
    Validates:
    - Search queries
    - Command inputs
    - Configuration values
    - File paths
    """
    
    def __init__(self):
        self.validators = {
            InputType.SEARCH_QUERY: self._validate_search_query,
            InputType.COMMAND: self._validate_command,
            InputType.CONFIG: self._validate_config,
            InputType.FILE_PATH: self._validate_file_path
        }
        
        self.sanitizers = {
            InputType.SEARCH_QUERY: self._sanitize_search_query,
            InputType.COMMAND: self._sanitize_command
        }
    
    async def validate_and_sanitize(
        self,
        input_value: str,
        input_type: InputType
    ) -> ValidationResult:
        """Validate and sanitize input."""
        # First validate
        validator = self.validators.get(input_type)
        if validator:
            validation_result = await validator(input_value)
            if not validation_result.is_valid:
                return validation_result
        
        # Then sanitize
        sanitizer = self.sanitizers.get(input_type)
        if sanitizer:
            sanitized_value = await sanitizer(input_value)
        else:
            sanitized_value = input_value
        
        return ValidationResult(
            is_valid=True,
            sanitized_value=sanitized_value,
            original_value=input_value
        )
    
    async def _validate_search_query(self, query: str) -> ValidationResult:
        """Validate search query."""
        # Check length
        if len(query) > 1000:
            return ValidationResult(
                is_valid=False,
                error="Query too long (max 1000 characters)"
            )
        
        # Check for injection attempts
        dangerous_patterns = [
            r'<script',
            r'javascript:',
            r'data:text/html',
            r'\x00',  # Null bytes
            r'\.\./',  # Path traversal
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, query, re.IGNORECASE):
                return ValidationResult(
                    is_valid=False,
                    error="Invalid characters in query"
                )
        
        return ValidationResult(is_valid=True)
```

---

## Deployment Strategy

### Deployment Architecture

```python
class DeploymentArchitecture:
    """
    Deployment strategy for Neural Navigator.
    
    Supports:
    1. Local installation
    2. Docker containers
    3. Cloud deployment (AWS/GCP/Azure)
    4. Kubernetes orchestration
    """
    
    def __init__(self):
        self.deployment_targets = {
            DeploymentTarget.LOCAL: LocalDeployment(),
            DeploymentTarget.DOCKER: DockerDeployment(),
            DeploymentTarget.KUBERNETES: KubernetesDeployment(),
            DeploymentTarget.CLOUD: CloudDeployment()
        }
```

### Docker Configuration

```dockerfile
# Dockerfile
FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install Node.js for Context7 MCP
RUN curl -fsSL https://deb.nodesource.com/setup_18.x | bash -
RUN apt-get install -y nodejs

# Set working directory
WORKDIR /app

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Install Context7 MCP
RUN npm install -g @upstash/context7-mcp

# Create volume for persistent data
VOLUME ["/app/data"]

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV NEURAL_NAVIGATOR_HOME=/app

# Entry point
ENTRYPOINT ["python", "neural_navigator.py"]
```

### Kubernetes Deployment

```yaml
# kubernetes/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: neural-navigator
  labels:
    app: neural-navigator
spec:
  replicas: 3
  selector:
    matchLabels:
      app: neural-navigator
  template:
    metadata:
      labels:
        app: neural-navigator
    spec:
      containers:
      - name: neural-navigator
        image: neural-navigator:latest
        ports:
        - containerPort: 8080
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: neural-secrets
              key: openai-api-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        volumeMounts:
        - name: data-volume
          mountPath: /app/data
      volumes:
      - name: data-volume
        persistentVolumeClaim:
          claimName: neural-data-pvc
```

---

## Future Extensibility

### Plugin Architecture

```python
class PluginArchitecture:
    """
    Plugin system for extending Neural Navigator.
    
    Plugin types:
    1. Search Strategies - Custom search algorithms
    2. Personalities - New AI personalities
    3. Visual Effects - Custom visual effects
    4. Integrations - Third-party service integrations
    """
    
    def __init__(self):
        self.plugin_registry = PluginRegistry()
        self.plugin_loader = PluginLoader()
        self.plugin_sandbox = PluginSandbox()
    
    def load_plugin(self, plugin_path: Path) -> Plugin:
        """Load and register a plugin."""
        # Load plugin metadata
        metadata = self.plugin_loader.load_metadata(plugin_path)
        
        # Validate plugin
        if not self._validate_plugin(metadata):
            raise InvalidPluginError()
        
        # Load in sandbox
        plugin = self.plugin_sandbox.load(
            plugin_path,
            restrictions=self._get_restrictions(metadata.type)
        )
        
        # Register plugin
        self.plugin_registry.register(plugin)
        
        return plugin
```

### Extension Points

```python
class ExtensionPoints:
    """
    Defines extension points where plugins can hook into.
    """
    
    # Search pipeline extensions
    SEARCH_PRE_PROCESS = "search.pre_process"
    SEARCH_POST_PROCESS = "search.post_process"
    SEARCH_RESULT_ENHANCE = "search.result_enhance"
    
    # Visual effect extensions
    EFFECT_PRE_RENDER = "effect.pre_render"
    EFFECT_POST_RENDER = "effect.post_render"
    EFFECT_CUSTOM = "effect.custom"
    
    # Personality extensions
    PERSONALITY_RESPONSE = "personality.response"
    PERSONALITY_MOOD = "personality.mood"
    
    # UI extensions
    UI_COMMAND_HANDLER = "ui.command_handler"
    UI_DISPLAY_FORMATTER = "ui.display_formatter"
    
    # Data extensions
    DATA_TRANSFORM = "data.transform"
    DATA_VALIDATE = "data.validate"
```

---

## Developer Guidelines

### Code Style Guidelines

```python
"""
Neural Navigator Code Style Guidelines

1. Naming Conventions:
   - Classes: PascalCase (NeuralAgent, QuantumSearch)
   - Functions: snake_case (search_documents, calculate_quantum_state)
   - Constants: UPPER_SNAKE_CASE (MAX_PARTICLES, DEFAULT_THEME)
   - Private methods: _leading_underscore (_internal_method)

2. Type Hints:
   - Always use type hints for function parameters and returns
   - Use generic types where appropriate (List[str], Dict[str, Any])
   - Create custom types for complex structures

3. Documentation:
   - Every class and function must have docstrings
   - Use Google-style docstrings
   - Include examples for complex functionality

4. Async/Await:
   - Prefer async/await over callbacks
   - Use asyncio.gather for parallel operations
   - Handle cancellation properly

5. Error Handling:
   - Create custom exceptions for specific errors
   - Always provide context in error messages
   - Use logging for debugging information
"""

# Example of well-styled code
class NeuralProcessor:
    """
    Processes neural network operations.
    
    This class handles the core neural processing operations including
    activation calculation, pathway exploration, and signal propagation.
    
    Attributes:
        activation_threshold: Minimum activation level for propagation
        max_depth: Maximum exploration depth for pathways
    
    Example:
        ```python
        processor = NeuralProcessor(activation_threshold=0.5)
        result = await processor.process_signal(input_signal)
        ```
    """
    
    def __init__(
        self,
        activation_threshold: float = 0.5,
        max_depth: int = 5
    ):
        """
        Initialize the neural processor.
        
        Args:
            activation_threshold: Minimum activation for signal propagation
            max_depth: Maximum depth for pathway exploration
        """
        self.activation_threshold = activation_threshold
        self.max_depth = max_depth
        self._node_cache: Dict[str, NeuralNode] = {}
    
    async def process_signal(
        self,
        signal: NeuralSignal
    ) -> ProcessingResult:
        """
        Process a neural signal through the network.
        
        Args:
            signal: The neural signal to process
            
        Returns:
            Processing result containing activated nodes and pathways
            
        Raises:
            InvalidSignalError: If the signal is malformed
            ProcessingTimeoutError: If processing exceeds time limit
        """
        # Implementation follows...
```

### Contributing Guidelines

```markdown
# Contributing to Neural Navigator

## Getting Started

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Set up development environment:
   ```bash
   python -m venv venv
   source venv/bin/activate
   pip install -r requirements-dev.txt
   pre-commit install
   ```

## Development Workflow

1. **Write Tests First**: Follow TDD principles
2. **Run Tests**: `pytest tests/`
3. **Check Coverage**: `pytest --cov=src tests/`
4. **Lint Code**: `flake8 src/` and `mypy src/`
5. **Format Code**: `black src/ tests/`

## Pull Request Process

1. Update documentation
2. Add tests for new functionality
3. Ensure all tests pass
4. Update CHANGELOG.md
5. Request review from maintainers

## Code Review Checklist

- [ ] Tests pass and coverage maintained
- [ ] Documentation updated
- [ ] Type hints added
- [ ] No security vulnerabilities
- [ ] Performance impact considered
- [ ] Visual effects render correctly
- [ ] Backwards compatibility maintained
```

---

## Conclusion

The Neural Navigator represents a revolutionary approach to knowledge discovery, transforming traditional search into an immersive neural exploration experience. This architecture document serves as the foundation for understanding and extending the system.

### Key Architectural Achievements

1. **Modular Neural Architecture**: Every component operates as an independent neural node
2. **Quantum Search Paradigm**: Probabilistic exploration of knowledge space
3. **Personality-Driven Design**: Adaptive behavior based on AI personalities
4. **Visual-First Philosophy**: Stunning effects as core functionality
5. **Gamification Integration**: Achievement and progression systems built-in
6. **Extensible Framework**: Plugin architecture for future growth

### Future Vision

The Neural Navigator is designed to evolve. Future enhancements may include:

- **Collective Intelligence**: Multiple users exploring together
- **Neural Synchronization**: Shared consciousness experiences
- **Reality Bending**: AR/VR integration
- **Quantum Entanglement**: Cross-dimensional search
- **Singularity Mode**: [CLASSIFIED]

Welcome to the future of knowledge discovery. Welcome to the Neural Navigator.

---

*"The only way to discover the limits of the possible is to go beyond them into the impossible."* - Arthur C. Clarke
```
